{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADS-B-Type-Track-CNN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD48FXL_dTsO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox64VPifHR5p"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTTEfIKk0gtm",
        "outputId": "96c9aa3a-f952-4ac5-e4c5-8585b1d93c9a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4hFAqqx01VA",
        "outputId": "e31205b9-bfa7-4958-fd8a-0c6413625d73"
      },
      "source": [
        "!pip install dask[dataframe]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n",
            "Collecting partd>=0.3.10; extra == \"dataframe\"\n",
            "  Downloading https://files.pythonhosted.org/packages/44/e1/68dbe731c9c067655bff1eca5b7d40c20ca4b23fd5ec9f3d17e201a6f36b/partd-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.23.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n",
            "Collecting fsspec>=0.6.0; extra == \"dataframe\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.1)\n",
            "Collecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.7.4.3)\n",
            "Installing collected packages: locket, partd, fsspec\n",
            "Successfully installed fsspec-0.8.7 locket-0.2.1 partd-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbgeFIVk04Mu",
        "outputId": "bcec1a54-2d30-4728-b76e-37d4c88a2813"
      },
      "source": [
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "file = '/content/drive/MyDrive/parsed_adsb_csvs_traks/*.csv'\n",
        "cols = ['Icao','Alt', 'Lat','Long', 'PosTime', 'Type', 'Trak']\n",
        "# read data frame from csv files\n",
        "train_df = dd.read_csv(file, dtype = {'Alt': 'uint16', 'Lat': 'float32', 'Long': 'float32', 'PosTime': 'int64', 'Trak': 'float32'}, usecols = cols) \n",
        "\n",
        "train_df = train_df.compute()\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Icao    Alt        Lat        Long        PosTime  Type        Trak\n",
            "0      A82B72   3500  39.717903  -84.619019  1596672029381  C172  215.100006\n",
            "1      A80E46  31000  61.336498 -140.995438  1596672028022  B748   85.400002\n",
            "2      A4E2E5    700  42.145557  -72.719398  1596672029830  C140  193.600006\n",
            "3      A4BDB9  15600  33.516727  -79.442421  1596672029378  E170  212.300003\n",
            "4      A4C3CE    650  32.965118  -96.833878  1596672030885  CRUZ  339.399994\n",
            "...       ...    ...        ...         ...            ...   ...         ...\n",
            "21419  C821F8  17975 -41.125225  175.051468  1596758412576  AT76  203.699997\n",
            "21420  C8234A  18500 -37.852840  174.806625  1596758411374  A320    0.000000\n",
            "21421  ACC040  28000  42.272324  -87.846115  1596758411880  CRJ9  339.200012\n",
            "21422  A7D222   6900  29.646700  -98.126343  1596757702853  BE36  165.000000\n",
            "21423  345292  32000  51.857941    5.114062  1596758411877  B734  272.399994\n",
            "\n",
            "[29300223 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xftglcmg2Q1Y",
        "outputId": "195ceb1e-6df8-49df-c6ef-62949d0e46bd"
      },
      "source": [
        "#Arrange in order of the Icao number\n",
        "train_df = train_df.sort_values(by=['Icao', 'PosTime'])\n",
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao   Alt        Lat       Long        PosTime  Type        Trak\n",
            "0         001000  2175  48.106934  11.258926  1596721377840  SIRA   37.299999\n",
            "1         001000  2175  48.106934  11.258926  1596721392353  SIRA   55.599998\n",
            "2         001000  2175  48.106934  11.258926  1596721394847  SIRA   55.599998\n",
            "3         001000  2175  48.109818  11.264557  1596721444191  SIRA  230.399994\n",
            "4         001000  2175  48.105652  11.257416  1596721470866  SIRA  229.699997\n",
            "...          ...   ...        ...        ...            ...   ...         ...\n",
            "29300218  F00000   450  49.149822   2.394817  1596742711592  SKRA  232.600006\n",
            "29300219  F00000   300  49.149822   2.394817  1596742711592  SKRA  232.600006\n",
            "29300220  F00000   200  49.149822   2.394817  1596742711592  SKRA  232.600006\n",
            "29300221  F00000   175  49.149822   2.394817  1596742711592  SKRA  232.600006\n",
            "29300222  F00000   175  49.149822   2.394817  1596742711592  SKRA  232.600006\n",
            "\n",
            "[29300223 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVApr6Rv2gKG",
        "outputId": "976c2167-5c9f-48b8-981a-bc3d40228b3e"
      },
      "source": [
        "max_lat = train_df['Lat'].max()\n",
        "min_lat = train_df['Lat'].min()\n",
        "max_lon = train_df['Long'].max()\n",
        "min_lon = train_df['Long'].min()\n",
        "max_alt = train_df['Alt'].max()\n",
        "min_alt = train_df['Alt'].min()\n",
        "max_trak = train_df['Trak'].max()\n",
        "min_trak = train_df['Trak'].min()\n",
        "\n",
        "#perform min- max normalization\n",
        "train_df['Lat'] = (train_df['Lat']- min_lat) / (max_lat - min_lat)\n",
        "train_df['Long'] = (train_df['Long']- min_lon) / (max_lon - min_lon)\n",
        "train_df['Alt'] = (train_df['Alt']- min_alt) / (max_alt - min_alt)\n",
        "train_df['Trak'] = (train_df['Trak']- min_trak) / (max_trak - min_trak)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type      Trak\n",
            "0         001000  0.033188  0.844904  0.531295  1596721377840  SIRA  0.103640\n",
            "1         001000  0.033188  0.844904  0.531295  1596721392353  SIRA  0.154487\n",
            "2         001000  0.033188  0.844904  0.531295  1596721394847  SIRA  0.154487\n",
            "3         001000  0.033188  0.844915  0.531311  1596721444191  SIRA  0.640178\n",
            "4         001000  0.033188  0.844899  0.531291  1596721470866  SIRA  0.638233\n",
            "...          ...       ...       ...       ...            ...   ...       ...\n",
            "29300218  F00000  0.006867  0.848767  0.506672  1596742711592  SKRA  0.646291\n",
            "29300219  F00000  0.004578  0.848767  0.506672  1596742711592  SKRA  0.646291\n",
            "29300220  F00000  0.003052  0.848767  0.506672  1596742711592  SKRA  0.646291\n",
            "29300221  F00000  0.002670  0.848767  0.506672  1596742711592  SKRA  0.646291\n",
            "29300222  F00000  0.002670  0.848767  0.506672  1596742711592  SKRA  0.646291\n",
            "\n",
            "[29300223 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsT6jkqZ2kHQ",
        "outputId": "dcdb62c7-d2d9-486b-de5f-6d4c5acd72d2"
      },
      "source": [
        "#Get percentage of Vessel Types in each data frame\n",
        "print(train_df['Type'].value_counts(normalize=True) * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B738    12.154024\n",
            "A320     8.080375\n",
            "C172     5.738216\n",
            "A321     3.910677\n",
            "B737     3.376336\n",
            "          ...    \n",
            "G300     0.000038\n",
            "D253     0.000017\n",
            "WACN     0.000010\n",
            "PTSS     0.000010\n",
            "A337     0.000007\n",
            "Name: Type, Length: 857, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp-0b5Cb2xOH",
        "outputId": "51663b19-4a4e-4a1f-b0b2-1df200468f87"
      },
      "source": [
        "Percentages = train_df['Type'].value_counts(normalize=True) * 100\n",
        "print(Percentages.head(25))\n",
        "print(Percentages[:10].sum())\n",
        "print(list(Percentages[:25].index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B738    12.154024\n",
            "A320     8.080375\n",
            "C172     5.738216\n",
            "A321     3.910677\n",
            "B737     3.376336\n",
            "A319     2.887497\n",
            "P28A     2.802849\n",
            "A20N     2.347242\n",
            "B763     1.749621\n",
            "B739     1.553411\n",
            "E75L     1.548084\n",
            "B752     1.324068\n",
            "B789     1.188991\n",
            "B773     1.140319\n",
            "CRJ9     1.029200\n",
            "B77L     1.011409\n",
            "C182     0.979177\n",
            "PC12     0.964255\n",
            "E190     0.878799\n",
            "C208     0.808519\n",
            "B744     0.801178\n",
            "A333     0.789704\n",
            "A21N     0.787666\n",
            "BE20     0.765492\n",
            "E170     0.755667\n",
            "Name: Type, dtype: float64\n",
            "44.60024758173343\n",
            "['B738', 'A320', 'C172', 'A321', 'B737', 'A319', 'P28A', 'A20N', 'B763', 'B739', 'E75L', 'B752', 'B789', 'B773', 'CRJ9', 'B77L', 'C182', 'PC12', 'E190', 'C208', 'B744', 'A333', 'A21N', 'BE20', 'E170']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkBxelStTcgB"
      },
      "source": [
        "# Top 10 Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYohhFKiTcgf",
        "outputId": "abc4cc15-3379-4f92-ce33-2f215f65fdd8"
      },
      "source": [
        "#remove rows not in the top 16 types\n",
        "train_df = train_df[train_df['Type'].isin(list(Percentages[:10].index))]\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type      Trak\n",
            "994       008DC6  0.088502  0.570442  0.578876  1596723690985  P28A  0.295916\n",
            "995       008DC6  0.089647  0.570432  0.578902  1596723703073  P28A  0.295916\n",
            "996       008DC6  0.090028  0.570430  0.578911  1596723717541  P28A  0.295916\n",
            "997       008DC6  0.090028  0.570430  0.578911  1596723719963  P28A  0.295916\n",
            "998       008DC6  0.152590  0.571812  0.578309  1596724548247  P28A  0.921089\n",
            "...          ...       ...       ...       ...            ...   ...       ...\n",
            "29300186  E94C42  0.122454  0.602148  0.316223  1596716959268  B738  0.861350\n",
            "29300187  E94C42  0.280766  0.601963  0.315146  1596733932455  B738  0.722423\n",
            "29300188  E94C42  0.281147  0.601961  0.315125  1596733935427  B738  0.722423\n",
            "29300189  E94C42  0.281147  0.601961  0.315125  1596733935427  B738  0.722423\n",
            "29300190  E94C42  0.286107  0.601955  0.314975  1596733965728  B738  0.722423\n",
            "\n",
            "[13067972 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyop92VmTcgh",
        "outputId": "00ac1573-b4fa-498e-eccb-5b7a19522c0d"
      },
      "source": [
        "type_dict = {k: v for v, k in enumerate(list(Percentages[:10].index))}\n",
        "print(type_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B738': 0, 'A320': 1, 'C172': 2, 'A321': 3, 'B737': 4, 'A319': 5, 'P28A': 6, 'A20N': 7, 'B763': 8, 'B739': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ_QsZ3iTcgi"
      },
      "source": [
        "train_df['Type'].replace(type_dict, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYkVT8SxTcgi",
        "outputId": "6e8405d5-d819-467c-f37a-ddd975f717f0"
      },
      "source": [
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type      Trak\n",
            "0         008DC6  0.088502  0.570442  0.578876  1596723690985     6  0.295916\n",
            "1         008DC6  0.089647  0.570432  0.578902  1596723703073     6  0.295916\n",
            "2         008DC6  0.090028  0.570430  0.578911  1596723717541     6  0.295916\n",
            "3         008DC6  0.090028  0.570430  0.578911  1596723719963     6  0.295916\n",
            "4         008DC6  0.152590  0.571812  0.578309  1596724548247     6  0.921089\n",
            "...          ...       ...       ...       ...            ...   ...       ...\n",
            "13067967  E94C42  0.122454  0.602148  0.316223  1596716959268     0  0.861350\n",
            "13067968  E94C42  0.280766  0.601963  0.315146  1596733932455     0  0.722423\n",
            "13067969  E94C42  0.281147  0.601961  0.315125  1596733935427     0  0.722423\n",
            "13067970  E94C42  0.281147  0.601961  0.315125  1596733935427     0  0.722423\n",
            "13067971  E94C42  0.286107  0.601955  0.314975  1596733965728     0  0.722423\n",
            "\n",
            "[13067972 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCkEsX7CTcgj",
        "outputId": "36f5b3dd-e3a7-4ea9-c921-d76e1e5304d6"
      },
      "source": [
        "#turn train dataframe into a multi-dimensional numpy array\n",
        "train_df = np.array(list(train_df.groupby('Icao').apply(pd.DataFrame.to_numpy)))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_count = train_df.shape[0]\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16014,)\n",
            "16014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ejVWHAoTcgk",
        "outputId": "07c22fc2-2528-41a3-f4eb-a19e5ad99aba"
      },
      "source": [
        "#load in first dataframe\n",
        "train_input = pd.DataFrame(data = train_df[1], columns = [\"Icao\", \"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\", \"Trak\"], index = None)\n",
        "train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "train_input = train_input.set_index('Time')\n",
        "train_input = train_input.drop('PosTime', axis = 1)\n",
        "train_input = train_input.drop('Icao', axis = 1)\n",
        "print(train_input)\n",
        "#Get Species Type\n",
        "unique_species = train_input.Type[0]\n",
        "print(unique_species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                Alt       Lat      Long Type      Trak\n",
            "Time                                                                  \n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0  0.966657\n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0  0.966657\n",
            "2020-08-06 07:13:29.760    0.995056  0.540866  0.551703    0    0.9611\n",
            "2020-08-06 07:13:44.242    0.998108  0.540902  0.551694    0  0.958322\n",
            "2020-08-06 07:13:56.289  0.00572213  0.540932  0.551686    0  0.951653\n",
            "...                             ...       ...       ...  ...       ...\n",
            "2020-08-06 16:02:45.713    0.999252   0.54098  0.551676    0  0.457905\n",
            "2020-08-06 16:02:57.784    0.996963  0.540951  0.551683    0  0.457905\n",
            "2020-08-06 16:03:55.777    0.994675  0.540866  0.551703    0  0.460684\n",
            "2020-08-06 16:04:10.278    0.994675  0.540864  0.551703    0  0.609614\n",
            "2020-08-06 16:04:27.227    0.994675  0.540863  0.551702    0  0.734649\n",
            "\n",
            "[373 rows x 5 columns]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eq80h-_Tcgk",
        "outputId": "545cdbc7-fd58-4da9-c830-f2941ba2048f"
      },
      "source": [
        "#Resampling/Interpolating\n",
        "norm_train_df = pd.DataFrame()\n",
        "norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "norm_train_df['Trak'] = train_input.Trak.resample('5T').last()\n",
        "norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "norm_train_df['Trak'] = pd.to_numeric(norm_train_df['Trak'], errors='coerce')\n",
        "norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "norm_train_df.reset_index(inplace = True)\n",
        "norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "norm_train_df = norm_train_df.iloc[0:73]\n",
        "print(norm_train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Time       Lat      Long       Alt      Trak\n",
            "0  2020-08-06 07:10:00  0.541109  0.551641  0.026703  0.973882\n",
            "1  2020-08-06 07:15:00  0.542472  0.552251  0.217823  0.093081\n",
            "2  2020-08-06 07:20:00  0.544178  0.553254  0.402075  0.092526\n",
            "3  2020-08-06 07:25:00  0.546072  0.554713  0.501640  0.135871\n",
            "4  2020-08-06 07:30:00  0.547895  0.556523  0.586328  0.133093\n",
            "..                 ...       ...       ...       ...       ...\n",
            "68 2020-08-06 12:50:00  0.575555  0.585123  0.000000  1.864393\n",
            "69 2020-08-06 12:55:00  0.575441  0.584925  0.000000  1.838877\n",
            "70 2020-08-06 13:00:00  0.575300  0.584686  0.000000  1.807243\n",
            "71 2020-08-06 13:05:00  0.575129  0.584407  0.000000  1.769276\n",
            "72 2020-08-06 13:10:00  0.574928  0.584084  0.000000  1.724758\n",
            "\n",
            "[73 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIemSNkgTcgl",
        "outputId": "0b0f2ddb-87c1-42e2-dca5-768b61bfec11"
      },
      "source": [
        "#add species to label list\n",
        "train_labels = []\n",
        "train_labels.append(unique_species)\n",
        "print(train_labels)\n",
        "#convert dataframe to numpy\n",
        "norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "norm_train_df = norm_train_df.to_numpy()\n",
        "print(norm_train_df)\n",
        "final_input_train = norm_train_df\n",
        "print(final_input_train.shape)\n",
        "final_input_train = np.reshape(final_input_train, (1,73,4))\n",
        "print(final_input_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[0.54110926 0.55164051 0.02670329 0.97388166]\n",
            " [0.54247236 0.55225104 0.21782254 0.09308141]\n",
            " [0.54417837 0.55325353 0.40207523 0.0925257 ]\n",
            " [0.54607177 0.55471271 0.50164034 0.13587108]\n",
            " [0.54789543 0.5565232  0.58632792 0.13309254]\n",
            " [0.54969102 0.55826527 0.59510185 0.13225895]\n",
            " [0.55004507 0.55860418 0.59510185 0.13225895]\n",
            " [0.55061809 0.55913722 0.60817557 0.12630752]\n",
            " [0.55184827 0.56027639 0.62872997 0.11537143]\n",
            " [0.55359598 0.56188938 0.65039623 0.10220479]\n",
            " [0.55572157 0.5638439  0.66680553 0.08956167]\n",
            " [0.55808541 0.56600764 0.67158908 0.08019615]\n",
            " [0.56054785 0.56824831 0.65837804 0.07686233]\n",
            " [0.56296924 0.5704336  0.62080362 0.08231428]\n",
            " [0.56520995 0.57243121 0.55249699 0.09930609]\n",
            " [0.56713033 0.57410884 0.44708934 0.13059184]\n",
            " [0.56859511 0.57544625 0.30861372 0.15837733]\n",
            " [0.56961566 0.57667202 0.17662318 0.13059184]\n",
            " [0.57040614 0.5773856  0.08812085 0.12725757]\n",
            " [0.57044345 0.57741934 0.08392462 0.13281468]\n",
            " [0.57031141 0.57733422 0.09457798 0.14164659]\n",
            " [0.57020701 0.57728254 0.09927008 0.15497712]\n",
            " [0.57012913 0.57726283 0.09827373 0.17258963]\n",
            " [0.57007663 0.57727358 0.09186173 0.19426746]\n",
            " [0.57004836 0.5773133  0.0803069  0.21979396]\n",
            " [0.5700432  0.57738052 0.06388204 0.24895249]\n",
            " [0.57006001 0.57747373 0.04285995 0.28152638]\n",
            " [0.57009765 0.57759144 0.01751345 0.317299  ]\n",
            " [0.57015498 0.57773217 0.         0.35605369]\n",
            " [0.57023088 0.57789442 0.         0.39757379]\n",
            " [0.5703242  0.57807671 0.         0.44164267]\n",
            " [0.5704338  0.57827755 0.         0.48804367]\n",
            " [0.57055856 0.57849543 0.         0.53656013]\n",
            " [0.57069733 0.57872888 0.         0.58697542]\n",
            " [0.57084898 0.5789764  0.         0.63907287]\n",
            " [0.57101237 0.5792365  0.         0.69263584]\n",
            " [0.57118636 0.5795077  0.         0.74744768]\n",
            " [0.57136983 0.57978849 0.         0.80329174]\n",
            " [0.57156163 0.5800774  0.         0.85995136]\n",
            " [0.57176063 0.58037292 0.         0.91720991]\n",
            " [0.57196568 0.58067358 0.         0.97485071]\n",
            " [0.57217567 0.58097787 0.         1.03265714]\n",
            " [0.57238944 0.58128432 0.         1.09041253]\n",
            " [0.57260586 0.58159142 0.         1.14790023]\n",
            " [0.5728238  0.58189769 0.         1.20490361]\n",
            " [0.57304211 0.58220164 0.         1.26120599]\n",
            " [0.57325968 0.58250177 0.         1.31659074]\n",
            " [0.57347534 0.58279661 0.         1.37084121]\n",
            " [0.57368798 0.58308465 0.         1.42374073]\n",
            " [0.57389646 0.5833644  0.         1.47507268]\n",
            " [0.57409963 0.58363438 0.         1.52462038]\n",
            " [0.57429636 0.5838931  0.         1.5721672 ]\n",
            " [0.57448553 0.58413906 0.         1.61749648]\n",
            " [0.57466598 0.58437077 0.         1.66039157]\n",
            " [0.57483658 0.58458675 0.         1.70063583]\n",
            " [0.5749962  0.5847855  0.         1.73801259]\n",
            " [0.5751437  0.58496553 0.         1.77230522]\n",
            " [0.57527795 0.58512536 0.         1.80329706]\n",
            " [0.57539781 0.58526349 0.         1.83077146]\n",
            " [0.57550214 0.58537843 0.         1.85451177]\n",
            " [0.5755898  0.58546869 0.         1.87430133]\n",
            " [0.57565966 0.58553279 0.         1.88992351]\n",
            " [0.57571059 0.58556922 0.         1.90116165]\n",
            " [0.57574145 0.5855765  0.         1.9077991 ]\n",
            " [0.57575109 0.58555314 0.         1.9096192 ]\n",
            " [0.57573839 0.58549765 0.         1.90640531]\n",
            " [0.57570221 0.58540854 0.         1.89794078]\n",
            " [0.57564142 0.58528432 0.         1.88400896]\n",
            " [0.57555487 0.5851235  0.         1.8643932 ]\n",
            " [0.57544142 0.58492458 0.         1.83887684]\n",
            " [0.57529996 0.58468608 0.         1.80724323]\n",
            " [0.57512933 0.58440651 0.         1.76927574]\n",
            " [0.5749284  0.58408437 0.         1.7247577 ]]\n",
            "(73, 4)\n",
            "(1, 73, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ji19cJbTcgm",
        "outputId": "7c451f49-debc-4beb-e80d-ac36b5e28664"
      },
      "source": [
        "for j in range(2,16046):\n",
        "    try:\n",
        "        train_input = pd.DataFrame(data = train_df[j], columns = [\"Icao\",\"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\", \"Trak\"], index = None)\n",
        "        train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "        train_input = train_input.set_index('Time')\n",
        "        train_input = train_input.drop('PosTime', axis = 1)\n",
        "        unique_species = train_input.Type[0]\n",
        "        norm_train_df = pd.DataFrame()\n",
        "        norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "        norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Trak'] = train_input.Trak.resample('5T').last()\n",
        "        norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "        norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "        norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "        norm_train_df['Trak'] = pd.to_numeric(norm_train_df['Trak'], errors='coerce')\n",
        "        norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "        norm_train_df.reset_index(inplace = True)\n",
        "        norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "        norm_train_df = norm_train_df.iloc[0:73]\n",
        "        norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "        norm_train_df = norm_train_df.to_numpy()\n",
        "        norm_train_df = np.reshape(norm_train_df, (1,73,4))\n",
        "        final_input_train = np.append(final_input_train, norm_train_df, axis = 0)\n",
        "        train_labels.append(unique_species)\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "print(final_input_train.shape)\n",
        "print(len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10355, 73, 4)\n",
            "10355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Rgj4SmTcgn",
        "outputId": "567ae371-a1aa-4ed6-9ccc-6aca492974f6"
      },
      "source": [
        "final_input_test = final_input_train[7766:]\n",
        "arr = list(range(7766,final_input_train.shape[0] ))\n",
        "print(final_input_test.shape)\n",
        "\n",
        "final_input_train = np.delete(final_input_train, arr, 0)\n",
        "print(final_input_train.shape)\n",
        "\n",
        "test_labels = train_labels[7766:]\n",
        "print(len(test_labels))\n",
        "\n",
        "train_labels_final = train_labels[:7766]\n",
        "print(len(train_labels_final))\n",
        "\n",
        "unique = list(dict.fromkeys(test_labels))\n",
        "unique2 = list(dict.fromkeys(train_labels_final))\n",
        "print(unique)\n",
        "print(unique2)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "test_labels = to_categorical(test_labels,num_classes = 10)\n",
        "train_labels_final = to_categorical(train_labels_final,num_classes = 10)\n",
        "print(len(test_labels))\n",
        "print(len(train_labels_final))\n",
        "\n",
        "train_labels_final = np.array(train_labels_final)\n",
        "test_labels = np.array(test_labels)\n",
        "print(train_labels_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2589, 73, 4)\n",
            "(7766, 73, 4)\n",
            "2589\n",
            "7766\n",
            "[2, 6, 0, 1, 5, 3, 9, 8, 7, 4]\n",
            "[0, 1, 5, 7, 4, 3, 6, 2, 8, 9]\n",
            "2589\n",
            "7766\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7F-NyiBTcgo",
        "outputId": "30483037-ed3e-4ce8-90c2-e9132dae1437"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(final_input_train, train_labels_final, final_input_test, test_labels):\n",
        "    verbose, epochs, batch_size = 2, 100, 16\n",
        "    n_timesteps, n_features, n_outputs = final_input_train.shape[1], final_input_train.shape[2], 10\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # fit network\n",
        "    model.fit(final_input_train, train_labels_final, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle = True)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(final_input_test, test_labels, batch_size=batch_size, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "    print(scores)\n",
        "    m, s = np.mean(scores), np.std(scores)\n",
        "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats=2):\n",
        "    # load data\n",
        "    # repeat experiment\n",
        "    scores = list()\n",
        "    for r in range(repeats):\n",
        "        score = evaluate_model(final_input_train, train_labels_final, final_input_test, test_labels)\n",
        "        score = score * 100.0\n",
        "        print('>#%d: %.3f' % (r+1, score))\n",
        "        scores.append(score)\n",
        "    # summarize results\n",
        "    summarize_results(scores)\n",
        "\n",
        "run_experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "486/486 - 6s - loss: 2.1688 - accuracy: 0.3647\n",
            "Epoch 2/100\n",
            "486/486 - 5s - loss: 1.6422 - accuracy: 0.3976\n",
            "Epoch 3/100\n",
            "486/486 - 5s - loss: 1.5938 - accuracy: 0.4068\n",
            "Epoch 4/100\n",
            "486/486 - 5s - loss: 1.5794 - accuracy: 0.4190\n",
            "Epoch 5/100\n",
            "486/486 - 5s - loss: 1.5053 - accuracy: 0.4257\n",
            "Epoch 6/100\n",
            "486/486 - 5s - loss: 1.4852 - accuracy: 0.4318\n",
            "Epoch 7/100\n",
            "486/486 - 5s - loss: 1.4676 - accuracy: 0.4346\n",
            "Epoch 8/100\n",
            "486/486 - 5s - loss: 1.4562 - accuracy: 0.4417\n",
            "Epoch 9/100\n",
            "486/486 - 5s - loss: 1.4442 - accuracy: 0.4473\n",
            "Epoch 10/100\n",
            "486/486 - 5s - loss: 1.4186 - accuracy: 0.4548\n",
            "Epoch 11/100\n",
            "486/486 - 5s - loss: 1.3997 - accuracy: 0.4575\n",
            "Epoch 12/100\n",
            "486/486 - 5s - loss: 1.3766 - accuracy: 0.4661\n",
            "Epoch 13/100\n",
            "486/486 - 5s - loss: 1.3616 - accuracy: 0.4683\n",
            "Epoch 14/100\n",
            "486/486 - 5s - loss: 1.3412 - accuracy: 0.4811\n",
            "Epoch 15/100\n",
            "486/486 - 5s - loss: 1.3152 - accuracy: 0.4911\n",
            "Epoch 16/100\n",
            "486/486 - 5s - loss: 1.2909 - accuracy: 0.4990\n",
            "Epoch 17/100\n",
            "486/486 - 5s - loss: 1.2606 - accuracy: 0.5080\n",
            "Epoch 18/100\n",
            "486/486 - 5s - loss: 1.2391 - accuracy: 0.5169\n",
            "Epoch 19/100\n",
            "486/486 - 5s - loss: 1.2051 - accuracy: 0.5309\n",
            "Epoch 20/100\n",
            "486/486 - 5s - loss: 1.1738 - accuracy: 0.5430\n",
            "Epoch 21/100\n",
            "486/486 - 5s - loss: 1.1433 - accuracy: 0.5594\n",
            "Epoch 22/100\n",
            "486/486 - 5s - loss: 1.1016 - accuracy: 0.5689\n",
            "Epoch 23/100\n",
            "486/486 - 5s - loss: 1.0713 - accuracy: 0.5860\n",
            "Epoch 24/100\n",
            "486/486 - 5s - loss: 1.0295 - accuracy: 0.6062\n",
            "Epoch 25/100\n",
            "486/486 - 5s - loss: 0.9892 - accuracy: 0.6129\n",
            "Epoch 26/100\n",
            "486/486 - 5s - loss: 0.9534 - accuracy: 0.6243\n",
            "Epoch 27/100\n",
            "486/486 - 5s - loss: 0.9205 - accuracy: 0.6483\n",
            "Epoch 28/100\n",
            "486/486 - 5s - loss: 0.8917 - accuracy: 0.6561\n",
            "Epoch 29/100\n",
            "486/486 - 5s - loss: 0.8725 - accuracy: 0.6550\n",
            "Epoch 30/100\n",
            "486/486 - 5s - loss: 0.8378 - accuracy: 0.6750\n",
            "Epoch 31/100\n",
            "486/486 - 5s - loss: 0.8110 - accuracy: 0.6847\n",
            "Epoch 32/100\n",
            "486/486 - 5s - loss: 0.7752 - accuracy: 0.6951\n",
            "Epoch 33/100\n",
            "486/486 - 5s - loss: 0.7606 - accuracy: 0.7047\n",
            "Epoch 34/100\n",
            "486/486 - 5s - loss: 0.7345 - accuracy: 0.7172\n",
            "Epoch 35/100\n",
            "486/486 - 5s - loss: 0.7218 - accuracy: 0.7229\n",
            "Epoch 36/100\n",
            "486/486 - 5s - loss: 0.6866 - accuracy: 0.7297\n",
            "Epoch 37/100\n",
            "486/486 - 5s - loss: 0.6651 - accuracy: 0.7438\n",
            "Epoch 38/100\n",
            "486/486 - 5s - loss: 0.6640 - accuracy: 0.7477\n",
            "Epoch 39/100\n",
            "486/486 - 5s - loss: 0.6428 - accuracy: 0.7524\n",
            "Epoch 40/100\n",
            "486/486 - 5s - loss: 0.6277 - accuracy: 0.7619\n",
            "Epoch 41/100\n",
            "486/486 - 5s - loss: 0.6171 - accuracy: 0.7583\n",
            "Epoch 42/100\n",
            "486/486 - 5s - loss: 0.5808 - accuracy: 0.7756\n",
            "Epoch 43/100\n",
            "486/486 - 5s - loss: 0.5665 - accuracy: 0.7842\n",
            "Epoch 44/100\n",
            "486/486 - 5s - loss: 0.5521 - accuracy: 0.7866\n",
            "Epoch 45/100\n",
            "486/486 - 5s - loss: 0.5551 - accuracy: 0.7856\n",
            "Epoch 46/100\n",
            "486/486 - 5s - loss: 0.5338 - accuracy: 0.7906\n",
            "Epoch 47/100\n",
            "486/486 - 5s - loss: 0.5271 - accuracy: 0.7962\n",
            "Epoch 48/100\n",
            "486/486 - 5s - loss: 0.5099 - accuracy: 0.8070\n",
            "Epoch 49/100\n",
            "486/486 - 5s - loss: 0.5177 - accuracy: 0.8053\n",
            "Epoch 50/100\n",
            "486/486 - 5s - loss: 0.4883 - accuracy: 0.8174\n",
            "Epoch 51/100\n",
            "486/486 - 5s - loss: 0.4859 - accuracy: 0.8135\n",
            "Epoch 52/100\n",
            "486/486 - 5s - loss: 0.4599 - accuracy: 0.8237\n",
            "Epoch 53/100\n",
            "486/486 - 5s - loss: 0.4476 - accuracy: 0.8313\n",
            "Epoch 54/100\n",
            "486/486 - 5s - loss: 0.4510 - accuracy: 0.8336\n",
            "Epoch 55/100\n",
            "486/486 - 5s - loss: 0.4444 - accuracy: 0.8344\n",
            "Epoch 56/100\n",
            "486/486 - 5s - loss: 0.4286 - accuracy: 0.8414\n",
            "Epoch 57/100\n",
            "486/486 - 5s - loss: 0.4225 - accuracy: 0.8412\n",
            "Epoch 58/100\n",
            "486/486 - 5s - loss: 0.4208 - accuracy: 0.8446\n",
            "Epoch 59/100\n",
            "486/486 - 5s - loss: 0.4163 - accuracy: 0.8423\n",
            "Epoch 60/100\n",
            "486/486 - 5s - loss: 0.4135 - accuracy: 0.8389\n",
            "Epoch 61/100\n",
            "486/486 - 5s - loss: 0.4055 - accuracy: 0.8490\n",
            "Epoch 62/100\n",
            "486/486 - 5s - loss: 0.3919 - accuracy: 0.8550\n",
            "Epoch 63/100\n",
            "486/486 - 5s - loss: 0.4023 - accuracy: 0.8475\n",
            "Epoch 64/100\n",
            "486/486 - 5s - loss: 0.3915 - accuracy: 0.8562\n",
            "Epoch 65/100\n",
            "486/486 - 5s - loss: 0.3665 - accuracy: 0.8638\n",
            "Epoch 66/100\n",
            "486/486 - 5s - loss: 0.3943 - accuracy: 0.8603\n",
            "Epoch 67/100\n",
            "486/486 - 5s - loss: 0.3499 - accuracy: 0.8698\n",
            "Epoch 68/100\n",
            "486/486 - 5s - loss: 0.3644 - accuracy: 0.8665\n",
            "Epoch 69/100\n",
            "486/486 - 5s - loss: 0.3799 - accuracy: 0.8640\n",
            "Epoch 70/100\n",
            "486/486 - 5s - loss: 0.3500 - accuracy: 0.8720\n",
            "Epoch 71/100\n",
            "486/486 - 5s - loss: 0.3464 - accuracy: 0.8679\n",
            "Epoch 72/100\n",
            "486/486 - 5s - loss: 0.3240 - accuracy: 0.8820\n",
            "Epoch 73/100\n",
            "486/486 - 5s - loss: 0.3083 - accuracy: 0.8835\n",
            "Epoch 74/100\n",
            "486/486 - 5s - loss: 0.3494 - accuracy: 0.8710\n",
            "Epoch 75/100\n",
            "486/486 - 5s - loss: 0.3167 - accuracy: 0.8806\n",
            "Epoch 76/100\n",
            "486/486 - 5s - loss: 0.3252 - accuracy: 0.8793\n",
            "Epoch 77/100\n",
            "486/486 - 5s - loss: 0.3322 - accuracy: 0.8781\n",
            "Epoch 78/100\n",
            "486/486 - 5s - loss: 0.3309 - accuracy: 0.8809\n",
            "Epoch 79/100\n",
            "486/486 - 5s - loss: 0.3140 - accuracy: 0.8818\n",
            "Epoch 80/100\n",
            "486/486 - 5s - loss: 0.2998 - accuracy: 0.8854\n",
            "Epoch 81/100\n",
            "486/486 - 5s - loss: 0.3021 - accuracy: 0.8884\n",
            "Epoch 82/100\n",
            "486/486 - 5s - loss: 0.3120 - accuracy: 0.8849\n",
            "Epoch 83/100\n",
            "486/486 - 5s - loss: 0.2974 - accuracy: 0.8911\n",
            "Epoch 84/100\n",
            "486/486 - 5s - loss: 0.3136 - accuracy: 0.8833\n",
            "Epoch 85/100\n",
            "486/486 - 5s - loss: 0.2708 - accuracy: 0.9001\n",
            "Epoch 86/100\n",
            "486/486 - 5s - loss: 0.3049 - accuracy: 0.8882\n",
            "Epoch 87/100\n",
            "486/486 - 5s - loss: 0.2919 - accuracy: 0.8952\n",
            "Epoch 88/100\n",
            "486/486 - 5s - loss: 0.2893 - accuracy: 0.8930\n",
            "Epoch 89/100\n",
            "486/486 - 5s - loss: 0.3013 - accuracy: 0.8913\n",
            "Epoch 90/100\n",
            "486/486 - 5s - loss: 0.2867 - accuracy: 0.8961\n",
            "Epoch 91/100\n",
            "486/486 - 5s - loss: 0.2789 - accuracy: 0.8987\n",
            "Epoch 92/100\n",
            "486/486 - 5s - loss: 0.2720 - accuracy: 0.9043\n",
            "Epoch 93/100\n",
            "486/486 - 5s - loss: 0.2531 - accuracy: 0.9081\n",
            "Epoch 94/100\n",
            "486/486 - 5s - loss: 0.2872 - accuracy: 0.8961\n",
            "Epoch 95/100\n",
            "486/486 - 5s - loss: 0.2892 - accuracy: 0.8935\n",
            "Epoch 96/100\n",
            "486/486 - 5s - loss: 0.2379 - accuracy: 0.9137\n",
            "Epoch 97/100\n",
            "486/486 - 5s - loss: 0.4284 - accuracy: 0.9015\n",
            "Epoch 98/100\n",
            "486/486 - 5s - loss: 0.2721 - accuracy: 0.9045\n",
            "Epoch 99/100\n",
            "486/486 - 5s - loss: 0.2725 - accuracy: 0.8996\n",
            "Epoch 100/100\n",
            "486/486 - 5s - loss: 0.2378 - accuracy: 0.9127\n",
            ">#1: 36.076\n",
            "Epoch 1/100\n",
            "486/486 - 5s - loss: 2.1141 - accuracy: 0.3577\n",
            "Epoch 2/100\n",
            "486/486 - 5s - loss: 1.9448 - accuracy: 0.3940\n",
            "Epoch 3/100\n",
            "486/486 - 5s - loss: 1.7793 - accuracy: 0.3997\n",
            "Epoch 4/100\n",
            "486/486 - 5s - loss: 1.6510 - accuracy: 0.4096\n",
            "Epoch 5/100\n",
            "486/486 - 5s - loss: 1.5329 - accuracy: 0.4187\n",
            "Epoch 6/100\n",
            "486/486 - 5s - loss: 1.5563 - accuracy: 0.4209\n",
            "Epoch 7/100\n",
            "486/486 - 5s - loss: 1.5129 - accuracy: 0.4280\n",
            "Epoch 8/100\n",
            "486/486 - 5s - loss: 1.5393 - accuracy: 0.4289\n",
            "Epoch 9/100\n",
            "486/486 - 5s - loss: 1.4924 - accuracy: 0.4339\n",
            "Epoch 10/100\n",
            "486/486 - 5s - loss: 1.4588 - accuracy: 0.4441\n",
            "Epoch 11/100\n",
            "486/486 - 5s - loss: 1.4506 - accuracy: 0.4458\n",
            "Epoch 12/100\n",
            "486/486 - 5s - loss: 1.4446 - accuracy: 0.4454\n",
            "Epoch 13/100\n",
            "486/486 - 5s - loss: 1.4296 - accuracy: 0.4557\n",
            "Epoch 14/100\n",
            "486/486 - 5s - loss: 1.4133 - accuracy: 0.4616\n",
            "Epoch 15/100\n",
            "486/486 - 5s - loss: 1.4803 - accuracy: 0.4571\n",
            "Epoch 16/100\n",
            "486/486 - 5s - loss: 1.3915 - accuracy: 0.4620\n",
            "Epoch 17/100\n",
            "486/486 - 5s - loss: 1.3588 - accuracy: 0.4768\n",
            "Epoch 18/100\n",
            "486/486 - 5s - loss: 1.3599 - accuracy: 0.4806\n",
            "Epoch 19/100\n",
            "486/486 - 5s - loss: 1.3242 - accuracy: 0.4885\n",
            "Epoch 20/100\n",
            "486/486 - 5s - loss: 1.2960 - accuracy: 0.4964\n",
            "Epoch 21/100\n",
            "486/486 - 5s - loss: 1.2656 - accuracy: 0.5088\n",
            "Epoch 22/100\n",
            "486/486 - 5s - loss: 1.2587 - accuracy: 0.5131\n",
            "Epoch 23/100\n",
            "486/486 - 5s - loss: 1.2148 - accuracy: 0.5267\n",
            "Epoch 24/100\n",
            "486/486 - 5s - loss: 1.1943 - accuracy: 0.5328\n",
            "Epoch 25/100\n",
            "486/486 - 5s - loss: 1.1466 - accuracy: 0.5525\n",
            "Epoch 26/100\n",
            "486/486 - 5s - loss: 1.1207 - accuracy: 0.5649\n",
            "Epoch 27/100\n",
            "486/486 - 5s - loss: 1.0918 - accuracy: 0.5771\n",
            "Epoch 28/100\n",
            "486/486 - 5s - loss: 1.0575 - accuracy: 0.5881\n",
            "Epoch 29/100\n",
            "486/486 - 5s - loss: 1.0193 - accuracy: 0.6092\n",
            "Epoch 30/100\n",
            "486/486 - 5s - loss: 0.9929 - accuracy: 0.6125\n",
            "Epoch 31/100\n",
            "486/486 - 5s - loss: 0.9681 - accuracy: 0.6223\n",
            "Epoch 32/100\n",
            "486/486 - 5s - loss: 0.9319 - accuracy: 0.6440\n",
            "Epoch 33/100\n",
            "486/486 - 5s - loss: 0.8930 - accuracy: 0.6505\n",
            "Epoch 34/100\n",
            "486/486 - 5s - loss: 0.8697 - accuracy: 0.6756\n",
            "Epoch 35/100\n",
            "486/486 - 5s - loss: 0.8581 - accuracy: 0.6769\n",
            "Epoch 36/100\n",
            "486/486 - 5s - loss: 0.8182 - accuracy: 0.6850\n",
            "Epoch 37/100\n",
            "486/486 - 5s - loss: 0.7909 - accuracy: 0.6937\n",
            "Epoch 38/100\n",
            "486/486 - 5s - loss: 0.7683 - accuracy: 0.7077\n",
            "Epoch 39/100\n",
            "486/486 - 5s - loss: 0.7637 - accuracy: 0.7058\n",
            "Epoch 40/100\n",
            "486/486 - 5s - loss: 0.7498 - accuracy: 0.7167\n",
            "Epoch 41/100\n",
            "486/486 - 5s - loss: 0.7001 - accuracy: 0.7327\n",
            "Epoch 42/100\n",
            "486/486 - 5s - loss: 0.6916 - accuracy: 0.7360\n",
            "Epoch 43/100\n",
            "486/486 - 5s - loss: 0.6674 - accuracy: 0.7481\n",
            "Epoch 44/100\n",
            "486/486 - 5s - loss: 0.6676 - accuracy: 0.7385\n",
            "Epoch 45/100\n",
            "486/486 - 5s - loss: 0.7159 - accuracy: 0.7398\n",
            "Epoch 46/100\n",
            "486/486 - 5s - loss: 0.6246 - accuracy: 0.7613\n",
            "Epoch 47/100\n",
            "486/486 - 5s - loss: 0.6053 - accuracy: 0.7703\n",
            "Epoch 48/100\n",
            "486/486 - 5s - loss: 0.5792 - accuracy: 0.7784\n",
            "Epoch 49/100\n",
            "486/486 - 5s - loss: 0.5642 - accuracy: 0.7905\n",
            "Epoch 50/100\n",
            "486/486 - 5s - loss: 0.5624 - accuracy: 0.7873\n",
            "Epoch 51/100\n",
            "486/486 - 5s - loss: 0.5561 - accuracy: 0.7915\n",
            "Epoch 52/100\n",
            "486/486 - 5s - loss: 0.5454 - accuracy: 0.7938\n",
            "Epoch 53/100\n",
            "486/486 - 5s - loss: 0.5143 - accuracy: 0.8011\n",
            "Epoch 54/100\n",
            "486/486 - 5s - loss: 0.5039 - accuracy: 0.8101\n",
            "Epoch 55/100\n",
            "486/486 - 5s - loss: 0.5097 - accuracy: 0.8105\n",
            "Epoch 56/100\n",
            "486/486 - 5s - loss: 0.4912 - accuracy: 0.8090\n",
            "Epoch 57/100\n",
            "486/486 - 5s - loss: 0.4756 - accuracy: 0.8266\n",
            "Epoch 58/100\n",
            "486/486 - 5s - loss: 0.4746 - accuracy: 0.8242\n",
            "Epoch 59/100\n",
            "486/486 - 5s - loss: 0.4791 - accuracy: 0.8231\n",
            "Epoch 60/100\n",
            "486/486 - 5s - loss: 0.4530 - accuracy: 0.8290\n",
            "Epoch 61/100\n",
            "486/486 - 5s - loss: 0.4546 - accuracy: 0.8285\n",
            "Epoch 62/100\n",
            "486/486 - 5s - loss: 0.4536 - accuracy: 0.8314\n",
            "Epoch 63/100\n",
            "486/486 - 5s - loss: 0.4288 - accuracy: 0.8388\n",
            "Epoch 64/100\n",
            "486/486 - 5s - loss: 0.4200 - accuracy: 0.8425\n",
            "Epoch 65/100\n",
            "486/486 - 5s - loss: 0.4186 - accuracy: 0.8434\n",
            "Epoch 66/100\n",
            "486/486 - 5s - loss: 0.4114 - accuracy: 0.8477\n",
            "Epoch 67/100\n",
            "486/486 - 5s - loss: 0.4111 - accuracy: 0.8479\n",
            "Epoch 68/100\n",
            "486/486 - 5s - loss: 0.4186 - accuracy: 0.8405\n",
            "Epoch 69/100\n",
            "486/486 - 5s - loss: 0.3878 - accuracy: 0.8572\n",
            "Epoch 70/100\n",
            "486/486 - 5s - loss: 0.3884 - accuracy: 0.8575\n",
            "Epoch 71/100\n",
            "486/486 - 5s - loss: 0.3812 - accuracy: 0.8573\n",
            "Epoch 72/100\n",
            "486/486 - 5s - loss: 0.3667 - accuracy: 0.8666\n",
            "Epoch 73/100\n",
            "486/486 - 5s - loss: 0.3743 - accuracy: 0.8623\n",
            "Epoch 74/100\n",
            "486/486 - 5s - loss: 0.3653 - accuracy: 0.8635\n",
            "Epoch 75/100\n",
            "486/486 - 5s - loss: 0.3663 - accuracy: 0.8618\n",
            "Epoch 76/100\n",
            "486/486 - 5s - loss: 0.3662 - accuracy: 0.8649\n",
            "Epoch 77/100\n",
            "486/486 - 5s - loss: 0.3623 - accuracy: 0.8680\n",
            "Epoch 78/100\n",
            "486/486 - 5s - loss: 0.3547 - accuracy: 0.8734\n",
            "Epoch 79/100\n",
            "486/486 - 5s - loss: 0.3518 - accuracy: 0.8688\n",
            "Epoch 80/100\n",
            "486/486 - 5s - loss: 0.3450 - accuracy: 0.8766\n",
            "Epoch 81/100\n",
            "486/486 - 5s - loss: 0.3516 - accuracy: 0.8694\n",
            "Epoch 82/100\n",
            "486/486 - 5s - loss: 0.3263 - accuracy: 0.8813\n",
            "Epoch 83/100\n",
            "486/486 - 5s - loss: 0.3326 - accuracy: 0.8808\n",
            "Epoch 84/100\n",
            "486/486 - 5s - loss: 0.3200 - accuracy: 0.8830\n",
            "Epoch 85/100\n",
            "486/486 - 5s - loss: 0.3330 - accuracy: 0.8763\n",
            "Epoch 86/100\n",
            "486/486 - 5s - loss: 0.3365 - accuracy: 0.8793\n",
            "Epoch 87/100\n",
            "486/486 - 5s - loss: 0.3230 - accuracy: 0.8854\n",
            "Epoch 88/100\n",
            "486/486 - 5s - loss: 0.3176 - accuracy: 0.8905\n",
            "Epoch 89/100\n",
            "486/486 - 5s - loss: 0.3119 - accuracy: 0.8878\n",
            "Epoch 90/100\n",
            "486/486 - 5s - loss: 0.3189 - accuracy: 0.8819\n",
            "Epoch 91/100\n",
            "486/486 - 5s - loss: 0.3026 - accuracy: 0.8921\n",
            "Epoch 92/100\n",
            "486/486 - 5s - loss: 0.3163 - accuracy: 0.8925\n",
            "Epoch 93/100\n",
            "486/486 - 5s - loss: 0.3019 - accuracy: 0.8914\n",
            "Epoch 94/100\n",
            "486/486 - 5s - loss: 0.2983 - accuracy: 0.8868\n",
            "Epoch 95/100\n",
            "486/486 - 5s - loss: 0.2905 - accuracy: 0.8952\n",
            "Epoch 96/100\n",
            "486/486 - 5s - loss: 0.2980 - accuracy: 0.8904\n",
            "Epoch 97/100\n",
            "486/486 - 5s - loss: 0.3007 - accuracy: 0.8960\n",
            "Epoch 98/100\n",
            "486/486 - 5s - loss: 0.2868 - accuracy: 0.8998\n",
            "Epoch 99/100\n",
            "486/486 - 5s - loss: 0.2923 - accuracy: 0.8925\n",
            "Epoch 100/100\n",
            "486/486 - 5s - loss: 0.2919 - accuracy: 0.8965\n",
            ">#2: 36.694\n",
            "[36.0757052898407, 36.69370412826538]\n",
            "Accuracy: 36.385% (+/-0.309)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}