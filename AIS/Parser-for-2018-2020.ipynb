{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unexpected-juvenile",
   "metadata": {},
   "source": [
    "# This file can be used to parse through the marine cadastre website for years 2018-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moving-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import math\n",
    "#REMEMBER ONLY CLICK ON THIS ONCE\n",
    "max_lat = []\n",
    "min_lat = []\n",
    "max_lon = []\n",
    "min_lon = []\n",
    "max_sog = []\n",
    "min_sog = []\n",
    "max_cog = []\n",
    "min_cog = []\n",
    "\n",
    "\n",
    "directory = glob.glob(r\"E:\\Capstone\\New_AIS_Data\\2020\\*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vietnamese-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in directory:\n",
    "    cols = [\"MMSI\", \"BaseDateTime\", \"LAT\", \"LON\", \"SOG\", \"COG\", \"VesselType\", \"Status\"]\n",
    "    train_df = dd.read_csv(file, parse_dates = ['BaseDateTime'], dtype={'Cargo': 'float64','VesselType': 'float64', 'LAT': 'float32', 'LON': 'float32', 'SOG': 'float32', 'COG': 'float32'}, usecols = cols)\n",
    "    train_df = train_df.compute()\n",
    "    #drop all rows not in Zone 19\n",
    "    train_df[\"Zone\"] = train_df[\"LON\"].apply(lambda x: (math.floor((x+180)/6) % 60) +1)\n",
    "    train_df = train_df[train_df['Zone'] == 19]\n",
    "    #drop the rows where there's no data for 'MMSI', 'BaseDateTime', 'LAT', 'SOG', 'LON', 'COG', 'VesselType'\n",
    "    train_df = train_df.dropna(subset=['MMSI', 'BaseDateTime', 'LAT', 'SOG', 'LON', 'COG', 'VesselType'])\n",
    "    #Change datatypes to shrink size of data frame\n",
    "    train_df['MMSI'] = pd.to_numeric(train_df['MMSI'], downcast='unsigned')\n",
    "    train_df['LAT'] = pd.to_numeric(train_df['LAT'], downcast='float')\n",
    "    train_df['LON'] = pd.to_numeric(train_df['LON'], downcast='float')\n",
    "    train_df['SOG'] = pd.to_numeric(train_df['SOG'], downcast='float')\n",
    "    train_df['COG'] = pd.to_numeric(train_df['COG'], downcast='float')\n",
    "    train_df['VesselType'] = pd.to_numeric(train_df['VesselType'], downcast='unsigned')\n",
    "\n",
    "\n",
    "    #Arrange in order of the MMSI number\n",
    "    train_df = train_df.sort_values(by=['MMSI', 'BaseDateTime'])\n",
    "\n",
    "    #remove any improper MMSIs (those whose length isn't 9)\n",
    "    train_df.MMSI = train_df.MMSI.astype('str')\n",
    "    train_df['MMLength'] = train_df.MMSI.str.len()\n",
    "    index_names = train_df[ train_df['MMLength'] != 9 ].index \n",
    "    train_df.drop(index_names, inplace = True)\n",
    "    train_df = train_df.drop('MMLength', axis = 1)\n",
    "\n",
    "    #remove those at anchor and moored\n",
    "    index_names2 = train_df[ train_df['Status'] == 'at anchor' ].index \n",
    "    train_df.drop(index_names2, inplace = True)\n",
    "    index_names3 = train_df[ train_df['Status'] == 'moored' ].index\n",
    "    train_df.drop(index_names3, inplace = True)\n",
    "    train_df = train_df.drop('Status', axis = 1)\n",
    "\n",
    "    #remove those with improper vessel types\n",
    "    index_names3 = train_df[ train_df['VesselType'] == 0].index\n",
    "    train_df.drop(index_names3, inplace = True)\n",
    "\n",
    "    #remove rows that only occur once\n",
    "    train_df = train_df[train_df.groupby('MMSI').MMSI.transform(len) > 99]\n",
    "\n",
    "\n",
    "    #reset the indices\n",
    "    train_df = train_df.reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "    #convert Vessel Type to categories\n",
    "    # 0=Cargo, 1=Fishing, 2=Tug Tow, 3=Other, 4=Passenger, 5=PleasureCraft/Sailing, 6=Tanker, 7=Military\n",
    "    preserved_titles = [1004,1003,70,71,72,73,74,75,76,77,78,79,30,1001,1002,1021,60,61,62,63,64,65,66,67,68,69,1012,1013,1014,1015,1019,36,37,\n",
    "                       80,81,82,83,84,85,86,87,88,89,1024,21,22,31,32,52,1023,1025,20,23,24,25,26,27,28,29,40,41,42,43,44,45,46,47,48,49]\n",
    "    train_df.loc[~train_df['VesselType'].isin(preserved_titles), 'VesselType'] = 3\n",
    "    train_df['VesselType'].replace([1004,1003,70,71,72,73,74,75,76,77,78,79],0, inplace = True)\n",
    "    train_df['VesselType'].replace([30,1001,1002],1, inplace = True)\n",
    "    train_df['VesselType'].replace([1021],7, inplace = True)\n",
    "    train_df['VesselType'].replace([60,61,62,63,64,65,66,67,68,69,1012,1013,1014,1015],4, inplace = True)\n",
    "    train_df['VesselType'].replace([1019,36,37],5, inplace = True)\n",
    "    train_df['VesselType'].replace([80,81,82,83,84,85,86,87,88,89,1024],6, inplace = True)\n",
    "    train_df['VesselType'].replace([21,22,31,32,52,1023,1025],2, inplace = True)\n",
    "    train_df['VesselType'].replace([20,23,24,25,26,27,28,29],3, inplace = True)\n",
    "    train_df['VesselType'].replace([40,41,42,43,44,45,46,47,48,49],3, inplace = True)\n",
    "    train_df['VesselType'] = pd.to_numeric(train_df['VesselType'], downcast='unsigned')\n",
    "\n",
    "    #get number of categories\n",
    "    #if you remove the .index from the next line you get a series, which you can normalize to get a percentage of data\n",
    "    cat_num = train_df['VesselType'].value_counts().index\n",
    "\n",
    "\n",
    "\n",
    "    train_df['MMSI'] = pd.to_numeric(train_df['MMSI'], downcast='unsigned')\n",
    "    \n",
    "    max_lat_train = train_df['LAT'].max()\n",
    "    min_lat_train = train_df['LAT'].min()\n",
    "    max_lon_train = train_df['LON'].max()\n",
    "    min_lon_train = train_df['LON'].min()\n",
    "    max_sog_train = train_df['SOG'].max()\n",
    "    min_sog_train = train_df['SOG'].min()\n",
    "    max_cog_train = train_df['COG'].max()\n",
    "    min_cog_train = train_df['COG'].min()\n",
    "    \n",
    "    \n",
    "    max_lat.append(max_lat_train)\n",
    "    min_lat.append(min_lat_train)\n",
    "    max_lon.append(max_lon_train)\n",
    "    min_lon.append(min_lon_train)\n",
    "    max_sog.append(max_sog_train)\n",
    "    min_sog.append(min_sog_train)\n",
    "    max_cog.append(max_cog_train)\n",
    "    min_cog.append(min_cog_train)\n",
    "    \n",
    "    train_df = train_df.drop('Zone', axis = 1)\n",
    "    train_df.to_csv (r\"E:\\Capstone\\New_AIS_Data\\Shrunken_AIS_Data_2020\\{}\".format(file[30:]), index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "stock-affair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_lat\n",
      "89.96446\n",
      "max_lon\n",
      "-66.00001\n",
      "max_sog\n",
      "51.1\n",
      "max_cog\n",
      "204.7\n",
      "min_lat\n",
      "0.0001\n",
      "min_lon\n",
      "-72.0\n",
      "min_sog\n",
      "-51.2\n",
      "min_cog\n",
      "-204.8\n"
     ]
    }
   ],
   "source": [
    "print(\"max_lat\")\n",
    "print(max(max_lat))\n",
    "print(\"max_lon\")\n",
    "print(max(max_lon))\n",
    "print(\"max_sog\")\n",
    "print(max(max_sog))\n",
    "print(\"max_cog\")\n",
    "print(max(max_cog))\n",
    "print(\"min_lat\")\n",
    "print(min(min_lat))\n",
    "print(\"min_lon\")\n",
    "print(min(min_lon))\n",
    "print(\"min_sog\")\n",
    "print(min(min_sog))\n",
    "print(\"min_cog\")\n",
    "print(min(min_cog))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
