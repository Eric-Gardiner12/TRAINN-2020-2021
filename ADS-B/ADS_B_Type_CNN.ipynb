{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADS-B-Type-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5bwdvvbkZU7B",
        "fkBxelStTcgB",
        "62w-aOTd6cKr",
        "nEVQnpvnjXCn",
        "-Apwt4NxZuMr",
        "LLgQThZKuUKG",
        "2LTmRsnAsNbP",
        "wA484-i0GIhl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox64VPifHR5p"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UXW_rVLyuDU"
      },
      "source": [
        "Allows for Google Colab to access Drive Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTTEfIKk0gtm",
        "outputId": "dfe1e7d8-d973-4208-9dbb-92ac19093955"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0M6Zj2Vy6cr"
      },
      "source": [
        "Installs requirements for dask dataframe and rocket model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4hFAqqx01VA",
        "outputId": "d0f2b8de-771f-4d82-ec8b-093d060c1d79"
      },
      "source": [
        "!pip install dask[dataframe]\n",
        "#!pip install --upgrade numba\n",
        "#!pip install sktime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Collecting fsspec>=0.6.0; extra == \"dataframe\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.1)\n",
            "Collecting partd>=0.3.10; extra == \"dataframe\"\n",
            "  Downloading https://files.pythonhosted.org/packages/41/94/360258a68b55f47859d72b2d0b2b3cfe0ca4fbbcb81b78812bd00ae86b7c/partd-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.23.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n",
            "Collecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (1.15.0)\n",
            "Installing collected packages: fsspec, locket, partd\n",
            "Successfully installed fsspec-2021.4.0 locket-0.2.1 partd-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWZA2pXazDjZ"
      },
      "source": [
        "Loads in all data as 1 pandas dataframe (usually take a bit to execute)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbgeFIVk04Mu",
        "outputId": "7ffee12e-f884-48d5-decb-7da009412bc5"
      },
      "source": [
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "file = '/content/drive/MyDrive/parsed_adsb_csvs_types/*.csv'\n",
        "#file = '/content/drive/MyDrive/testtest/parsed_adsb_csvs_types-20210407T164239Z-001.zip (Unzipped Files)/parsed_adsb_csvs_types/*.csv'\n",
        "#file = '/content/drive/MyDrive/testtest/*.csv'\n",
        "cols = ['Icao','Alt', 'Lat','Long', 'PosTime', 'Type']\n",
        "# read data frame from csv files\n",
        "train_df = dd.read_csv(file, dtype = {'Alt': 'uint16', 'Lat': 'float32', 'Long': 'float32', 'PosTime': 'int64'}, usecols = cols) \n",
        "\n",
        "train_df = train_df.compute()\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Icao    Alt        Lat        Long        PosTime  Type\n",
            "0      A82B72   3500  39.717903  -84.619019  1596672029381  C172\n",
            "1      A80E46  31000  61.336498 -140.995438  1596672028022  B748\n",
            "2      A4E2E5    700  42.145557  -72.719398  1596672029830  C140\n",
            "3      A4BDB9  15600  33.516727  -79.442421  1596672029378  E170\n",
            "4      A4C3CE    650  32.965118  -96.833878  1596672030885  CRUZ\n",
            "...       ...    ...        ...         ...            ...   ...\n",
            "21531  C821F8  17975 -41.125225  175.051468  1596758412576  AT76\n",
            "21532  C8234A  18500 -37.852840  174.806625  1596758411374  A320\n",
            "21533  ACC040  28000  42.272324  -87.846115  1596758411880  CRJ9\n",
            "21534  A7D222   6900  29.646700  -98.126343  1596757702853  BE36\n",
            "21535  345292  32000  51.857941    5.114062  1596758411877  B734\n",
            "\n",
            "[29550434 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duv2nVMWzRk9"
      },
      "source": [
        "Arrange in order of the Icao number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xftglcmg2Q1Y",
        "outputId": "20e6b20f-d3b0-4217-ffaf-29edda27cad1"
      },
      "source": [
        "\n",
        "train_df = train_df.sort_values(by=['Icao', 'PosTime'])\n",
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao   Alt        Lat       Long        PosTime  Type\n",
            "0         001000  2175  48.106934  11.258926  1596721377840  SIRA\n",
            "1         001000  2175  48.106934  11.258926  1596721392353  SIRA\n",
            "2         001000  2175  48.106934  11.258926  1596721394847  SIRA\n",
            "3         001000  2175  48.109818  11.264557  1596721444191  SIRA\n",
            "4         001000  2175  48.105652  11.257416  1596721470866  SIRA\n",
            "...          ...   ...        ...        ...            ...   ...\n",
            "29550429  F00000   450  49.149822   2.394817  1596742711592  SKRA\n",
            "29550430  F00000   300  49.149822   2.394817  1596742711592  SKRA\n",
            "29550431  F00000   200  49.149822   2.394817  1596742711592  SKRA\n",
            "29550432  F00000   175  49.149822   2.394817  1596742711592  SKRA\n",
            "29550433  F00000   175  49.149822   2.394817  1596742711592  SKRA\n",
            "\n",
            "[29550434 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I1wWRBgzXm6"
      },
      "source": [
        "Perform min- max normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVApr6Rv2gKG",
        "outputId": "e141682b-e422-4849-9900-15da5e84a6c4"
      },
      "source": [
        "max_lat = train_df['Lat'].max()\n",
        "min_lat = train_df['Lat'].min()\n",
        "max_lon = train_df['Long'].max()\n",
        "min_lon = train_df['Long'].min()\n",
        "max_alt = train_df['Alt'].max()\n",
        "min_alt = train_df['Alt'].min()\n",
        "\n",
        "\n",
        "train_df['Lat'] = (train_df['Lat']- min_lat) / (max_lat - min_lat)\n",
        "train_df['Long'] = (train_df['Long']- min_lon) / (max_lon - min_lon)\n",
        "train_df['Alt'] = (train_df['Alt']- min_alt) / (max_alt - min_alt)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "0         001000  0.033188  0.844904  0.531295  1596721377840  SIRA\n",
            "1         001000  0.033188  0.844904  0.531295  1596721392353  SIRA\n",
            "2         001000  0.033188  0.844904  0.531295  1596721394847  SIRA\n",
            "3         001000  0.033188  0.844915  0.531311  1596721444191  SIRA\n",
            "4         001000  0.033188  0.844899  0.531291  1596721470866  SIRA\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "29550429  F00000  0.006867  0.848767  0.506672  1596742711592  SKRA\n",
            "29550430  F00000  0.004578  0.848767  0.506672  1596742711592  SKRA\n",
            "29550431  F00000  0.003052  0.848767  0.506672  1596742711592  SKRA\n",
            "29550432  F00000  0.002670  0.848767  0.506672  1596742711592  SKRA\n",
            "29550433  F00000  0.002670  0.848767  0.506672  1596742711592  SKRA\n",
            "\n",
            "[29550434 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS3cCEFA5i7S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5fvdXnszkTz"
      },
      "source": [
        "Get percentage of Vessel Types in data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsT6jkqZ2kHQ",
        "outputId": "5d86c18b-de0b-4dbc-ae77-3c6fbca399f9"
      },
      "source": [
        "\n",
        "print(train_df['Type'].value_counts(normalize=True) * 100)\n",
        "\n",
        "Percentages = train_df['Type'].value_counts(normalize=True) * 100\n",
        "print(Percentages.head(25))\n",
        "print(Percentages[:50].sum())\n",
        "print(list(Percentages[:50].index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B738    12.082537\n",
            "A320     8.034159\n",
            "C172     5.748447\n",
            "A321     3.897489\n",
            "B737     3.358540\n",
            "          ...    \n",
            "G300     0.000037\n",
            "E314     0.000037\n",
            "A337     0.000017\n",
            "PTSS     0.000010\n",
            "WACN     0.000010\n",
            "Name: Type, Length: 859, dtype: float64\n",
            "B738    12.082537\n",
            "A320     8.034159\n",
            "C172     5.748447\n",
            "A321     3.897489\n",
            "B737     3.358540\n",
            "A319     2.872411\n",
            "P28A     2.810757\n",
            "A20N     2.338856\n",
            "B763     1.780898\n",
            "B739     1.546363\n",
            "E75L     1.538011\n",
            "B752     1.344224\n",
            "B789     1.197722\n",
            "B773     1.141442\n",
            "CRJ9     1.021809\n",
            "B77L     1.012435\n",
            "C182     0.978436\n",
            "PC12     0.959624\n",
            "E190     0.874617\n",
            "C208     0.808472\n",
            "B744     0.801027\n",
            "A333     0.786411\n",
            "A21N     0.783004\n",
            "BE20     0.764100\n",
            "E170     0.752141\n",
            "Name: Type, dtype: float64\n",
            "71.76295955585626\n",
            "['B738', 'A320', 'C172', 'A321', 'B737', 'A319', 'P28A', 'A20N', 'B763', 'B739', 'E75L', 'B752', 'B789', 'B773', 'CRJ9', 'B77L', 'C182', 'PC12', 'E190', 'C208', 'B744', 'A333', 'A21N', 'BE20', 'E170', 'CRJ7', 'A359', 'DA40', 'C152', 'SR22', 'A306', 'CRJ2', 'C56X', 'A332', 'DH8D', 'B748', 'MD11', 'E55P', 'B788', 'B350', 'BE9L', 'AT76', 'TEX2', 'EC35', 'SR20', 'AS50', 'E145', 'B734', 'B77W', 'R44']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bwdvvbkZU7B"
      },
      "source": [
        "# Setup (For x,y,z coordinates)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIFAU0jmZU7L",
        "outputId": "209e1f57-9490-4062-aa3f-e64d0b09b18e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoK7TSBEZU7O",
        "outputId": "d143fc41-b268-40e4-8728-68fedd40d6b0"
      },
      "source": [
        "!pip install dask[dataframe]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.13.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.19.5)\n",
            "Requirement already satisfied: fsspec>=0.6.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.9.0)\n",
            "Requirement already satisfied: partd>=0.3.10; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.2.0)\n",
            "Requirement already satisfied: pandas>=0.23.0; extra == \"dataframe\" in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.1.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.8.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[dataframe]) (0.2.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (2.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->fsspec>=0.6.0; extra == \"dataframe\"->dask[dataframe]) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0; extra == \"dataframe\"->dask[dataframe]) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77bzFMQgZU7P",
        "outputId": "dbf5ec0d-bc39-4843-84e1-cf86e52f81a5"
      },
      "source": [
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "#file = '/content/drive/MyDrive/parsed_adsb_csvs_types/*.csv'\n",
        "file = '/content/drive/MyDrive/testtest/parsed_adsb_csvs_types-20210407T164239Z-001.zip (Unzipped Files)/parsed_adsb_csvs_types/*.csv'\n",
        "cols = ['Icao','Alt', 'Lat','Long', 'PosTime', 'Type']\n",
        "# read data frame from csv files\n",
        "train_df = dd.read_csv(file, dtype = {'Alt': 'uint16', 'Lat': 'float32', 'Long': 'float32', 'PosTime': 'int64'}, usecols = cols) \n",
        "\n",
        "train_df = train_df.compute()\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         Icao    Alt        Lat        Long        PosTime  Type\n",
            "0      A82B72   3500  39.717903  -84.619019  1596672029381  C172\n",
            "1      A80E46  31000  61.336498 -140.995438  1596672028022  B748\n",
            "2      A4E2E5    700  42.145557  -72.719398  1596672029830  C140\n",
            "3      A4BDB9  15600  33.516727  -79.442421  1596672029378  E170\n",
            "4      A4C3CE    650  32.965118  -96.833878  1596672030885  CRUZ\n",
            "...       ...    ...        ...         ...            ...   ...\n",
            "21531  C821F8  17975 -41.125225  175.051468  1596758412576  AT76\n",
            "21532  C8234A  18500 -37.852840  174.806625  1596758411374  A320\n",
            "21533  ACC040  28000  42.272324  -87.846115  1596758411880  CRJ9\n",
            "21534  A7D222   6900  29.646700  -98.126343  1596757702853  BE36\n",
            "21535  345292  32000  51.857941    5.114062  1596758411877  B734\n",
            "\n",
            "[29550434 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl6-tZO4ZU7R",
        "outputId": "ab8eecae-a894-43e7-c3a4-f2b9351e0d46"
      },
      "source": [
        "#Arrange in order of the Icao number\n",
        "train_df = train_df.sort_values(by=['Icao', 'PosTime'])\n",
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao   Alt        Lat       Long        PosTime  Type\n",
            "0         001000  2175  48.106934  11.258926  1596721377840  SIRA\n",
            "1         001000  2175  48.106934  11.258926  1596721392353  SIRA\n",
            "2         001000  2175  48.106934  11.258926  1596721394847  SIRA\n",
            "3         001000  2175  48.109818  11.264557  1596721444191  SIRA\n",
            "4         001000  2175  48.105652  11.257416  1596721470866  SIRA\n",
            "...          ...   ...        ...        ...            ...   ...\n",
            "29550429  F00000   450  49.149822   2.394817  1596742711592  SKRA\n",
            "29550430  F00000   300  49.149822   2.394817  1596742711592  SKRA\n",
            "29550431  F00000   200  49.149822   2.394817  1596742711592  SKRA\n",
            "29550432  F00000   175  49.149822   2.394817  1596742711592  SKRA\n",
            "29550433  F00000   175  49.149822   2.394817  1596742711592  SKRA\n",
            "\n",
            "[29550434 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H_BXSTSZU7S",
        "outputId": "426d1260-24f5-4f8a-b4d3-ad96a21ea8f6"
      },
      "source": [
        "\n",
        "max_alt = train_df['Alt'].max()\n",
        "min_alt = train_df['Alt'].min()\n",
        "\n",
        "#perform min- max normalization\n",
        "\n",
        "train_df['Alt'] = (train_df['Alt']- min_alt) / (max_alt - min_alt)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt        Lat       Long        PosTime  Type\n",
            "0         001000  0.033188  48.106934  11.258926  1596721377840  SIRA\n",
            "1         001000  0.033188  48.106934  11.258926  1596721392353  SIRA\n",
            "2         001000  0.033188  48.106934  11.258926  1596721394847  SIRA\n",
            "3         001000  0.033188  48.109818  11.264557  1596721444191  SIRA\n",
            "4         001000  0.033188  48.105652  11.257416  1596721470866  SIRA\n",
            "...          ...       ...        ...        ...            ...   ...\n",
            "29550429  F00000  0.006867  49.149822   2.394817  1596742711592  SKRA\n",
            "29550430  F00000  0.004578  49.149822   2.394817  1596742711592  SKRA\n",
            "29550431  F00000  0.003052  49.149822   2.394817  1596742711592  SKRA\n",
            "29550432  F00000  0.002670  49.149822   2.394817  1596742711592  SKRA\n",
            "29550433  F00000  0.002670  49.149822   2.394817  1596742711592  SKRA\n",
            "\n",
            "[29550434 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8GLINYIZU7U",
        "outputId": "b45d27b7-5156-4b51-e6d5-9c35dc74da92"
      },
      "source": [
        "#Get percentage of Vessel Types in each data frame\n",
        "print(train_df['Type'].value_counts(normalize=True) * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B738    12.082537\n",
            "A320     8.034159\n",
            "C172     5.748447\n",
            "A321     3.897489\n",
            "B737     3.358540\n",
            "          ...    \n",
            "E314     0.000037\n",
            "G300     0.000037\n",
            "A337     0.000017\n",
            "PTSS     0.000010\n",
            "WACN     0.000010\n",
            "Name: Type, Length: 859, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Iq8ck4ZU7V",
        "outputId": "063d1304-028d-48f7-ec52-c8e8da8d67b5"
      },
      "source": [
        "Percentages = train_df['Type'].value_counts(normalize=True) * 100\n",
        "print(Percentages.head(25))\n",
        "print(Percentages[:25].sum())\n",
        "print(list(Percentages[:25].index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "B738    12.082537\n",
            "A320     8.034159\n",
            "C172     5.748447\n",
            "A321     3.897489\n",
            "B737     3.358540\n",
            "A319     2.872411\n",
            "P28A     2.810757\n",
            "A20N     2.338856\n",
            "B763     1.780898\n",
            "B739     1.546363\n",
            "E75L     1.538011\n",
            "B752     1.344224\n",
            "B789     1.197722\n",
            "B773     1.141442\n",
            "CRJ9     1.021809\n",
            "B77L     1.012435\n",
            "C182     0.978436\n",
            "PC12     0.959624\n",
            "E190     0.874617\n",
            "C208     0.808472\n",
            "B744     0.801027\n",
            "A333     0.786411\n",
            "A21N     0.783004\n",
            "BE20     0.764100\n",
            "E170     0.752141\n",
            "Name: Type, dtype: float64\n",
            "59.233932063400495\n",
            "['B738', 'A320', 'C172', 'A321', 'B737', 'A319', 'P28A', 'A20N', 'B763', 'B739', 'E75L', 'B752', 'B789', 'B773', 'CRJ9', 'B77L', 'C182', 'PC12', 'E190', 'C208', 'B744', 'A333', 'A21N', 'BE20', 'E170']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkBxelStTcgB"
      },
      "source": [
        "# Top 10 Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYohhFKiTcgf",
        "outputId": "e9fd06d5-9310-4bba-f71c-2b3b227b016b"
      },
      "source": [
        "#remove rows not in the top 16 types\n",
        "train_df = train_df[train_df['Type'].isin(list(Percentages[:10].index))]\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "994       008DC6  0.088502  0.570442  0.578876  1596723690985  P28A\n",
            "995       008DC6  0.089647  0.570432  0.578902  1596723703073  P28A\n",
            "996       008DC6  0.090028  0.570430  0.578911  1596723717541  P28A\n",
            "997       008DC6  0.090028  0.570430  0.578911  1596723719963  P28A\n",
            "998       008DC6  0.136568  0.570992  0.578782  1596724125875  P28A\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "29550390  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550391  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550392  E94C42  0.286107  0.601955  0.314975  1596733965728  B738\n",
            "29550393  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "29550394  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "\n",
            "[13141213 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyop92VmTcgh",
        "outputId": "f527ecce-ee69-4315-f5bc-4fbc4f441537"
      },
      "source": [
        "type_dict = {k: v for v, k in enumerate(list(Percentages[:10].index))}\n",
        "print(type_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B738': 0, 'A320': 1, 'C172': 2, 'A321': 3, 'B737': 4, 'A319': 5, 'P28A': 6, 'A20N': 7, 'B763': 8, 'B739': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ_QsZ3iTcgi"
      },
      "source": [
        "train_df['Type'].replace(type_dict, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYkVT8SxTcgi",
        "outputId": "90881e57-4a29-49d4-9bce-cf460844884e"
      },
      "source": [
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "0         008DC6  0.088502  0.570442  0.578876  1596723690985     6\n",
            "1         008DC6  0.089647  0.570432  0.578902  1596723703073     6\n",
            "2         008DC6  0.090028  0.570430  0.578911  1596723717541     6\n",
            "3         008DC6  0.090028  0.570430  0.578911  1596723719963     6\n",
            "4         008DC6  0.136568  0.570992  0.578782  1596724125875     6\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "13141208  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "13141209  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "13141210  E94C42  0.286107  0.601955  0.314975  1596733965728     0\n",
            "13141211  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "13141212  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "\n",
            "[13141213 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cANNEA3ULnvX"
      },
      "source": [
        "Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "a4pNSMsHLcSj",
        "outputId": "5c3809b6-d0fa-462f-ceb6-1604ae162166"
      },
      "source": [
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "corrMatrix = train_df.corr()\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0OovoCLNXBJ",
        "outputId": "1fab38a9-03a5-42fa-b7e2-ab9638eafa83"
      },
      "source": [
        "train_df['Cross'] = train_df['Lat'] * train_df['Long']\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type     Cross\n",
            "0         008DC6  0.088502  0.570442  0.578876  1596723690985     6  0.330215\n",
            "1         008DC6  0.089647  0.570432  0.578902  1596723703073     6  0.330225\n",
            "2         008DC6  0.090028  0.570430  0.578911  1596723717541     6  0.330228\n",
            "3         008DC6  0.090028  0.570430  0.578911  1596723719963     6  0.330228\n",
            "4         008DC6  0.136568  0.570992  0.578782  1596724125875     6  0.330480\n",
            "...          ...       ...       ...       ...            ...   ...       ...\n",
            "13141208  E94C42  0.281147  0.601961  0.315125  1596733935427     0  0.189693\n",
            "13141209  E94C42  0.281147  0.601961  0.315125  1596733935427     0  0.189693\n",
            "13141210  E94C42  0.286107  0.601955  0.314975  1596733965728     0  0.189601\n",
            "13141211  E94C42  0.301747  0.602027  0.314776  1596734007974     0  0.189504\n",
            "13141212  E94C42  0.301747  0.602027  0.314776  1596734007974     0  0.189504\n",
            "\n",
            "[13141213 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "PAub2XGRNwbm",
        "outputId": "812aa4fd-d849-4297-b89c-75713d2f5331"
      },
      "source": [
        "corrMatrix = train_df.corr()\n",
        "sn.heatmap(corrMatrix, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPcD9pdXOWb3"
      },
      "source": [
        "train_df = train_df.drop(columns = ['Cross'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCkEsX7CTcgj",
        "outputId": "52c7e225-cd9d-408d-803b-5b60d3aa9873"
      },
      "source": [
        "#turn train dataframe into a multi-dimensional numpy array\n",
        "train_df = np.array(list(train_df.groupby('Icao').apply(pd.DataFrame.to_numpy)))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_count = train_df.shape[0]\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16046,)\n",
            "16046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ejVWHAoTcgk",
        "outputId": "14b12107-9977-40bb-f57b-c258f519d5c7"
      },
      "source": [
        "#load in first dataframe\n",
        "train_input = pd.DataFrame(data = train_df[1], columns = [\"Icao\", \"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "train_input = train_input.set_index('Time')\n",
        "train_input = train_input.drop('PosTime', axis = 1)\n",
        "train_input = train_input.drop('Icao', axis = 1)\n",
        "print(train_input)\n",
        "#Get Species Type\n",
        "unique_species = train_input.Type[0]\n",
        "print(unique_species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                Alt       Lat      Long Type\n",
            "Time                                                        \n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:13:29.760    0.995056  0.540866  0.551703    0\n",
            "2020-08-06 07:13:44.242    0.998108  0.540902  0.551694    0\n",
            "2020-08-06 07:13:56.289  0.00572213  0.540932  0.551686    0\n",
            "...                             ...       ...       ...  ...\n",
            "2020-08-06 16:02:45.713    0.999252   0.54098  0.551676    0\n",
            "2020-08-06 16:02:57.784    0.996963  0.540951  0.551683    0\n",
            "2020-08-06 16:03:55.777    0.994675  0.540866  0.551703    0\n",
            "2020-08-06 16:04:10.278    0.994675  0.540864  0.551703    0\n",
            "2020-08-06 16:04:27.227    0.994675  0.540863  0.551702    0\n",
            "\n",
            "[373 rows x 4 columns]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eq80h-_Tcgk",
        "outputId": "31c2534a-d8ca-4849-a075-0b82f49c13a2"
      },
      "source": [
        "#Resampling/Interpolating\n",
        "norm_train_df = pd.DataFrame()\n",
        "norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "norm_train_df.reset_index(inplace = True)\n",
        "#norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "norm_train_df = norm_train_df.iloc[0:73]\n",
        "print(norm_train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Time       Lat      Long       Alt\n",
            "0  2020-08-06 07:10:00  0.541109  0.551641  0.026703\n",
            "1  2020-08-06 07:15:00  0.542472  0.552251  0.217823\n",
            "2  2020-08-06 07:20:00  0.544178  0.553254  0.402075\n",
            "3  2020-08-06 07:25:00  0.546072  0.554713  0.501640\n",
            "4  2020-08-06 07:30:00  0.547895  0.556523  0.586328\n",
            "..                 ...       ...       ...       ...\n",
            "68 2020-08-06 12:50:00  0.575555  0.585123 -1.378310\n",
            "69 2020-08-06 12:55:00  0.575441  0.584925 -1.338937\n",
            "70 2020-08-06 13:00:00  0.575300  0.584686 -1.292159\n",
            "71 2020-08-06 13:05:00  0.575129  0.584407 -1.237701\n",
            "72 2020-08-06 13:10:00  0.574928  0.584084 -1.175291\n",
            "\n",
            "[73 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIemSNkgTcgl",
        "outputId": "6d9ef4f8-f8b9-4513-9e41-87fbc51c7293"
      },
      "source": [
        "#add species to label list\n",
        "train_labels = []\n",
        "train_labels.append(unique_species)\n",
        "print(train_labels)\n",
        "#convert dataframe to numpy\n",
        "norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "norm_train_df = norm_train_df.to_numpy()\n",
        "print(norm_train_df)\n",
        "final_input_train = norm_train_df\n",
        "print(final_input_train.shape)\n",
        "final_input_train = np.reshape(final_input_train, (1,73,3))\n",
        "print(final_input_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[ 0.54110926  0.55164051  0.02670329]\n",
            " [ 0.54247236  0.55225104  0.21782254]\n",
            " [ 0.54417837  0.55325353  0.40207523]\n",
            " [ 0.54607177  0.55471271  0.50164034]\n",
            " [ 0.54789543  0.5565232   0.58632792]\n",
            " [ 0.54969102  0.55826527  0.59510185]\n",
            " [ 0.55004507  0.55860418  0.59510185]\n",
            " [ 0.55061809  0.55913722  0.60817557]\n",
            " [ 0.55184827  0.56027639  0.62872997]\n",
            " [ 0.55359598  0.56188938  0.65039623]\n",
            " [ 0.55572157  0.5638439   0.66680553]\n",
            " [ 0.55808541  0.56600764  0.67158908]\n",
            " [ 0.56054785  0.56824831  0.65837804]\n",
            " [ 0.56296924  0.5704336   0.62080362]\n",
            " [ 0.56520995  0.57243121  0.55249699]\n",
            " [ 0.56713033  0.57410884  0.44708934]\n",
            " [ 0.56859511  0.57544625  0.30861372]\n",
            " [ 0.56961566  0.57667202  0.17662318]\n",
            " [ 0.57040614  0.5773856   0.08812085]\n",
            " [ 0.57044345  0.57741934  0.08392462]\n",
            " [ 0.57031141  0.57733422  0.09457798]\n",
            " [ 0.57020701  0.57728254  0.09927008]\n",
            " [ 0.57012913  0.57726283  0.09827373]\n",
            " [ 0.57007663  0.57727358  0.09186173]\n",
            " [ 0.57004836  0.5773133   0.0803069 ]\n",
            " [ 0.5700432   0.57738052  0.06388204]\n",
            " [ 0.57006001  0.57747373  0.04285995]\n",
            " [ 0.57009765  0.57759144  0.01751345]\n",
            " [ 0.57015498  0.57773217 -0.01188467]\n",
            " [ 0.57023088  0.57789442 -0.04506159]\n",
            " [ 0.5703242   0.57807671 -0.08174451]\n",
            " [ 0.5704338   0.57827755 -0.12166062]\n",
            " [ 0.57055856  0.57849543 -0.16453711]\n",
            " [ 0.57069733  0.57872888 -0.21010118]\n",
            " [ 0.57084898  0.5789764  -0.25808002]\n",
            " [ 0.57101237  0.5792365  -0.30820083]\n",
            " [ 0.57118636  0.5795077  -0.36019079]\n",
            " [ 0.57136983  0.57978849 -0.41377711]\n",
            " [ 0.57156163  0.5800774  -0.46868697]\n",
            " [ 0.57176063  0.58037292 -0.52464756]\n",
            " [ 0.57196568  0.58067358 -0.58138609]\n",
            " [ 0.57217567  0.58097787 -0.63862974]\n",
            " [ 0.57238944  0.58128432 -0.69610571]\n",
            " [ 0.57260586  0.58159142 -0.75354119]\n",
            " [ 0.5728238   0.58189769 -0.81066338]\n",
            " [ 0.57304211  0.58220164 -0.86719946]\n",
            " [ 0.57325968  0.58250177 -0.92287663]\n",
            " [ 0.57347534  0.58279661 -0.97742209]\n",
            " [ 0.57368798  0.58308465 -1.03056303]\n",
            " [ 0.57389646  0.5833644  -1.08202663]\n",
            " [ 0.57409963  0.58363438 -1.1315401 ]\n",
            " [ 0.57429636  0.5838931  -1.17883063]\n",
            " [ 0.57448553  0.58413906 -1.22362541]\n",
            " [ 0.57466598  0.58437077 -1.26565163]\n",
            " [ 0.57483658  0.58458675 -1.30463649]\n",
            " [ 0.5749962   0.5847855  -1.34030718]\n",
            " [ 0.5751437   0.58496553 -1.3723909 ]\n",
            " [ 0.57527795  0.58512536 -1.40061483]\n",
            " [ 0.57539781  0.58526349 -1.42470618]\n",
            " [ 0.57550214  0.58537843 -1.44439212]\n",
            " [ 0.5755898   0.58546869 -1.45939987]\n",
            " [ 0.57565966  0.58553279 -1.46945661]\n",
            " [ 0.57571059  0.58556922 -1.47428953]\n",
            " [ 0.57574145  0.5855765  -1.47362583]\n",
            " [ 0.57575109  0.58555314 -1.4671927 ]\n",
            " [ 0.57573839  0.58549765 -1.45471733]\n",
            " [ 0.57570221  0.58540854 -1.43592692]\n",
            " [ 0.57564142  0.58528432 -1.41054866]\n",
            " [ 0.57555487  0.5851235  -1.37830975]\n",
            " [ 0.57544142  0.58492458 -1.33893737]\n",
            " [ 0.57529996  0.58468608 -1.29215873]\n",
            " [ 0.57512933  0.58440651 -1.23770101]\n",
            " [ 0.5749284   0.58408437 -1.1752914 ]]\n",
            "(73, 3)\n",
            "(1, 73, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ji19cJbTcgm",
        "outputId": "d40c2402-d1d7-432d-c558-c3811a8eb63e"
      },
      "source": [
        "for j in range(2,16046):\n",
        "    try:\n",
        "        train_input = pd.DataFrame(data = train_df[j], columns = [\"Icao\",\"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "        train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "        train_input = train_input.set_index('Time')\n",
        "        train_input = train_input.drop('PosTime', axis = 1)\n",
        "        unique_species = train_input.Type[0]\n",
        "        norm_train_df = pd.DataFrame()\n",
        "        norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "        norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "        norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "        norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "        norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "        norm_train_df.reset_index(inplace = True)\n",
        "        #norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "        norm_train_df = norm_train_df.iloc[0:73]\n",
        "        norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "        norm_train_df = norm_train_df.to_numpy()\n",
        "        norm_train_df = np.reshape(norm_train_df, (1,73,3))\n",
        "        final_input_train = np.append(final_input_train, norm_train_df, axis = 0)\n",
        "        train_labels.append(unique_species)\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "print(final_input_train.shape)\n",
        "print(len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10376, 73, 3)\n",
            "10376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Rgj4SmTcgn",
        "outputId": "719e6adb-4e7c-41f0-c4c0-84b5dd83a082"
      },
      "source": [
        "final_input_test = final_input_train[7263:]\n",
        "arr = list(range(7263,final_input_train.shape[0] ))\n",
        "print(final_input_test.shape)\n",
        "\n",
        "final_input_train = np.delete(final_input_train, arr, 0)\n",
        "print(final_input_train.shape)\n",
        "\n",
        "test_labels = train_labels[7263:]\n",
        "print(len(test_labels))\n",
        "\n",
        "train_labels_final = train_labels[:7263]\n",
        "print(len(train_labels_final))\n",
        "\n",
        "unique = list(dict.fromkeys(test_labels))\n",
        "unique2 = list(dict.fromkeys(train_labels_final))\n",
        "print(unique)\n",
        "print(unique2)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "test_labels = to_categorical(test_labels,num_classes = 10)\n",
        "train_labels_final = to_categorical(train_labels_final,num_classes = 10)\n",
        "print(len(test_labels))\n",
        "print(len(train_labels_final))\n",
        "\n",
        "train_labels_final = np.array(train_labels_final)\n",
        "test_labels = np.array(test_labels)\n",
        "print(train_labels_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3113, 73, 3)\n",
            "(7263, 73, 3)\n",
            "3113\n",
            "7263\n",
            "[9, 8, 2, 1, 4, 6, 0, 5, 3, 7]\n",
            "[0, 1, 5, 7, 4, 3, 6, 2, 8, 9]\n",
            "3113\n",
            "7263\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7F-NyiBTcgo",
        "outputId": "45b5f93d-074a-4641-adf3-ef285f3410c7"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "import keras\n",
        "# fit and evaluate a model\n",
        "verbose, epochs, batch_size = 2, 1000, 128\n",
        "n_timesteps, n_features, n_outputs = final_input_train.shape[1], final_input_train.shape[2], 10\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "#model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "# fit network\n",
        "history =  model.fit(final_input_train, train_labels_final, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle = True)\n",
        "# evaluate model\n",
        "_, accuracy = model.evaluate(final_input_test, test_labels, batch_size=batch_size, verbose=0)\n",
        "print(accuracy *100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "57/57 - 4s - loss: 2.1759 - accuracy: 0.2810\n",
            "Epoch 2/1000\n",
            "57/57 - 3s - loss: 1.9931 - accuracy: 0.3014\n",
            "Epoch 3/1000\n",
            "57/57 - 3s - loss: 1.9105 - accuracy: 0.3454\n",
            "Epoch 4/1000\n",
            "57/57 - 3s - loss: 1.8272 - accuracy: 0.3691\n",
            "Epoch 5/1000\n",
            "57/57 - 3s - loss: 1.7875 - accuracy: 0.3763\n",
            "Epoch 6/1000\n",
            "57/57 - 3s - loss: 1.7220 - accuracy: 0.3857\n",
            "Epoch 7/1000\n",
            "57/57 - 3s - loss: 1.7237 - accuracy: 0.3884\n",
            "Epoch 8/1000\n",
            "57/57 - 3s - loss: 1.6795 - accuracy: 0.3870\n",
            "Epoch 9/1000\n",
            "57/57 - 3s - loss: 1.6450 - accuracy: 0.3969\n",
            "Epoch 10/1000\n",
            "57/57 - 3s - loss: 1.6219 - accuracy: 0.3945\n",
            "Epoch 11/1000\n",
            "57/57 - 3s - loss: 1.6417 - accuracy: 0.3996\n",
            "Epoch 12/1000\n",
            "57/57 - 3s - loss: 1.6059 - accuracy: 0.3976\n",
            "Epoch 13/1000\n",
            "57/57 - 3s - loss: 1.6435 - accuracy: 0.4022\n",
            "Epoch 14/1000\n",
            "57/57 - 3s - loss: 1.5902 - accuracy: 0.4013\n",
            "Epoch 15/1000\n",
            "57/57 - 3s - loss: 1.5852 - accuracy: 0.4069\n",
            "Epoch 16/1000\n",
            "57/57 - 3s - loss: 1.6090 - accuracy: 0.4074\n",
            "Epoch 17/1000\n",
            "57/57 - 3s - loss: 1.5717 - accuracy: 0.4089\n",
            "Epoch 18/1000\n",
            "57/57 - 3s - loss: 1.5842 - accuracy: 0.4165\n",
            "Epoch 19/1000\n",
            "57/57 - 3s - loss: 1.5620 - accuracy: 0.4144\n",
            "Epoch 20/1000\n",
            "57/57 - 3s - loss: 1.5614 - accuracy: 0.4209\n",
            "Epoch 21/1000\n",
            "57/57 - 3s - loss: 1.5538 - accuracy: 0.4184\n",
            "Epoch 22/1000\n",
            "57/57 - 3s - loss: 1.5367 - accuracy: 0.4187\n",
            "Epoch 23/1000\n",
            "57/57 - 3s - loss: 1.5413 - accuracy: 0.4213\n",
            "Epoch 24/1000\n",
            "57/57 - 3s - loss: 1.5396 - accuracy: 0.4232\n",
            "Epoch 25/1000\n",
            "57/57 - 3s - loss: 1.5375 - accuracy: 0.4275\n",
            "Epoch 26/1000\n",
            "57/57 - 3s - loss: 1.5337 - accuracy: 0.4249\n",
            "Epoch 27/1000\n",
            "57/57 - 3s - loss: 1.5242 - accuracy: 0.4248\n",
            "Epoch 28/1000\n",
            "57/57 - 3s - loss: 1.5224 - accuracy: 0.4246\n",
            "Epoch 29/1000\n",
            "57/57 - 3s - loss: 1.5299 - accuracy: 0.4270\n",
            "Epoch 30/1000\n",
            "57/57 - 3s - loss: 1.5154 - accuracy: 0.4243\n",
            "Epoch 31/1000\n",
            "57/57 - 3s - loss: 1.5266 - accuracy: 0.4297\n",
            "Epoch 32/1000\n",
            "57/57 - 3s - loss: 1.5059 - accuracy: 0.4344\n",
            "Epoch 33/1000\n",
            "57/57 - 3s - loss: 1.5119 - accuracy: 0.4332\n",
            "Epoch 34/1000\n",
            "57/57 - 3s - loss: 1.5027 - accuracy: 0.4301\n",
            "Epoch 35/1000\n",
            "57/57 - 3s - loss: 1.4972 - accuracy: 0.4418\n",
            "Epoch 36/1000\n",
            "57/57 - 3s - loss: 1.4975 - accuracy: 0.4340\n",
            "Epoch 37/1000\n",
            "57/57 - 3s - loss: 1.5011 - accuracy: 0.4304\n",
            "Epoch 38/1000\n",
            "57/57 - 3s - loss: 1.4946 - accuracy: 0.4345\n",
            "Epoch 39/1000\n",
            "57/57 - 3s - loss: 1.4976 - accuracy: 0.4389\n",
            "Epoch 40/1000\n",
            "57/57 - 3s - loss: 1.4858 - accuracy: 0.4414\n",
            "Epoch 41/1000\n",
            "57/57 - 3s - loss: 1.4819 - accuracy: 0.4399\n",
            "Epoch 42/1000\n",
            "57/57 - 3s - loss: 1.4862 - accuracy: 0.4374\n",
            "Epoch 43/1000\n",
            "57/57 - 3s - loss: 1.4868 - accuracy: 0.4337\n",
            "Epoch 44/1000\n",
            "57/57 - 3s - loss: 1.4789 - accuracy: 0.4414\n",
            "Epoch 45/1000\n",
            "57/57 - 3s - loss: 1.4818 - accuracy: 0.4416\n",
            "Epoch 46/1000\n",
            "57/57 - 3s - loss: 1.4797 - accuracy: 0.4409\n",
            "Epoch 47/1000\n",
            "57/57 - 3s - loss: 1.4751 - accuracy: 0.4370\n",
            "Epoch 48/1000\n",
            "57/57 - 3s - loss: 1.4809 - accuracy: 0.4413\n",
            "Epoch 49/1000\n",
            "57/57 - 3s - loss: 1.4754 - accuracy: 0.4403\n",
            "Epoch 50/1000\n",
            "57/57 - 3s - loss: 1.4699 - accuracy: 0.4466\n",
            "Epoch 51/1000\n",
            "57/57 - 3s - loss: 1.4698 - accuracy: 0.4400\n",
            "Epoch 52/1000\n",
            "57/57 - 3s - loss: 1.4643 - accuracy: 0.4409\n",
            "Epoch 53/1000\n",
            "57/57 - 3s - loss: 1.4600 - accuracy: 0.4531\n",
            "Epoch 54/1000\n",
            "57/57 - 3s - loss: 1.4636 - accuracy: 0.4461\n",
            "Epoch 55/1000\n",
            "57/57 - 3s - loss: 1.4582 - accuracy: 0.4495\n",
            "Epoch 56/1000\n",
            "57/57 - 3s - loss: 1.4560 - accuracy: 0.4495\n",
            "Epoch 57/1000\n",
            "57/57 - 3s - loss: 1.4536 - accuracy: 0.4501\n",
            "Epoch 58/1000\n",
            "57/57 - 3s - loss: 1.4517 - accuracy: 0.4511\n",
            "Epoch 59/1000\n",
            "57/57 - 3s - loss: 1.4538 - accuracy: 0.4440\n",
            "Epoch 60/1000\n",
            "57/57 - 4s - loss: 1.4564 - accuracy: 0.4480\n",
            "Epoch 61/1000\n",
            "57/57 - 3s - loss: 1.4481 - accuracy: 0.4544\n",
            "Epoch 62/1000\n",
            "57/57 - 3s - loss: 1.4490 - accuracy: 0.4498\n",
            "Epoch 63/1000\n",
            "57/57 - 3s - loss: 1.4481 - accuracy: 0.4491\n",
            "Epoch 64/1000\n",
            "57/57 - 3s - loss: 1.4490 - accuracy: 0.4480\n",
            "Epoch 65/1000\n",
            "57/57 - 3s - loss: 1.4441 - accuracy: 0.4451\n",
            "Epoch 66/1000\n",
            "57/57 - 3s - loss: 1.4439 - accuracy: 0.4539\n",
            "Epoch 67/1000\n",
            "57/57 - 3s - loss: 1.4352 - accuracy: 0.4574\n",
            "Epoch 68/1000\n",
            "57/57 - 3s - loss: 1.4376 - accuracy: 0.4538\n",
            "Epoch 69/1000\n",
            "57/57 - 3s - loss: 1.4311 - accuracy: 0.4566\n",
            "Epoch 70/1000\n",
            "57/57 - 3s - loss: 1.4338 - accuracy: 0.4546\n",
            "Epoch 71/1000\n",
            "57/57 - 3s - loss: 1.4300 - accuracy: 0.4549\n",
            "Epoch 72/1000\n",
            "57/57 - 3s - loss: 1.4318 - accuracy: 0.4511\n",
            "Epoch 73/1000\n",
            "57/57 - 3s - loss: 1.4294 - accuracy: 0.4571\n",
            "Epoch 74/1000\n",
            "57/57 - 3s - loss: 1.4266 - accuracy: 0.4572\n",
            "Epoch 75/1000\n",
            "57/57 - 3s - loss: 1.4297 - accuracy: 0.4556\n",
            "Epoch 76/1000\n",
            "57/57 - 3s - loss: 1.4249 - accuracy: 0.4603\n",
            "Epoch 77/1000\n",
            "57/57 - 3s - loss: 1.4246 - accuracy: 0.4593\n",
            "Epoch 78/1000\n",
            "57/57 - 3s - loss: 1.4216 - accuracy: 0.4639\n",
            "Epoch 79/1000\n",
            "57/57 - 3s - loss: 1.4159 - accuracy: 0.4625\n",
            "Epoch 80/1000\n",
            "57/57 - 3s - loss: 1.4172 - accuracy: 0.4582\n",
            "Epoch 81/1000\n",
            "57/57 - 3s - loss: 1.4169 - accuracy: 0.4625\n",
            "Epoch 82/1000\n",
            "57/57 - 3s - loss: 1.4147 - accuracy: 0.4585\n",
            "Epoch 83/1000\n",
            "57/57 - 3s - loss: 1.4196 - accuracy: 0.4626\n",
            "Epoch 84/1000\n",
            "57/57 - 3s - loss: 1.4057 - accuracy: 0.4654\n",
            "Epoch 85/1000\n",
            "57/57 - 3s - loss: 1.4097 - accuracy: 0.4640\n",
            "Epoch 86/1000\n",
            "57/57 - 3s - loss: 1.4090 - accuracy: 0.4648\n",
            "Epoch 87/1000\n",
            "57/57 - 3s - loss: 1.4077 - accuracy: 0.4630\n",
            "Epoch 88/1000\n",
            "57/57 - 3s - loss: 1.4076 - accuracy: 0.4563\n",
            "Epoch 89/1000\n",
            "57/57 - 3s - loss: 1.4052 - accuracy: 0.4615\n",
            "Epoch 90/1000\n",
            "57/57 - 3s - loss: 1.3995 - accuracy: 0.4661\n",
            "Epoch 91/1000\n",
            "57/57 - 3s - loss: 1.3977 - accuracy: 0.4614\n",
            "Epoch 92/1000\n",
            "57/57 - 3s - loss: 1.3959 - accuracy: 0.4652\n",
            "Epoch 93/1000\n",
            "57/57 - 3s - loss: 1.3922 - accuracy: 0.4676\n",
            "Epoch 94/1000\n",
            "57/57 - 3s - loss: 1.3929 - accuracy: 0.4698\n",
            "Epoch 95/1000\n",
            "57/57 - 3s - loss: 1.3937 - accuracy: 0.4702\n",
            "Epoch 96/1000\n",
            "57/57 - 3s - loss: 1.3923 - accuracy: 0.4710\n",
            "Epoch 97/1000\n",
            "57/57 - 3s - loss: 1.3866 - accuracy: 0.4694\n",
            "Epoch 98/1000\n",
            "57/57 - 3s - loss: 1.3863 - accuracy: 0.4655\n",
            "Epoch 99/1000\n",
            "57/57 - 3s - loss: 1.3866 - accuracy: 0.4721\n",
            "Epoch 100/1000\n",
            "57/57 - 3s - loss: 1.3866 - accuracy: 0.4754\n",
            "Epoch 101/1000\n",
            "57/57 - 3s - loss: 1.3912 - accuracy: 0.4731\n",
            "Epoch 102/1000\n",
            "57/57 - 3s - loss: 1.3978 - accuracy: 0.4714\n",
            "Epoch 103/1000\n",
            "57/57 - 3s - loss: 1.3866 - accuracy: 0.4661\n",
            "Epoch 104/1000\n",
            "57/57 - 3s - loss: 1.3791 - accuracy: 0.4691\n",
            "Epoch 105/1000\n",
            "57/57 - 3s - loss: 1.3781 - accuracy: 0.4761\n",
            "Epoch 106/1000\n",
            "57/57 - 3s - loss: 1.3797 - accuracy: 0.4703\n",
            "Epoch 107/1000\n",
            "57/57 - 3s - loss: 1.3747 - accuracy: 0.4721\n",
            "Epoch 108/1000\n",
            "57/57 - 3s - loss: 1.3671 - accuracy: 0.4801\n",
            "Epoch 109/1000\n",
            "57/57 - 3s - loss: 1.3721 - accuracy: 0.4820\n",
            "Epoch 110/1000\n",
            "57/57 - 3s - loss: 1.3674 - accuracy: 0.4786\n",
            "Epoch 111/1000\n",
            "57/57 - 3s - loss: 1.3649 - accuracy: 0.4838\n",
            "Epoch 112/1000\n",
            "57/57 - 3s - loss: 1.3710 - accuracy: 0.4787\n",
            "Epoch 113/1000\n",
            "57/57 - 3s - loss: 1.3651 - accuracy: 0.4802\n",
            "Epoch 114/1000\n",
            "57/57 - 3s - loss: 1.3602 - accuracy: 0.4793\n",
            "Epoch 115/1000\n",
            "57/57 - 3s - loss: 1.3621 - accuracy: 0.4857\n",
            "Epoch 116/1000\n",
            "57/57 - 3s - loss: 1.3557 - accuracy: 0.4794\n",
            "Epoch 117/1000\n",
            "57/57 - 3s - loss: 1.3517 - accuracy: 0.4823\n",
            "Epoch 118/1000\n",
            "57/57 - 3s - loss: 1.3523 - accuracy: 0.4851\n",
            "Epoch 119/1000\n",
            "57/57 - 3s - loss: 1.3514 - accuracy: 0.4800\n",
            "Epoch 120/1000\n",
            "57/57 - 3s - loss: 1.3498 - accuracy: 0.4866\n",
            "Epoch 121/1000\n",
            "57/57 - 3s - loss: 1.3469 - accuracy: 0.4833\n",
            "Epoch 122/1000\n",
            "57/57 - 3s - loss: 1.3493 - accuracy: 0.4852\n",
            "Epoch 123/1000\n",
            "57/57 - 3s - loss: 1.3452 - accuracy: 0.4859\n",
            "Epoch 124/1000\n",
            "57/57 - 3s - loss: 1.3448 - accuracy: 0.4921\n",
            "Epoch 125/1000\n",
            "57/57 - 3s - loss: 1.3448 - accuracy: 0.4845\n",
            "Epoch 126/1000\n",
            "57/57 - 3s - loss: 1.3435 - accuracy: 0.4791\n",
            "Epoch 127/1000\n",
            "57/57 - 3s - loss: 1.3366 - accuracy: 0.4900\n",
            "Epoch 128/1000\n",
            "57/57 - 3s - loss: 1.3393 - accuracy: 0.4859\n",
            "Epoch 129/1000\n",
            "57/57 - 3s - loss: 1.3331 - accuracy: 0.4943\n",
            "Epoch 130/1000\n",
            "57/57 - 3s - loss: 1.3272 - accuracy: 0.4889\n",
            "Epoch 131/1000\n",
            "57/57 - 3s - loss: 1.3316 - accuracy: 0.4930\n",
            "Epoch 132/1000\n",
            "57/57 - 3s - loss: 1.3312 - accuracy: 0.4948\n",
            "Epoch 133/1000\n",
            "57/57 - 3s - loss: 1.3222 - accuracy: 0.4964\n",
            "Epoch 134/1000\n",
            "57/57 - 3s - loss: 1.3280 - accuracy: 0.4904\n",
            "Epoch 135/1000\n",
            "57/57 - 3s - loss: 1.3272 - accuracy: 0.4983\n",
            "Epoch 136/1000\n",
            "57/57 - 3s - loss: 1.3288 - accuracy: 0.4892\n",
            "Epoch 137/1000\n",
            "57/57 - 3s - loss: 1.3292 - accuracy: 0.4910\n",
            "Epoch 138/1000\n",
            "57/57 - 3s - loss: 1.3185 - accuracy: 0.4929\n",
            "Epoch 139/1000\n",
            "57/57 - 3s - loss: 1.3192 - accuracy: 0.4991\n",
            "Epoch 140/1000\n",
            "57/57 - 3s - loss: 1.3169 - accuracy: 0.4964\n",
            "Epoch 141/1000\n",
            "57/57 - 3s - loss: 1.3165 - accuracy: 0.5025\n",
            "Epoch 142/1000\n",
            "57/57 - 3s - loss: 1.3151 - accuracy: 0.4981\n",
            "Epoch 143/1000\n",
            "57/57 - 3s - loss: 1.3124 - accuracy: 0.5013\n",
            "Epoch 144/1000\n",
            "57/57 - 3s - loss: 1.3130 - accuracy: 0.4962\n",
            "Epoch 145/1000\n",
            "57/57 - 3s - loss: 1.3071 - accuracy: 0.5053\n",
            "Epoch 146/1000\n",
            "57/57 - 3s - loss: 1.3033 - accuracy: 0.5006\n",
            "Epoch 147/1000\n",
            "57/57 - 3s - loss: 1.3013 - accuracy: 0.5050\n",
            "Epoch 148/1000\n",
            "57/57 - 3s - loss: 1.3070 - accuracy: 0.5003\n",
            "Epoch 149/1000\n",
            "57/57 - 3s - loss: 1.3071 - accuracy: 0.5019\n",
            "Epoch 150/1000\n",
            "57/57 - 3s - loss: 1.3010 - accuracy: 0.5041\n",
            "Epoch 151/1000\n",
            "57/57 - 3s - loss: 1.2979 - accuracy: 0.5021\n",
            "Epoch 152/1000\n",
            "57/57 - 3s - loss: 1.2941 - accuracy: 0.5019\n",
            "Epoch 153/1000\n",
            "57/57 - 3s - loss: 1.2919 - accuracy: 0.5096\n",
            "Epoch 154/1000\n",
            "57/57 - 3s - loss: 1.2958 - accuracy: 0.5021\n",
            "Epoch 155/1000\n",
            "57/57 - 3s - loss: 1.2943 - accuracy: 0.5020\n",
            "Epoch 156/1000\n",
            "57/57 - 3s - loss: 1.2849 - accuracy: 0.5141\n",
            "Epoch 157/1000\n",
            "57/57 - 3s - loss: 1.2944 - accuracy: 0.5085\n",
            "Epoch 158/1000\n",
            "57/57 - 3s - loss: 1.2883 - accuracy: 0.5046\n",
            "Epoch 159/1000\n",
            "57/57 - 3s - loss: 1.2799 - accuracy: 0.5131\n",
            "Epoch 160/1000\n",
            "57/57 - 3s - loss: 1.2868 - accuracy: 0.5085\n",
            "Epoch 161/1000\n",
            "57/57 - 3s - loss: 1.2793 - accuracy: 0.5090\n",
            "Epoch 162/1000\n",
            "57/57 - 3s - loss: 1.2792 - accuracy: 0.5127\n",
            "Epoch 163/1000\n",
            "57/57 - 3s - loss: 1.2806 - accuracy: 0.5156\n",
            "Epoch 164/1000\n",
            "57/57 - 3s - loss: 1.2725 - accuracy: 0.5115\n",
            "Epoch 165/1000\n",
            "57/57 - 3s - loss: 1.2746 - accuracy: 0.5120\n",
            "Epoch 166/1000\n",
            "57/57 - 3s - loss: 1.2701 - accuracy: 0.5151\n",
            "Epoch 167/1000\n",
            "57/57 - 3s - loss: 1.2703 - accuracy: 0.5163\n",
            "Epoch 168/1000\n",
            "57/57 - 3s - loss: 1.2704 - accuracy: 0.5151\n",
            "Epoch 169/1000\n",
            "57/57 - 3s - loss: 1.2608 - accuracy: 0.5214\n",
            "Epoch 170/1000\n",
            "57/57 - 3s - loss: 1.2581 - accuracy: 0.5184\n",
            "Epoch 171/1000\n",
            "57/57 - 3s - loss: 1.2664 - accuracy: 0.5185\n",
            "Epoch 172/1000\n",
            "57/57 - 3s - loss: 1.2603 - accuracy: 0.5108\n",
            "Epoch 173/1000\n",
            "57/57 - 3s - loss: 1.2614 - accuracy: 0.5225\n",
            "Epoch 174/1000\n",
            "57/57 - 3s - loss: 1.2588 - accuracy: 0.5148\n",
            "Epoch 175/1000\n",
            "57/57 - 3s - loss: 1.2633 - accuracy: 0.5162\n",
            "Epoch 176/1000\n",
            "57/57 - 3s - loss: 1.2482 - accuracy: 0.5262\n",
            "Epoch 177/1000\n",
            "57/57 - 3s - loss: 1.2549 - accuracy: 0.5176\n",
            "Epoch 178/1000\n",
            "57/57 - 3s - loss: 1.2529 - accuracy: 0.5169\n",
            "Epoch 179/1000\n",
            "57/57 - 3s - loss: 1.2519 - accuracy: 0.5249\n",
            "Epoch 180/1000\n",
            "57/57 - 3s - loss: 1.2558 - accuracy: 0.5189\n",
            "Epoch 181/1000\n",
            "57/57 - 3s - loss: 1.2521 - accuracy: 0.5198\n",
            "Epoch 182/1000\n",
            "57/57 - 3s - loss: 1.2385 - accuracy: 0.5254\n",
            "Epoch 183/1000\n",
            "57/57 - 3s - loss: 1.2446 - accuracy: 0.5276\n",
            "Epoch 184/1000\n",
            "57/57 - 3s - loss: 1.2452 - accuracy: 0.5211\n",
            "Epoch 185/1000\n",
            "57/57 - 3s - loss: 1.2403 - accuracy: 0.5229\n",
            "Epoch 186/1000\n",
            "57/57 - 3s - loss: 1.2424 - accuracy: 0.5277\n",
            "Epoch 187/1000\n",
            "57/57 - 3s - loss: 1.2401 - accuracy: 0.5301\n",
            "Epoch 188/1000\n",
            "57/57 - 3s - loss: 1.2374 - accuracy: 0.5244\n",
            "Epoch 189/1000\n",
            "57/57 - 3s - loss: 1.2402 - accuracy: 0.5232\n",
            "Epoch 190/1000\n",
            "57/57 - 3s - loss: 1.2368 - accuracy: 0.5277\n",
            "Epoch 191/1000\n",
            "57/57 - 3s - loss: 1.2359 - accuracy: 0.5276\n",
            "Epoch 192/1000\n",
            "57/57 - 3s - loss: 1.2232 - accuracy: 0.5359\n",
            "Epoch 193/1000\n",
            "57/57 - 3s - loss: 1.2272 - accuracy: 0.5301\n",
            "Epoch 194/1000\n",
            "57/57 - 3s - loss: 1.2281 - accuracy: 0.5253\n",
            "Epoch 195/1000\n",
            "57/57 - 3s - loss: 1.2313 - accuracy: 0.5317\n",
            "Epoch 196/1000\n",
            "57/57 - 3s - loss: 1.2186 - accuracy: 0.5337\n",
            "Epoch 197/1000\n",
            "57/57 - 3s - loss: 1.2174 - accuracy: 0.5334\n",
            "Epoch 198/1000\n",
            "57/57 - 3s - loss: 1.2194 - accuracy: 0.5359\n",
            "Epoch 199/1000\n",
            "57/57 - 3s - loss: 1.2162 - accuracy: 0.5320\n",
            "Epoch 200/1000\n",
            "57/57 - 3s - loss: 1.2194 - accuracy: 0.5374\n",
            "Epoch 201/1000\n",
            "57/57 - 3s - loss: 1.2105 - accuracy: 0.5374\n",
            "Epoch 202/1000\n",
            "57/57 - 3s - loss: 1.2133 - accuracy: 0.5324\n",
            "Epoch 203/1000\n",
            "57/57 - 3s - loss: 1.2082 - accuracy: 0.5335\n",
            "Epoch 204/1000\n",
            "57/57 - 3s - loss: 1.2088 - accuracy: 0.5423\n",
            "Epoch 205/1000\n",
            "57/57 - 3s - loss: 1.2080 - accuracy: 0.5375\n",
            "Epoch 206/1000\n",
            "57/57 - 3s - loss: 1.2120 - accuracy: 0.5377\n",
            "Epoch 207/1000\n",
            "57/57 - 3s - loss: 1.2023 - accuracy: 0.5418\n",
            "Epoch 208/1000\n",
            "57/57 - 3s - loss: 1.2027 - accuracy: 0.5390\n",
            "Epoch 209/1000\n",
            "57/57 - 3s - loss: 1.1948 - accuracy: 0.5456\n",
            "Epoch 210/1000\n",
            "57/57 - 3s - loss: 1.1939 - accuracy: 0.5403\n",
            "Epoch 211/1000\n",
            "57/57 - 3s - loss: 1.2065 - accuracy: 0.5404\n",
            "Epoch 212/1000\n",
            "57/57 - 3s - loss: 1.1942 - accuracy: 0.5470\n",
            "Epoch 213/1000\n",
            "57/57 - 3s - loss: 1.1931 - accuracy: 0.5491\n",
            "Epoch 214/1000\n",
            "57/57 - 3s - loss: 1.2046 - accuracy: 0.5349\n",
            "Epoch 215/1000\n",
            "57/57 - 3s - loss: 1.1958 - accuracy: 0.5421\n",
            "Epoch 216/1000\n",
            "57/57 - 3s - loss: 1.1877 - accuracy: 0.5458\n",
            "Epoch 217/1000\n",
            "57/57 - 3s - loss: 1.1858 - accuracy: 0.5403\n",
            "Epoch 218/1000\n",
            "57/57 - 3s - loss: 1.1888 - accuracy: 0.5463\n",
            "Epoch 219/1000\n",
            "57/57 - 3s - loss: 1.1864 - accuracy: 0.5488\n",
            "Epoch 220/1000\n",
            "57/57 - 3s - loss: 1.1765 - accuracy: 0.5505\n",
            "Epoch 221/1000\n",
            "57/57 - 3s - loss: 1.1786 - accuracy: 0.5467\n",
            "Epoch 222/1000\n",
            "57/57 - 3s - loss: 1.1772 - accuracy: 0.5465\n",
            "Epoch 223/1000\n",
            "57/57 - 3s - loss: 1.1798 - accuracy: 0.5450\n",
            "Epoch 224/1000\n",
            "57/57 - 3s - loss: 1.1776 - accuracy: 0.5443\n",
            "Epoch 225/1000\n",
            "57/57 - 3s - loss: 1.1794 - accuracy: 0.5483\n",
            "Epoch 226/1000\n",
            "57/57 - 3s - loss: 1.1731 - accuracy: 0.5503\n",
            "Epoch 227/1000\n",
            "57/57 - 3s - loss: 1.1715 - accuracy: 0.5529\n",
            "Epoch 228/1000\n",
            "57/57 - 3s - loss: 1.1639 - accuracy: 0.5513\n",
            "Epoch 229/1000\n",
            "57/57 - 3s - loss: 1.1637 - accuracy: 0.5536\n",
            "Epoch 230/1000\n",
            "57/57 - 3s - loss: 1.1537 - accuracy: 0.5633\n",
            "Epoch 231/1000\n",
            "57/57 - 3s - loss: 1.1669 - accuracy: 0.5538\n",
            "Epoch 232/1000\n",
            "57/57 - 3s - loss: 1.1633 - accuracy: 0.5575\n",
            "Epoch 233/1000\n",
            "57/57 - 3s - loss: 1.1648 - accuracy: 0.5540\n",
            "Epoch 234/1000\n",
            "57/57 - 3s - loss: 1.1606 - accuracy: 0.5495\n",
            "Epoch 235/1000\n",
            "57/57 - 3s - loss: 1.1559 - accuracy: 0.5657\n",
            "Epoch 236/1000\n",
            "57/57 - 3s - loss: 1.1592 - accuracy: 0.5561\n",
            "Epoch 237/1000\n",
            "57/57 - 3s - loss: 1.1456 - accuracy: 0.5601\n",
            "Epoch 238/1000\n",
            "57/57 - 3s - loss: 1.1502 - accuracy: 0.5616\n",
            "Epoch 239/1000\n",
            "57/57 - 3s - loss: 1.1543 - accuracy: 0.5619\n",
            "Epoch 240/1000\n",
            "57/57 - 3s - loss: 1.1455 - accuracy: 0.5664\n",
            "Epoch 241/1000\n",
            "57/57 - 3s - loss: 1.1420 - accuracy: 0.5580\n",
            "Epoch 242/1000\n",
            "57/57 - 3s - loss: 1.1498 - accuracy: 0.5553\n",
            "Epoch 243/1000\n",
            "57/57 - 3s - loss: 1.1378 - accuracy: 0.5609\n",
            "Epoch 244/1000\n",
            "57/57 - 3s - loss: 1.1377 - accuracy: 0.5645\n",
            "Epoch 245/1000\n",
            "57/57 - 3s - loss: 1.1427 - accuracy: 0.5664\n",
            "Epoch 246/1000\n",
            "57/57 - 3s - loss: 1.1399 - accuracy: 0.5584\n",
            "Epoch 247/1000\n",
            "57/57 - 3s - loss: 1.1339 - accuracy: 0.5651\n",
            "Epoch 248/1000\n",
            "57/57 - 3s - loss: 1.1336 - accuracy: 0.5679\n",
            "Epoch 249/1000\n",
            "57/57 - 3s - loss: 1.1257 - accuracy: 0.5681\n",
            "Epoch 250/1000\n",
            "57/57 - 3s - loss: 1.1287 - accuracy: 0.5674\n",
            "Epoch 251/1000\n",
            "57/57 - 3s - loss: 1.1248 - accuracy: 0.5722\n",
            "Epoch 252/1000\n",
            "57/57 - 3s - loss: 1.1341 - accuracy: 0.5670\n",
            "Epoch 253/1000\n",
            "57/57 - 3s - loss: 1.1172 - accuracy: 0.5743\n",
            "Epoch 254/1000\n",
            "57/57 - 3s - loss: 1.1271 - accuracy: 0.5667\n",
            "Epoch 255/1000\n",
            "57/57 - 3s - loss: 1.1139 - accuracy: 0.5663\n",
            "Epoch 256/1000\n",
            "57/57 - 3s - loss: 1.1201 - accuracy: 0.5735\n",
            "Epoch 257/1000\n",
            "57/57 - 3s - loss: 1.1237 - accuracy: 0.5685\n",
            "Epoch 258/1000\n",
            "57/57 - 3s - loss: 1.1190 - accuracy: 0.5766\n",
            "Epoch 259/1000\n",
            "57/57 - 3s - loss: 1.1120 - accuracy: 0.5710\n",
            "Epoch 260/1000\n",
            "57/57 - 3s - loss: 1.1140 - accuracy: 0.5754\n",
            "Epoch 261/1000\n",
            "57/57 - 3s - loss: 1.1081 - accuracy: 0.5740\n",
            "Epoch 262/1000\n",
            "57/57 - 3s - loss: 1.1089 - accuracy: 0.5744\n",
            "Epoch 263/1000\n",
            "57/57 - 3s - loss: 1.1063 - accuracy: 0.5857\n",
            "Epoch 264/1000\n",
            "57/57 - 3s - loss: 1.1047 - accuracy: 0.5704\n",
            "Epoch 265/1000\n",
            "57/57 - 3s - loss: 1.1073 - accuracy: 0.5754\n",
            "Epoch 266/1000\n",
            "57/57 - 3s - loss: 1.1036 - accuracy: 0.5746\n",
            "Epoch 267/1000\n",
            "57/57 - 3s - loss: 1.1017 - accuracy: 0.5790\n",
            "Epoch 268/1000\n",
            "57/57 - 3s - loss: 1.1037 - accuracy: 0.5754\n",
            "Epoch 269/1000\n",
            "57/57 - 3s - loss: 1.1025 - accuracy: 0.5747\n",
            "Epoch 270/1000\n",
            "57/57 - 3s - loss: 1.0940 - accuracy: 0.5809\n",
            "Epoch 271/1000\n",
            "57/57 - 3s - loss: 1.1035 - accuracy: 0.5758\n",
            "Epoch 272/1000\n",
            "57/57 - 3s - loss: 1.0920 - accuracy: 0.5803\n",
            "Epoch 273/1000\n",
            "57/57 - 3s - loss: 1.0924 - accuracy: 0.5819\n",
            "Epoch 274/1000\n",
            "57/57 - 3s - loss: 1.0903 - accuracy: 0.5810\n",
            "Epoch 275/1000\n",
            "57/57 - 3s - loss: 1.0870 - accuracy: 0.5845\n",
            "Epoch 276/1000\n",
            "57/57 - 3s - loss: 1.0845 - accuracy: 0.5871\n",
            "Epoch 277/1000\n",
            "57/57 - 3s - loss: 1.0859 - accuracy: 0.5836\n",
            "Epoch 278/1000\n",
            "57/57 - 3s - loss: 1.0928 - accuracy: 0.5762\n",
            "Epoch 279/1000\n",
            "57/57 - 4s - loss: 1.0814 - accuracy: 0.5897\n",
            "Epoch 280/1000\n",
            "57/57 - 3s - loss: 1.0836 - accuracy: 0.5878\n",
            "Epoch 281/1000\n",
            "57/57 - 3s - loss: 1.0876 - accuracy: 0.5856\n",
            "Epoch 282/1000\n",
            "57/57 - 3s - loss: 1.0764 - accuracy: 0.5937\n",
            "Epoch 283/1000\n",
            "57/57 - 3s - loss: 1.0734 - accuracy: 0.5874\n",
            "Epoch 284/1000\n",
            "57/57 - 3s - loss: 1.0715 - accuracy: 0.5909\n",
            "Epoch 285/1000\n",
            "57/57 - 3s - loss: 1.0709 - accuracy: 0.5940\n",
            "Epoch 286/1000\n",
            "57/57 - 3s - loss: 1.0707 - accuracy: 0.5887\n",
            "Epoch 287/1000\n",
            "57/57 - 3s - loss: 1.0676 - accuracy: 0.5885\n",
            "Epoch 288/1000\n",
            "57/57 - 3s - loss: 1.0680 - accuracy: 0.5927\n",
            "Epoch 289/1000\n",
            "57/57 - 3s - loss: 1.0629 - accuracy: 0.5878\n",
            "Epoch 290/1000\n",
            "57/57 - 3s - loss: 1.0671 - accuracy: 0.5925\n",
            "Epoch 291/1000\n",
            "57/57 - 3s - loss: 1.0668 - accuracy: 0.5945\n",
            "Epoch 292/1000\n",
            "57/57 - 3s - loss: 1.0633 - accuracy: 0.5909\n",
            "Epoch 293/1000\n",
            "57/57 - 3s - loss: 1.0565 - accuracy: 0.5971\n",
            "Epoch 294/1000\n",
            "57/57 - 3s - loss: 1.0565 - accuracy: 0.5920\n",
            "Epoch 295/1000\n",
            "57/57 - 3s - loss: 1.0652 - accuracy: 0.5909\n",
            "Epoch 296/1000\n",
            "57/57 - 3s - loss: 1.0546 - accuracy: 0.5952\n",
            "Epoch 297/1000\n",
            "57/57 - 3s - loss: 1.0525 - accuracy: 0.6000\n",
            "Epoch 298/1000\n",
            "57/57 - 3s - loss: 1.0530 - accuracy: 0.5984\n",
            "Epoch 299/1000\n",
            "57/57 - 3s - loss: 1.0499 - accuracy: 0.5981\n",
            "Epoch 300/1000\n",
            "57/57 - 3s - loss: 1.0478 - accuracy: 0.5985\n",
            "Epoch 301/1000\n",
            "57/57 - 3s - loss: 1.0475 - accuracy: 0.5973\n",
            "Epoch 302/1000\n",
            "57/57 - 3s - loss: 1.0508 - accuracy: 0.6014\n",
            "Epoch 303/1000\n",
            "57/57 - 3s - loss: 1.0444 - accuracy: 0.5987\n",
            "Epoch 304/1000\n",
            "57/57 - 3s - loss: 1.0384 - accuracy: 0.6021\n",
            "Epoch 305/1000\n",
            "57/57 - 3s - loss: 1.0366 - accuracy: 0.6033\n",
            "Epoch 306/1000\n",
            "57/57 - 3s - loss: 1.0405 - accuracy: 0.6055\n",
            "Epoch 307/1000\n",
            "57/57 - 3s - loss: 1.0470 - accuracy: 0.5973\n",
            "Epoch 308/1000\n",
            "57/57 - 3s - loss: 1.0410 - accuracy: 0.6035\n",
            "Epoch 309/1000\n",
            "57/57 - 3s - loss: 1.0294 - accuracy: 0.6149\n",
            "Epoch 310/1000\n",
            "57/57 - 3s - loss: 1.0390 - accuracy: 0.6046\n",
            "Epoch 311/1000\n",
            "57/57 - 3s - loss: 1.0358 - accuracy: 0.6018\n",
            "Epoch 312/1000\n",
            "57/57 - 3s - loss: 1.0272 - accuracy: 0.6048\n",
            "Epoch 313/1000\n",
            "57/57 - 3s - loss: 1.0308 - accuracy: 0.6050\n",
            "Epoch 314/1000\n",
            "57/57 - 3s - loss: 1.0226 - accuracy: 0.6097\n",
            "Epoch 315/1000\n",
            "57/57 - 3s - loss: 1.0252 - accuracy: 0.6062\n",
            "Epoch 316/1000\n",
            "57/57 - 3s - loss: 1.0235 - accuracy: 0.6068\n",
            "Epoch 317/1000\n",
            "57/57 - 3s - loss: 1.0211 - accuracy: 0.6084\n",
            "Epoch 318/1000\n",
            "57/57 - 3s - loss: 1.0219 - accuracy: 0.6031\n",
            "Epoch 319/1000\n",
            "57/57 - 3s - loss: 1.0242 - accuracy: 0.6021\n",
            "Epoch 320/1000\n",
            "57/57 - 3s - loss: 1.0185 - accuracy: 0.6097\n",
            "Epoch 321/1000\n",
            "57/57 - 3s - loss: 1.0159 - accuracy: 0.6022\n",
            "Epoch 322/1000\n",
            "57/57 - 3s - loss: 1.0145 - accuracy: 0.6088\n",
            "Epoch 323/1000\n",
            "57/57 - 3s - loss: 1.0122 - accuracy: 0.6163\n",
            "Epoch 324/1000\n",
            "57/57 - 3s - loss: 1.0087 - accuracy: 0.6119\n",
            "Epoch 325/1000\n",
            "57/57 - 3s - loss: 1.0094 - accuracy: 0.6094\n",
            "Epoch 326/1000\n",
            "57/57 - 3s - loss: 1.0046 - accuracy: 0.6108\n",
            "Epoch 327/1000\n",
            "57/57 - 3s - loss: 1.0084 - accuracy: 0.6148\n",
            "Epoch 328/1000\n",
            "57/57 - 3s - loss: 1.0029 - accuracy: 0.6083\n",
            "Epoch 329/1000\n",
            "57/57 - 3s - loss: 1.0032 - accuracy: 0.6088\n",
            "Epoch 330/1000\n",
            "57/57 - 3s - loss: 1.0043 - accuracy: 0.6171\n",
            "Epoch 331/1000\n",
            "57/57 - 3s - loss: 1.0067 - accuracy: 0.6127\n",
            "Epoch 332/1000\n",
            "57/57 - 3s - loss: 1.0004 - accuracy: 0.6168\n",
            "Epoch 333/1000\n",
            "57/57 - 3s - loss: 0.9986 - accuracy: 0.6223\n",
            "Epoch 334/1000\n",
            "57/57 - 3s - loss: 0.9965 - accuracy: 0.6167\n",
            "Epoch 335/1000\n",
            "57/57 - 3s - loss: 0.9912 - accuracy: 0.6186\n",
            "Epoch 336/1000\n",
            "57/57 - 3s - loss: 0.9949 - accuracy: 0.6188\n",
            "Epoch 337/1000\n",
            "57/57 - 3s - loss: 0.9864 - accuracy: 0.6300\n",
            "Epoch 338/1000\n",
            "57/57 - 3s - loss: 0.9919 - accuracy: 0.6222\n",
            "Epoch 339/1000\n",
            "57/57 - 3s - loss: 0.9957 - accuracy: 0.6208\n",
            "Epoch 340/1000\n",
            "57/57 - 3s - loss: 0.9996 - accuracy: 0.6222\n",
            "Epoch 341/1000\n",
            "57/57 - 3s - loss: 0.9834 - accuracy: 0.6226\n",
            "Epoch 342/1000\n",
            "57/57 - 3s - loss: 0.9882 - accuracy: 0.6197\n",
            "Epoch 343/1000\n",
            "57/57 - 3s - loss: 0.9871 - accuracy: 0.6164\n",
            "Epoch 344/1000\n",
            "57/57 - 3s - loss: 0.9865 - accuracy: 0.6238\n",
            "Epoch 345/1000\n",
            "57/57 - 3s - loss: 0.9805 - accuracy: 0.6256\n",
            "Epoch 346/1000\n",
            "57/57 - 3s - loss: 0.9772 - accuracy: 0.6181\n",
            "Epoch 347/1000\n",
            "57/57 - 3s - loss: 0.9896 - accuracy: 0.6219\n",
            "Epoch 348/1000\n",
            "57/57 - 3s - loss: 0.9774 - accuracy: 0.6295\n",
            "Epoch 349/1000\n",
            "57/57 - 3s - loss: 0.9726 - accuracy: 0.6273\n",
            "Epoch 350/1000\n",
            "57/57 - 3s - loss: 0.9772 - accuracy: 0.6259\n",
            "Epoch 351/1000\n",
            "57/57 - 3s - loss: 0.9604 - accuracy: 0.6303\n",
            "Epoch 352/1000\n",
            "57/57 - 3s - loss: 0.9698 - accuracy: 0.6344\n",
            "Epoch 353/1000\n",
            "57/57 - 3s - loss: 0.9775 - accuracy: 0.6219\n",
            "Epoch 354/1000\n",
            "57/57 - 3s - loss: 0.9706 - accuracy: 0.6260\n",
            "Epoch 355/1000\n",
            "57/57 - 3s - loss: 0.9678 - accuracy: 0.6309\n",
            "Epoch 356/1000\n",
            "57/57 - 3s - loss: 0.9676 - accuracy: 0.6251\n",
            "Epoch 357/1000\n",
            "57/57 - 3s - loss: 0.9684 - accuracy: 0.6273\n",
            "Epoch 358/1000\n",
            "57/57 - 3s - loss: 0.9556 - accuracy: 0.6350\n",
            "Epoch 359/1000\n",
            "57/57 - 3s - loss: 0.9566 - accuracy: 0.6354\n",
            "Epoch 360/1000\n",
            "57/57 - 3s - loss: 0.9605 - accuracy: 0.6280\n",
            "Epoch 361/1000\n",
            "57/57 - 3s - loss: 0.9504 - accuracy: 0.6299\n",
            "Epoch 362/1000\n",
            "57/57 - 3s - loss: 0.9614 - accuracy: 0.6321\n",
            "Epoch 363/1000\n",
            "57/57 - 3s - loss: 0.9592 - accuracy: 0.6295\n",
            "Epoch 364/1000\n",
            "57/57 - 3s - loss: 0.9536 - accuracy: 0.6362\n",
            "Epoch 365/1000\n",
            "57/57 - 3s - loss: 0.9611 - accuracy: 0.6318\n",
            "Epoch 366/1000\n",
            "57/57 - 3s - loss: 0.9553 - accuracy: 0.6338\n",
            "Epoch 367/1000\n",
            "57/57 - 3s - loss: 0.9472 - accuracy: 0.6389\n",
            "Epoch 368/1000\n",
            "57/57 - 3s - loss: 0.9526 - accuracy: 0.6344\n",
            "Epoch 369/1000\n",
            "57/57 - 3s - loss: 0.9508 - accuracy: 0.6342\n",
            "Epoch 370/1000\n",
            "57/57 - 3s - loss: 0.9409 - accuracy: 0.6420\n",
            "Epoch 371/1000\n",
            "57/57 - 3s - loss: 0.9452 - accuracy: 0.6368\n",
            "Epoch 372/1000\n",
            "57/57 - 3s - loss: 0.9410 - accuracy: 0.6433\n",
            "Epoch 373/1000\n",
            "57/57 - 3s - loss: 0.9429 - accuracy: 0.6373\n",
            "Epoch 374/1000\n",
            "57/57 - 3s - loss: 0.9363 - accuracy: 0.6423\n",
            "Epoch 375/1000\n",
            "57/57 - 3s - loss: 0.9262 - accuracy: 0.6466\n",
            "Epoch 376/1000\n",
            "57/57 - 3s - loss: 0.9302 - accuracy: 0.6426\n",
            "Epoch 377/1000\n",
            "57/57 - 3s - loss: 0.9321 - accuracy: 0.6448\n",
            "Epoch 378/1000\n",
            "57/57 - 3s - loss: 0.9359 - accuracy: 0.6415\n",
            "Epoch 379/1000\n",
            "57/57 - 3s - loss: 0.9249 - accuracy: 0.6473\n",
            "Epoch 380/1000\n",
            "57/57 - 3s - loss: 0.9221 - accuracy: 0.6453\n",
            "Epoch 381/1000\n",
            "57/57 - 3s - loss: 0.9247 - accuracy: 0.6451\n",
            "Epoch 382/1000\n",
            "57/57 - 3s - loss: 0.9317 - accuracy: 0.6473\n",
            "Epoch 383/1000\n",
            "57/57 - 3s - loss: 0.9330 - accuracy: 0.6431\n",
            "Epoch 384/1000\n",
            "57/57 - 3s - loss: 0.9297 - accuracy: 0.6427\n",
            "Epoch 385/1000\n",
            "57/57 - 3s - loss: 0.9309 - accuracy: 0.6453\n",
            "Epoch 386/1000\n",
            "57/57 - 3s - loss: 0.9175 - accuracy: 0.6515\n",
            "Epoch 387/1000\n",
            "57/57 - 3s - loss: 0.9156 - accuracy: 0.6547\n",
            "Epoch 388/1000\n",
            "57/57 - 3s - loss: 0.9320 - accuracy: 0.6439\n",
            "Epoch 389/1000\n",
            "57/57 - 3s - loss: 0.9223 - accuracy: 0.6453\n",
            "Epoch 390/1000\n",
            "57/57 - 3s - loss: 0.9216 - accuracy: 0.6473\n",
            "Epoch 391/1000\n",
            "57/57 - 3s - loss: 0.9151 - accuracy: 0.6466\n",
            "Epoch 392/1000\n",
            "57/57 - 3s - loss: 0.9168 - accuracy: 0.6473\n",
            "Epoch 393/1000\n",
            "57/57 - 3s - loss: 0.9161 - accuracy: 0.6489\n",
            "Epoch 394/1000\n",
            "57/57 - 3s - loss: 0.9129 - accuracy: 0.6510\n",
            "Epoch 395/1000\n",
            "57/57 - 3s - loss: 0.8998 - accuracy: 0.6563\n",
            "Epoch 396/1000\n",
            "57/57 - 3s - loss: 0.8993 - accuracy: 0.6541\n",
            "Epoch 397/1000\n",
            "57/57 - 3s - loss: 0.9056 - accuracy: 0.6584\n",
            "Epoch 398/1000\n",
            "57/57 - 3s - loss: 0.9101 - accuracy: 0.6550\n",
            "Epoch 399/1000\n",
            "57/57 - 3s - loss: 0.9078 - accuracy: 0.6493\n",
            "Epoch 400/1000\n",
            "57/57 - 3s - loss: 0.9065 - accuracy: 0.6584\n",
            "Epoch 401/1000\n",
            "57/57 - 3s - loss: 0.8885 - accuracy: 0.6664\n",
            "Epoch 402/1000\n",
            "57/57 - 3s - loss: 0.9051 - accuracy: 0.6530\n",
            "Epoch 403/1000\n",
            "57/57 - 3s - loss: 0.8863 - accuracy: 0.6667\n",
            "Epoch 404/1000\n",
            "57/57 - 3s - loss: 0.8933 - accuracy: 0.6599\n",
            "Epoch 405/1000\n",
            "57/57 - 3s - loss: 0.8885 - accuracy: 0.6529\n",
            "Epoch 406/1000\n",
            "57/57 - 3s - loss: 0.8934 - accuracy: 0.6585\n",
            "Epoch 407/1000\n",
            "57/57 - 3s - loss: 0.8939 - accuracy: 0.6614\n",
            "Epoch 408/1000\n",
            "57/57 - 3s - loss: 0.8805 - accuracy: 0.6660\n",
            "Epoch 409/1000\n",
            "57/57 - 3s - loss: 0.8900 - accuracy: 0.6610\n",
            "Epoch 410/1000\n",
            "57/57 - 3s - loss: 0.8807 - accuracy: 0.6601\n",
            "Epoch 411/1000\n",
            "57/57 - 3s - loss: 0.8853 - accuracy: 0.6558\n",
            "Epoch 412/1000\n",
            "57/57 - 3s - loss: 0.8881 - accuracy: 0.6610\n",
            "Epoch 413/1000\n",
            "57/57 - 3s - loss: 0.8864 - accuracy: 0.6550\n",
            "Epoch 414/1000\n",
            "57/57 - 3s - loss: 0.8833 - accuracy: 0.6591\n",
            "Epoch 415/1000\n",
            "57/57 - 3s - loss: 0.8783 - accuracy: 0.6654\n",
            "Epoch 416/1000\n",
            "57/57 - 3s - loss: 0.8754 - accuracy: 0.6623\n",
            "Epoch 417/1000\n",
            "57/57 - 3s - loss: 0.8856 - accuracy: 0.6667\n",
            "Epoch 418/1000\n",
            "57/57 - 3s - loss: 0.8829 - accuracy: 0.6595\n",
            "Epoch 419/1000\n",
            "57/57 - 3s - loss: 0.8820 - accuracy: 0.6634\n",
            "Epoch 420/1000\n",
            "57/57 - 3s - loss: 0.8778 - accuracy: 0.6643\n",
            "Epoch 421/1000\n",
            "57/57 - 3s - loss: 0.8716 - accuracy: 0.6641\n",
            "Epoch 422/1000\n",
            "57/57 - 3s - loss: 0.8752 - accuracy: 0.6612\n",
            "Epoch 423/1000\n",
            "57/57 - 3s - loss: 0.8649 - accuracy: 0.6734\n",
            "Epoch 424/1000\n",
            "57/57 - 3s - loss: 0.8725 - accuracy: 0.6696\n",
            "Epoch 425/1000\n",
            "57/57 - 3s - loss: 0.8701 - accuracy: 0.6650\n",
            "Epoch 426/1000\n",
            "57/57 - 3s - loss: 0.8587 - accuracy: 0.6736\n",
            "Epoch 427/1000\n",
            "57/57 - 3s - loss: 0.8612 - accuracy: 0.6702\n",
            "Epoch 428/1000\n",
            "57/57 - 3s - loss: 0.8625 - accuracy: 0.6711\n",
            "Epoch 429/1000\n",
            "57/57 - 3s - loss: 0.8635 - accuracy: 0.6625\n",
            "Epoch 430/1000\n",
            "57/57 - 3s - loss: 0.8586 - accuracy: 0.6736\n",
            "Epoch 431/1000\n",
            "57/57 - 3s - loss: 0.8602 - accuracy: 0.6661\n",
            "Epoch 432/1000\n",
            "57/57 - 3s - loss: 0.8644 - accuracy: 0.6707\n",
            "Epoch 433/1000\n",
            "57/57 - 3s - loss: 0.8640 - accuracy: 0.6698\n",
            "Epoch 434/1000\n",
            "57/57 - 3s - loss: 0.8539 - accuracy: 0.6775\n",
            "Epoch 435/1000\n",
            "57/57 - 3s - loss: 0.8586 - accuracy: 0.6657\n",
            "Epoch 436/1000\n",
            "57/57 - 3s - loss: 0.8579 - accuracy: 0.6796\n",
            "Epoch 437/1000\n",
            "57/57 - 3s - loss: 0.8468 - accuracy: 0.6763\n",
            "Epoch 438/1000\n",
            "57/57 - 3s - loss: 0.8472 - accuracy: 0.6741\n",
            "Epoch 439/1000\n",
            "57/57 - 3s - loss: 0.8519 - accuracy: 0.6753\n",
            "Epoch 440/1000\n",
            "57/57 - 3s - loss: 0.8421 - accuracy: 0.6803\n",
            "Epoch 441/1000\n",
            "57/57 - 3s - loss: 0.8483 - accuracy: 0.6737\n",
            "Epoch 442/1000\n",
            "57/57 - 3s - loss: 0.8660 - accuracy: 0.6751\n",
            "Epoch 443/1000\n",
            "57/57 - 3s - loss: 0.8370 - accuracy: 0.6786\n",
            "Epoch 444/1000\n",
            "57/57 - 3s - loss: 0.8388 - accuracy: 0.6788\n",
            "Epoch 445/1000\n",
            "57/57 - 3s - loss: 0.8335 - accuracy: 0.6815\n",
            "Epoch 446/1000\n",
            "57/57 - 3s - loss: 0.8325 - accuracy: 0.6811\n",
            "Epoch 447/1000\n",
            "57/57 - 3s - loss: 0.8359 - accuracy: 0.6810\n",
            "Epoch 448/1000\n",
            "57/57 - 3s - loss: 0.8373 - accuracy: 0.6836\n",
            "Epoch 449/1000\n",
            "57/57 - 3s - loss: 0.8362 - accuracy: 0.6742\n",
            "Epoch 450/1000\n",
            "57/57 - 3s - loss: 0.8337 - accuracy: 0.6832\n",
            "Epoch 451/1000\n",
            "57/57 - 3s - loss: 0.8414 - accuracy: 0.6759\n",
            "Epoch 452/1000\n",
            "57/57 - 3s - loss: 0.8328 - accuracy: 0.6826\n",
            "Epoch 453/1000\n",
            "57/57 - 3s - loss: 0.8256 - accuracy: 0.6818\n",
            "Epoch 454/1000\n",
            "57/57 - 3s - loss: 0.8331 - accuracy: 0.6808\n",
            "Epoch 455/1000\n",
            "57/57 - 3s - loss: 0.8201 - accuracy: 0.6814\n",
            "Epoch 456/1000\n",
            "57/57 - 3s - loss: 0.8325 - accuracy: 0.6795\n",
            "Epoch 457/1000\n",
            "57/57 - 3s - loss: 0.8288 - accuracy: 0.6770\n",
            "Epoch 458/1000\n",
            "57/57 - 3s - loss: 0.8235 - accuracy: 0.6793\n",
            "Epoch 459/1000\n",
            "57/57 - 3s - loss: 0.8145 - accuracy: 0.6881\n",
            "Epoch 460/1000\n",
            "57/57 - 3s - loss: 0.8140 - accuracy: 0.6888\n",
            "Epoch 461/1000\n",
            "57/57 - 3s - loss: 0.8243 - accuracy: 0.6842\n",
            "Epoch 462/1000\n",
            "57/57 - 3s - loss: 0.8153 - accuracy: 0.6854\n",
            "Epoch 463/1000\n",
            "57/57 - 3s - loss: 0.8153 - accuracy: 0.6833\n",
            "Epoch 464/1000\n",
            "57/57 - 3s - loss: 0.8194 - accuracy: 0.6881\n",
            "Epoch 465/1000\n",
            "57/57 - 3s - loss: 0.8182 - accuracy: 0.6858\n",
            "Epoch 466/1000\n",
            "57/57 - 3s - loss: 0.8054 - accuracy: 0.6916\n",
            "Epoch 467/1000\n",
            "57/57 - 3s - loss: 0.8209 - accuracy: 0.6824\n",
            "Epoch 468/1000\n",
            "57/57 - 3s - loss: 0.8128 - accuracy: 0.6887\n",
            "Epoch 469/1000\n",
            "57/57 - 3s - loss: 0.8023 - accuracy: 0.6923\n",
            "Epoch 470/1000\n",
            "57/57 - 3s - loss: 0.8141 - accuracy: 0.6857\n",
            "Epoch 471/1000\n",
            "57/57 - 3s - loss: 0.8120 - accuracy: 0.6883\n",
            "Epoch 472/1000\n",
            "57/57 - 3s - loss: 0.7957 - accuracy: 0.6937\n",
            "Epoch 473/1000\n",
            "57/57 - 3s - loss: 0.7992 - accuracy: 0.6930\n",
            "Epoch 474/1000\n",
            "57/57 - 3s - loss: 0.8082 - accuracy: 0.6948\n",
            "Epoch 475/1000\n",
            "57/57 - 3s - loss: 0.8048 - accuracy: 0.6906\n",
            "Epoch 476/1000\n",
            "57/57 - 3s - loss: 0.8045 - accuracy: 0.6901\n",
            "Epoch 477/1000\n",
            "57/57 - 3s - loss: 0.8001 - accuracy: 0.6917\n",
            "Epoch 478/1000\n",
            "57/57 - 3s - loss: 0.7935 - accuracy: 0.6970\n",
            "Epoch 479/1000\n",
            "57/57 - 3s - loss: 0.7920 - accuracy: 0.6961\n",
            "Epoch 480/1000\n",
            "57/57 - 3s - loss: 0.7969 - accuracy: 0.6923\n",
            "Epoch 481/1000\n",
            "57/57 - 3s - loss: 0.7975 - accuracy: 0.6964\n",
            "Epoch 482/1000\n",
            "57/57 - 3s - loss: 0.7987 - accuracy: 0.6946\n",
            "Epoch 483/1000\n",
            "57/57 - 3s - loss: 0.7909 - accuracy: 0.7000\n",
            "Epoch 484/1000\n",
            "57/57 - 3s - loss: 0.8021 - accuracy: 0.6886\n",
            "Epoch 485/1000\n",
            "57/57 - 3s - loss: 0.7912 - accuracy: 0.7004\n",
            "Epoch 486/1000\n",
            "57/57 - 3s - loss: 0.7825 - accuracy: 0.7022\n",
            "Epoch 487/1000\n",
            "57/57 - 3s - loss: 0.7800 - accuracy: 0.6986\n",
            "Epoch 488/1000\n",
            "57/57 - 3s - loss: 0.7856 - accuracy: 0.6949\n",
            "Epoch 489/1000\n",
            "57/57 - 3s - loss: 0.7809 - accuracy: 0.6983\n",
            "Epoch 490/1000\n",
            "57/57 - 3s - loss: 0.7896 - accuracy: 0.6971\n",
            "Epoch 491/1000\n",
            "57/57 - 3s - loss: 0.7732 - accuracy: 0.7047\n",
            "Epoch 492/1000\n",
            "57/57 - 3s - loss: 0.7808 - accuracy: 0.6982\n",
            "Epoch 493/1000\n",
            "57/57 - 3s - loss: 0.7808 - accuracy: 0.7037\n",
            "Epoch 494/1000\n",
            "57/57 - 3s - loss: 0.7834 - accuracy: 0.6993\n",
            "Epoch 495/1000\n",
            "57/57 - 3s - loss: 0.7735 - accuracy: 0.7016\n",
            "Epoch 496/1000\n",
            "57/57 - 3s - loss: 0.7787 - accuracy: 0.7016\n",
            "Epoch 497/1000\n",
            "57/57 - 3s - loss: 0.7767 - accuracy: 0.6996\n",
            "Epoch 498/1000\n",
            "57/57 - 5s - loss: 0.7722 - accuracy: 0.7023\n",
            "Epoch 499/1000\n",
            "57/57 - 4s - loss: 0.7769 - accuracy: 0.7029\n",
            "Epoch 500/1000\n",
            "57/57 - 3s - loss: 0.7734 - accuracy: 0.6981\n",
            "Epoch 501/1000\n",
            "57/57 - 3s - loss: 0.7731 - accuracy: 0.7023\n",
            "Epoch 502/1000\n",
            "57/57 - 3s - loss: 0.7735 - accuracy: 0.7021\n",
            "Epoch 503/1000\n",
            "57/57 - 3s - loss: 0.7749 - accuracy: 0.7037\n",
            "Epoch 504/1000\n",
            "57/57 - 3s - loss: 0.7671 - accuracy: 0.7066\n",
            "Epoch 505/1000\n",
            "57/57 - 3s - loss: 0.7629 - accuracy: 0.7084\n",
            "Epoch 506/1000\n",
            "57/57 - 3s - loss: 0.7696 - accuracy: 0.7073\n",
            "Epoch 507/1000\n",
            "57/57 - 3s - loss: 0.7622 - accuracy: 0.7139\n",
            "Epoch 508/1000\n",
            "57/57 - 3s - loss: 0.7723 - accuracy: 0.7034\n",
            "Epoch 509/1000\n",
            "57/57 - 3s - loss: 0.7626 - accuracy: 0.7099\n",
            "Epoch 510/1000\n",
            "57/57 - 3s - loss: 0.7549 - accuracy: 0.7088\n",
            "Epoch 511/1000\n",
            "57/57 - 3s - loss: 0.7578 - accuracy: 0.7092\n",
            "Epoch 512/1000\n",
            "57/57 - 3s - loss: 0.7581 - accuracy: 0.7073\n",
            "Epoch 513/1000\n",
            "57/57 - 3s - loss: 0.7671 - accuracy: 0.7093\n",
            "Epoch 514/1000\n",
            "57/57 - 3s - loss: 0.7603 - accuracy: 0.7089\n",
            "Epoch 515/1000\n",
            "57/57 - 3s - loss: 0.7480 - accuracy: 0.7158\n",
            "Epoch 516/1000\n",
            "57/57 - 3s - loss: 0.7632 - accuracy: 0.7071\n",
            "Epoch 517/1000\n",
            "57/57 - 3s - loss: 0.7522 - accuracy: 0.7135\n",
            "Epoch 518/1000\n",
            "57/57 - 3s - loss: 0.7487 - accuracy: 0.7093\n",
            "Epoch 519/1000\n",
            "57/57 - 3s - loss: 0.7382 - accuracy: 0.7215\n",
            "Epoch 520/1000\n",
            "57/57 - 3s - loss: 0.7597 - accuracy: 0.7056\n",
            "Epoch 521/1000\n",
            "57/57 - 3s - loss: 0.7437 - accuracy: 0.7132\n",
            "Epoch 522/1000\n",
            "57/57 - 3s - loss: 0.7415 - accuracy: 0.7120\n",
            "Epoch 523/1000\n",
            "57/57 - 3s - loss: 0.7322 - accuracy: 0.7183\n",
            "Epoch 524/1000\n",
            "57/57 - 3s - loss: 0.7464 - accuracy: 0.7111\n",
            "Epoch 525/1000\n",
            "57/57 - 3s - loss: 0.7573 - accuracy: 0.7128\n",
            "Epoch 526/1000\n",
            "57/57 - 3s - loss: 0.7400 - accuracy: 0.7173\n",
            "Epoch 527/1000\n",
            "57/57 - 3s - loss: 0.7448 - accuracy: 0.7157\n",
            "Epoch 528/1000\n",
            "57/57 - 3s - loss: 0.7407 - accuracy: 0.7133\n",
            "Epoch 529/1000\n",
            "57/57 - 3s - loss: 0.7273 - accuracy: 0.7235\n",
            "Epoch 530/1000\n",
            "57/57 - 3s - loss: 0.7429 - accuracy: 0.7173\n",
            "Epoch 531/1000\n",
            "57/57 - 3s - loss: 0.7406 - accuracy: 0.7120\n",
            "Epoch 532/1000\n",
            "57/57 - 3s - loss: 0.7398 - accuracy: 0.7146\n",
            "Epoch 533/1000\n",
            "57/57 - 3s - loss: 0.7370 - accuracy: 0.7216\n",
            "Epoch 534/1000\n",
            "57/57 - 3s - loss: 0.7321 - accuracy: 0.7198\n",
            "Epoch 535/1000\n",
            "57/57 - 3s - loss: 0.7253 - accuracy: 0.7261\n",
            "Epoch 536/1000\n",
            "57/57 - 3s - loss: 0.7270 - accuracy: 0.7241\n",
            "Epoch 537/1000\n",
            "57/57 - 3s - loss: 0.7250 - accuracy: 0.7238\n",
            "Epoch 538/1000\n",
            "57/57 - 3s - loss: 0.7264 - accuracy: 0.7182\n",
            "Epoch 539/1000\n",
            "57/57 - 3s - loss: 0.7251 - accuracy: 0.7184\n",
            "Epoch 540/1000\n",
            "57/57 - 3s - loss: 0.7298 - accuracy: 0.7195\n",
            "Epoch 541/1000\n",
            "57/57 - 3s - loss: 0.7298 - accuracy: 0.7191\n",
            "Epoch 542/1000\n",
            "57/57 - 3s - loss: 0.7223 - accuracy: 0.7244\n",
            "Epoch 543/1000\n",
            "57/57 - 3s - loss: 0.7239 - accuracy: 0.7227\n",
            "Epoch 544/1000\n",
            "57/57 - 3s - loss: 0.7169 - accuracy: 0.7205\n",
            "Epoch 545/1000\n",
            "57/57 - 3s - loss: 0.7248 - accuracy: 0.7187\n",
            "Epoch 546/1000\n",
            "57/57 - 3s - loss: 0.7135 - accuracy: 0.7227\n",
            "Epoch 547/1000\n",
            "57/57 - 3s - loss: 0.7256 - accuracy: 0.7220\n",
            "Epoch 548/1000\n",
            "57/57 - 3s - loss: 0.7259 - accuracy: 0.7184\n",
            "Epoch 549/1000\n",
            "57/57 - 3s - loss: 0.7192 - accuracy: 0.7242\n",
            "Epoch 550/1000\n",
            "57/57 - 3s - loss: 0.7189 - accuracy: 0.7202\n",
            "Epoch 551/1000\n",
            "57/57 - 3s - loss: 0.7053 - accuracy: 0.7257\n",
            "Epoch 552/1000\n",
            "57/57 - 3s - loss: 0.7113 - accuracy: 0.7238\n",
            "Epoch 553/1000\n",
            "57/57 - 3s - loss: 0.7274 - accuracy: 0.7140\n",
            "Epoch 554/1000\n",
            "57/57 - 3s - loss: 0.7127 - accuracy: 0.7303\n",
            "Epoch 555/1000\n",
            "57/57 - 3s - loss: 0.7138 - accuracy: 0.7274\n",
            "Epoch 556/1000\n",
            "57/57 - 3s - loss: 0.7157 - accuracy: 0.7216\n",
            "Epoch 557/1000\n",
            "57/57 - 3s - loss: 0.7032 - accuracy: 0.7249\n",
            "Epoch 558/1000\n",
            "57/57 - 3s - loss: 0.7069 - accuracy: 0.7266\n",
            "Epoch 559/1000\n",
            "57/57 - 3s - loss: 0.6997 - accuracy: 0.7322\n",
            "Epoch 560/1000\n",
            "57/57 - 3s - loss: 0.7016 - accuracy: 0.7311\n",
            "Epoch 561/1000\n",
            "57/57 - 3s - loss: 0.6941 - accuracy: 0.7340\n",
            "Epoch 562/1000\n",
            "57/57 - 3s - loss: 0.6990 - accuracy: 0.7340\n",
            "Epoch 563/1000\n",
            "57/57 - 3s - loss: 0.7005 - accuracy: 0.7307\n",
            "Epoch 564/1000\n",
            "57/57 - 3s - loss: 0.7031 - accuracy: 0.7352\n",
            "Epoch 565/1000\n",
            "57/57 - 3s - loss: 0.7007 - accuracy: 0.7285\n",
            "Epoch 566/1000\n",
            "57/57 - 3s - loss: 0.6938 - accuracy: 0.7334\n",
            "Epoch 567/1000\n",
            "57/57 - 3s - loss: 0.7014 - accuracy: 0.7318\n",
            "Epoch 568/1000\n",
            "57/57 - 3s - loss: 0.7046 - accuracy: 0.7296\n",
            "Epoch 569/1000\n",
            "57/57 - 3s - loss: 0.6949 - accuracy: 0.7352\n",
            "Epoch 570/1000\n",
            "57/57 - 3s - loss: 0.6959 - accuracy: 0.7317\n",
            "Epoch 571/1000\n",
            "57/57 - 3s - loss: 0.6960 - accuracy: 0.7308\n",
            "Epoch 572/1000\n",
            "57/57 - 3s - loss: 0.6964 - accuracy: 0.7339\n",
            "Epoch 573/1000\n",
            "57/57 - 3s - loss: 0.6970 - accuracy: 0.7319\n",
            "Epoch 574/1000\n",
            "57/57 - 3s - loss: 0.6926 - accuracy: 0.7329\n",
            "Epoch 575/1000\n",
            "57/57 - 3s - loss: 0.6909 - accuracy: 0.7306\n",
            "Epoch 576/1000\n",
            "57/57 - 3s - loss: 0.6842 - accuracy: 0.7383\n",
            "Epoch 577/1000\n",
            "57/57 - 3s - loss: 0.6829 - accuracy: 0.7354\n",
            "Epoch 578/1000\n",
            "57/57 - 3s - loss: 0.6908 - accuracy: 0.7344\n",
            "Epoch 579/1000\n",
            "57/57 - 3s - loss: 0.6871 - accuracy: 0.7362\n",
            "Epoch 580/1000\n",
            "57/57 - 3s - loss: 0.6970 - accuracy: 0.7350\n",
            "Epoch 581/1000\n",
            "57/57 - 3s - loss: 0.6880 - accuracy: 0.7354\n",
            "Epoch 582/1000\n",
            "57/57 - 3s - loss: 0.6876 - accuracy: 0.7367\n",
            "Epoch 583/1000\n",
            "57/57 - 3s - loss: 0.6926 - accuracy: 0.7345\n",
            "Epoch 584/1000\n",
            "57/57 - 3s - loss: 0.6757 - accuracy: 0.7348\n",
            "Epoch 585/1000\n",
            "57/57 - 3s - loss: 0.6732 - accuracy: 0.7378\n",
            "Epoch 586/1000\n",
            "57/57 - 3s - loss: 0.6914 - accuracy: 0.7333\n",
            "Epoch 587/1000\n",
            "57/57 - 3s - loss: 0.6769 - accuracy: 0.7372\n",
            "Epoch 588/1000\n",
            "57/57 - 3s - loss: 0.6693 - accuracy: 0.7443\n",
            "Epoch 589/1000\n",
            "57/57 - 3s - loss: 0.6757 - accuracy: 0.7401\n",
            "Epoch 590/1000\n",
            "57/57 - 3s - loss: 0.6719 - accuracy: 0.7429\n",
            "Epoch 591/1000\n",
            "57/57 - 3s - loss: 0.6656 - accuracy: 0.7398\n",
            "Epoch 592/1000\n",
            "57/57 - 3s - loss: 0.6648 - accuracy: 0.7467\n",
            "Epoch 593/1000\n",
            "57/57 - 3s - loss: 0.6760 - accuracy: 0.7340\n",
            "Epoch 594/1000\n",
            "57/57 - 3s - loss: 0.6650 - accuracy: 0.7472\n",
            "Epoch 595/1000\n",
            "57/57 - 3s - loss: 0.6672 - accuracy: 0.7392\n",
            "Epoch 596/1000\n",
            "57/57 - 3s - loss: 0.6603 - accuracy: 0.7438\n",
            "Epoch 597/1000\n",
            "57/57 - 3s - loss: 0.6632 - accuracy: 0.7461\n",
            "Epoch 598/1000\n",
            "57/57 - 3s - loss: 0.6606 - accuracy: 0.7406\n",
            "Epoch 599/1000\n",
            "57/57 - 3s - loss: 0.6559 - accuracy: 0.7504\n",
            "Epoch 600/1000\n",
            "57/57 - 3s - loss: 0.6694 - accuracy: 0.7399\n",
            "Epoch 601/1000\n",
            "57/57 - 3s - loss: 0.6655 - accuracy: 0.7475\n",
            "Epoch 602/1000\n",
            "57/57 - 3s - loss: 0.6577 - accuracy: 0.7468\n",
            "Epoch 603/1000\n",
            "57/57 - 3s - loss: 0.6565 - accuracy: 0.7456\n",
            "Epoch 604/1000\n",
            "57/57 - 3s - loss: 0.6572 - accuracy: 0.7480\n",
            "Epoch 605/1000\n",
            "57/57 - 3s - loss: 0.6571 - accuracy: 0.7494\n",
            "Epoch 606/1000\n",
            "57/57 - 3s - loss: 0.6621 - accuracy: 0.7446\n",
            "Epoch 607/1000\n",
            "57/57 - 3s - loss: 0.6605 - accuracy: 0.7446\n",
            "Epoch 608/1000\n",
            "57/57 - 3s - loss: 0.6526 - accuracy: 0.7451\n",
            "Epoch 609/1000\n",
            "57/57 - 3s - loss: 0.6595 - accuracy: 0.7440\n",
            "Epoch 610/1000\n",
            "57/57 - 3s - loss: 0.6526 - accuracy: 0.7478\n",
            "Epoch 611/1000\n",
            "57/57 - 3s - loss: 0.6519 - accuracy: 0.7450\n",
            "Epoch 612/1000\n",
            "57/57 - 3s - loss: 0.6465 - accuracy: 0.7500\n",
            "Epoch 613/1000\n",
            "57/57 - 3s - loss: 0.6487 - accuracy: 0.7496\n",
            "Epoch 614/1000\n",
            "57/57 - 3s - loss: 0.6600 - accuracy: 0.7407\n",
            "Epoch 615/1000\n",
            "57/57 - 3s - loss: 0.6468 - accuracy: 0.7485\n",
            "Epoch 616/1000\n",
            "57/57 - 3s - loss: 0.6494 - accuracy: 0.7559\n",
            "Epoch 617/1000\n",
            "57/57 - 3s - loss: 0.6397 - accuracy: 0.7515\n",
            "Epoch 618/1000\n",
            "57/57 - 3s - loss: 0.6415 - accuracy: 0.7498\n",
            "Epoch 619/1000\n",
            "57/57 - 3s - loss: 0.6393 - accuracy: 0.7531\n",
            "Epoch 620/1000\n",
            "57/57 - 3s - loss: 0.6450 - accuracy: 0.7526\n",
            "Epoch 621/1000\n",
            "57/57 - 3s - loss: 0.6459 - accuracy: 0.7535\n",
            "Epoch 622/1000\n",
            "57/57 - 3s - loss: 0.6400 - accuracy: 0.7566\n",
            "Epoch 623/1000\n",
            "57/57 - 3s - loss: 0.6383 - accuracy: 0.7545\n",
            "Epoch 624/1000\n",
            "57/57 - 3s - loss: 0.6317 - accuracy: 0.7555\n",
            "Epoch 625/1000\n",
            "57/57 - 3s - loss: 0.6485 - accuracy: 0.7507\n",
            "Epoch 626/1000\n",
            "57/57 - 3s - loss: 0.6421 - accuracy: 0.7538\n",
            "Epoch 627/1000\n",
            "57/57 - 3s - loss: 0.6299 - accuracy: 0.7497\n",
            "Epoch 628/1000\n",
            "57/57 - 3s - loss: 0.6391 - accuracy: 0.7491\n",
            "Epoch 629/1000\n",
            "57/57 - 3s - loss: 0.6443 - accuracy: 0.7487\n",
            "Epoch 630/1000\n",
            "57/57 - 3s - loss: 0.6437 - accuracy: 0.7489\n",
            "Epoch 631/1000\n",
            "57/57 - 3s - loss: 0.6306 - accuracy: 0.7577\n",
            "Epoch 632/1000\n",
            "57/57 - 3s - loss: 0.6317 - accuracy: 0.7557\n",
            "Epoch 633/1000\n",
            "57/57 - 3s - loss: 0.6330 - accuracy: 0.7596\n",
            "Epoch 634/1000\n",
            "57/57 - 3s - loss: 0.6268 - accuracy: 0.7553\n",
            "Epoch 635/1000\n",
            "57/57 - 3s - loss: 0.6386 - accuracy: 0.7520\n",
            "Epoch 636/1000\n",
            "57/57 - 3s - loss: 0.6297 - accuracy: 0.7577\n",
            "Epoch 637/1000\n",
            "57/57 - 3s - loss: 0.6327 - accuracy: 0.7546\n",
            "Epoch 638/1000\n",
            "57/57 - 3s - loss: 0.6333 - accuracy: 0.7611\n",
            "Epoch 639/1000\n",
            "57/57 - 3s - loss: 0.6361 - accuracy: 0.7520\n",
            "Epoch 640/1000\n",
            "57/57 - 3s - loss: 0.6308 - accuracy: 0.7573\n",
            "Epoch 641/1000\n",
            "57/57 - 3s - loss: 0.6273 - accuracy: 0.7562\n",
            "Epoch 642/1000\n",
            "57/57 - 3s - loss: 0.6182 - accuracy: 0.7571\n",
            "Epoch 643/1000\n",
            "57/57 - 3s - loss: 0.6179 - accuracy: 0.7648\n",
            "Epoch 644/1000\n",
            "57/57 - 3s - loss: 0.6294 - accuracy: 0.7555\n",
            "Epoch 645/1000\n",
            "57/57 - 3s - loss: 0.6298 - accuracy: 0.7552\n",
            "Epoch 646/1000\n",
            "57/57 - 3s - loss: 0.6158 - accuracy: 0.7607\n",
            "Epoch 647/1000\n",
            "57/57 - 3s - loss: 0.6175 - accuracy: 0.7538\n",
            "Epoch 648/1000\n",
            "57/57 - 3s - loss: 0.6144 - accuracy: 0.7639\n",
            "Epoch 649/1000\n",
            "57/57 - 3s - loss: 0.6182 - accuracy: 0.7650\n",
            "Epoch 650/1000\n",
            "57/57 - 3s - loss: 0.6096 - accuracy: 0.7658\n",
            "Epoch 651/1000\n",
            "57/57 - 3s - loss: 0.6094 - accuracy: 0.7603\n",
            "Epoch 652/1000\n",
            "57/57 - 3s - loss: 0.6102 - accuracy: 0.7636\n",
            "Epoch 653/1000\n",
            "57/57 - 3s - loss: 0.6090 - accuracy: 0.7635\n",
            "Epoch 654/1000\n",
            "57/57 - 3s - loss: 0.6124 - accuracy: 0.7597\n",
            "Epoch 655/1000\n",
            "57/57 - 3s - loss: 0.6147 - accuracy: 0.7625\n",
            "Epoch 656/1000\n",
            "57/57 - 3s - loss: 0.6077 - accuracy: 0.7637\n",
            "Epoch 657/1000\n",
            "57/57 - 3s - loss: 0.6098 - accuracy: 0.7637\n",
            "Epoch 658/1000\n",
            "57/57 - 3s - loss: 0.6124 - accuracy: 0.7604\n",
            "Epoch 659/1000\n",
            "57/57 - 3s - loss: 0.6208 - accuracy: 0.7618\n",
            "Epoch 660/1000\n",
            "57/57 - 3s - loss: 0.6135 - accuracy: 0.7619\n",
            "Epoch 661/1000\n",
            "57/57 - 3s - loss: 0.6109 - accuracy: 0.7628\n",
            "Epoch 662/1000\n",
            "57/57 - 3s - loss: 0.6060 - accuracy: 0.7720\n",
            "Epoch 663/1000\n",
            "57/57 - 3s - loss: 0.5921 - accuracy: 0.7805\n",
            "Epoch 664/1000\n",
            "57/57 - 3s - loss: 0.6055 - accuracy: 0.7655\n",
            "Epoch 665/1000\n",
            "57/57 - 3s - loss: 0.6047 - accuracy: 0.7686\n",
            "Epoch 666/1000\n",
            "57/57 - 3s - loss: 0.6125 - accuracy: 0.7635\n",
            "Epoch 667/1000\n",
            "57/57 - 3s - loss: 0.6032 - accuracy: 0.7683\n",
            "Epoch 668/1000\n",
            "57/57 - 3s - loss: 0.5949 - accuracy: 0.7690\n",
            "Epoch 669/1000\n",
            "57/57 - 3s - loss: 0.5916 - accuracy: 0.7692\n",
            "Epoch 670/1000\n",
            "57/57 - 3s - loss: 0.5987 - accuracy: 0.7663\n",
            "Epoch 671/1000\n",
            "57/57 - 3s - loss: 0.5974 - accuracy: 0.7688\n",
            "Epoch 672/1000\n",
            "57/57 - 3s - loss: 0.5920 - accuracy: 0.7703\n",
            "Epoch 673/1000\n",
            "57/57 - 3s - loss: 0.5881 - accuracy: 0.7714\n",
            "Epoch 674/1000\n",
            "57/57 - 3s - loss: 0.5971 - accuracy: 0.7632\n",
            "Epoch 675/1000\n",
            "57/57 - 3s - loss: 0.5909 - accuracy: 0.7710\n",
            "Epoch 676/1000\n",
            "57/57 - 3s - loss: 0.5927 - accuracy: 0.7725\n",
            "Epoch 677/1000\n",
            "57/57 - 3s - loss: 0.5976 - accuracy: 0.7690\n",
            "Epoch 678/1000\n",
            "57/57 - 3s - loss: 0.5878 - accuracy: 0.7727\n",
            "Epoch 679/1000\n",
            "57/57 - 3s - loss: 0.5802 - accuracy: 0.7735\n",
            "Epoch 680/1000\n",
            "57/57 - 3s - loss: 0.5935 - accuracy: 0.7697\n",
            "Epoch 681/1000\n",
            "57/57 - 3s - loss: 0.5940 - accuracy: 0.7712\n",
            "Epoch 682/1000\n",
            "57/57 - 3s - loss: 0.5790 - accuracy: 0.7779\n",
            "Epoch 683/1000\n",
            "57/57 - 3s - loss: 0.5766 - accuracy: 0.7794\n",
            "Epoch 684/1000\n",
            "57/57 - 3s - loss: 0.5858 - accuracy: 0.7749\n",
            "Epoch 685/1000\n",
            "57/57 - 3s - loss: 0.5829 - accuracy: 0.7752\n",
            "Epoch 686/1000\n",
            "57/57 - 3s - loss: 0.5856 - accuracy: 0.7727\n",
            "Epoch 687/1000\n",
            "57/57 - 3s - loss: 0.5760 - accuracy: 0.7772\n",
            "Epoch 688/1000\n",
            "57/57 - 3s - loss: 0.5895 - accuracy: 0.7724\n",
            "Epoch 689/1000\n",
            "57/57 - 3s - loss: 0.5756 - accuracy: 0.7754\n",
            "Epoch 690/1000\n",
            "57/57 - 3s - loss: 0.5785 - accuracy: 0.7734\n",
            "Epoch 691/1000\n",
            "57/57 - 3s - loss: 0.5781 - accuracy: 0.7703\n",
            "Epoch 692/1000\n",
            "57/57 - 3s - loss: 0.5967 - accuracy: 0.7672\n",
            "Epoch 693/1000\n",
            "57/57 - 3s - loss: 0.5818 - accuracy: 0.7731\n",
            "Epoch 694/1000\n",
            "57/57 - 3s - loss: 0.5777 - accuracy: 0.7819\n",
            "Epoch 695/1000\n",
            "57/57 - 3s - loss: 0.5765 - accuracy: 0.7792\n",
            "Epoch 696/1000\n",
            "57/57 - 3s - loss: 0.5776 - accuracy: 0.7787\n",
            "Epoch 697/1000\n",
            "57/57 - 3s - loss: 0.5700 - accuracy: 0.7782\n",
            "Epoch 698/1000\n",
            "57/57 - 3s - loss: 0.5686 - accuracy: 0.7797\n",
            "Epoch 699/1000\n",
            "57/57 - 3s - loss: 0.5808 - accuracy: 0.7708\n",
            "Epoch 700/1000\n",
            "57/57 - 3s - loss: 0.5736 - accuracy: 0.7747\n",
            "Epoch 701/1000\n",
            "57/57 - 3s - loss: 0.5712 - accuracy: 0.7738\n",
            "Epoch 702/1000\n",
            "57/57 - 3s - loss: 0.5745 - accuracy: 0.7746\n",
            "Epoch 703/1000\n",
            "57/57 - 3s - loss: 0.5606 - accuracy: 0.7801\n",
            "Epoch 704/1000\n",
            "57/57 - 3s - loss: 0.5650 - accuracy: 0.7768\n",
            "Epoch 705/1000\n",
            "57/57 - 3s - loss: 0.5665 - accuracy: 0.7820\n",
            "Epoch 706/1000\n",
            "57/57 - 3s - loss: 0.5773 - accuracy: 0.7782\n",
            "Epoch 707/1000\n",
            "57/57 - 3s - loss: 0.5659 - accuracy: 0.7772\n",
            "Epoch 708/1000\n",
            "57/57 - 3s - loss: 0.5594 - accuracy: 0.7807\n",
            "Epoch 709/1000\n",
            "57/57 - 3s - loss: 0.5750 - accuracy: 0.7764\n",
            "Epoch 710/1000\n",
            "57/57 - 3s - loss: 0.5569 - accuracy: 0.7852\n",
            "Epoch 711/1000\n",
            "57/57 - 3s - loss: 0.5570 - accuracy: 0.7848\n",
            "Epoch 712/1000\n",
            "57/57 - 3s - loss: 0.5574 - accuracy: 0.7863\n",
            "Epoch 713/1000\n",
            "57/57 - 3s - loss: 0.5623 - accuracy: 0.7789\n",
            "Epoch 714/1000\n",
            "57/57 - 3s - loss: 0.5749 - accuracy: 0.7767\n",
            "Epoch 715/1000\n",
            "57/57 - 3s - loss: 0.5628 - accuracy: 0.7827\n",
            "Epoch 716/1000\n",
            "57/57 - 3s - loss: 0.5621 - accuracy: 0.7786\n",
            "Epoch 717/1000\n",
            "57/57 - 3s - loss: 0.5595 - accuracy: 0.7833\n",
            "Epoch 718/1000\n",
            "57/57 - 3s - loss: 0.5609 - accuracy: 0.7811\n",
            "Epoch 719/1000\n",
            "57/57 - 3s - loss: 0.5564 - accuracy: 0.7859\n",
            "Epoch 720/1000\n",
            "57/57 - 3s - loss: 0.5579 - accuracy: 0.7848\n",
            "Epoch 721/1000\n",
            "57/57 - 3s - loss: 0.5537 - accuracy: 0.7842\n",
            "Epoch 722/1000\n",
            "57/57 - 3s - loss: 0.5502 - accuracy: 0.7887\n",
            "Epoch 723/1000\n",
            "57/57 - 3s - loss: 0.5428 - accuracy: 0.7887\n",
            "Epoch 724/1000\n",
            "57/57 - 3s - loss: 0.5458 - accuracy: 0.7935\n",
            "Epoch 725/1000\n",
            "57/57 - 3s - loss: 0.5643 - accuracy: 0.7772\n",
            "Epoch 726/1000\n",
            "57/57 - 3s - loss: 0.5461 - accuracy: 0.7899\n",
            "Epoch 727/1000\n",
            "57/57 - 3s - loss: 0.5500 - accuracy: 0.7896\n",
            "Epoch 728/1000\n",
            "57/57 - 3s - loss: 0.5668 - accuracy: 0.7856\n",
            "Epoch 729/1000\n",
            "57/57 - 3s - loss: 0.5613 - accuracy: 0.7834\n",
            "Epoch 730/1000\n",
            "57/57 - 3s - loss: 0.5838 - accuracy: 0.7847\n",
            "Epoch 731/1000\n",
            "57/57 - 3s - loss: 0.5543 - accuracy: 0.7900\n",
            "Epoch 732/1000\n",
            "57/57 - 3s - loss: 0.5460 - accuracy: 0.7860\n",
            "Epoch 733/1000\n",
            "57/57 - 3s - loss: 0.5524 - accuracy: 0.7915\n",
            "Epoch 734/1000\n",
            "57/57 - 3s - loss: 0.5523 - accuracy: 0.7862\n",
            "Epoch 735/1000\n",
            "57/57 - 3s - loss: 0.5549 - accuracy: 0.7921\n",
            "Epoch 736/1000\n",
            "57/57 - 3s - loss: 0.5434 - accuracy: 0.7900\n",
            "Epoch 737/1000\n",
            "57/57 - 3s - loss: 0.5428 - accuracy: 0.7880\n",
            "Epoch 738/1000\n",
            "57/57 - 3s - loss: 0.5419 - accuracy: 0.7907\n",
            "Epoch 739/1000\n",
            "57/57 - 3s - loss: 0.5406 - accuracy: 0.7931\n",
            "Epoch 740/1000\n",
            "57/57 - 3s - loss: 0.5367 - accuracy: 0.7937\n",
            "Epoch 741/1000\n",
            "57/57 - 3s - loss: 0.5530 - accuracy: 0.7852\n",
            "Epoch 742/1000\n",
            "57/57 - 3s - loss: 0.5480 - accuracy: 0.7851\n",
            "Epoch 743/1000\n",
            "57/57 - 3s - loss: 0.5373 - accuracy: 0.7971\n",
            "Epoch 744/1000\n",
            "57/57 - 3s - loss: 0.5427 - accuracy: 0.7932\n",
            "Epoch 745/1000\n",
            "57/57 - 3s - loss: 0.5364 - accuracy: 0.7937\n",
            "Epoch 746/1000\n",
            "57/57 - 3s - loss: 0.5310 - accuracy: 0.7942\n",
            "Epoch 747/1000\n",
            "57/57 - 3s - loss: 0.5383 - accuracy: 0.7960\n",
            "Epoch 748/1000\n",
            "57/57 - 3s - loss: 0.5351 - accuracy: 0.7944\n",
            "Epoch 749/1000\n",
            "57/57 - 3s - loss: 0.5343 - accuracy: 0.7906\n",
            "Epoch 750/1000\n",
            "57/57 - 3s - loss: 0.5315 - accuracy: 0.7929\n",
            "Epoch 751/1000\n",
            "57/57 - 3s - loss: 0.5366 - accuracy: 0.7926\n",
            "Epoch 752/1000\n",
            "57/57 - 3s - loss: 0.5278 - accuracy: 0.7903\n",
            "Epoch 753/1000\n",
            "57/57 - 3s - loss: 0.5309 - accuracy: 0.7980\n",
            "Epoch 754/1000\n",
            "57/57 - 3s - loss: 0.5355 - accuracy: 0.7949\n",
            "Epoch 755/1000\n",
            "57/57 - 3s - loss: 0.5291 - accuracy: 0.7910\n",
            "Epoch 756/1000\n",
            "57/57 - 3s - loss: 0.5282 - accuracy: 0.7966\n",
            "Epoch 757/1000\n",
            "57/57 - 3s - loss: 0.5326 - accuracy: 0.8015\n",
            "Epoch 758/1000\n",
            "57/57 - 3s - loss: 0.5337 - accuracy: 0.7932\n",
            "Epoch 759/1000\n",
            "57/57 - 3s - loss: 0.5322 - accuracy: 0.7999\n",
            "Epoch 760/1000\n",
            "57/57 - 3s - loss: 0.5244 - accuracy: 0.7965\n",
            "Epoch 761/1000\n",
            "57/57 - 3s - loss: 0.5310 - accuracy: 0.7951\n",
            "Epoch 762/1000\n",
            "57/57 - 3s - loss: 0.5193 - accuracy: 0.8027\n",
            "Epoch 763/1000\n",
            "57/57 - 3s - loss: 0.5253 - accuracy: 0.7973\n",
            "Epoch 764/1000\n",
            "57/57 - 3s - loss: 0.5208 - accuracy: 0.7928\n",
            "Epoch 765/1000\n",
            "57/57 - 3s - loss: 0.5347 - accuracy: 0.7940\n",
            "Epoch 766/1000\n",
            "57/57 - 3s - loss: 0.5240 - accuracy: 0.7980\n",
            "Epoch 767/1000\n",
            "57/57 - 3s - loss: 0.5046 - accuracy: 0.8035\n",
            "Epoch 768/1000\n",
            "57/57 - 3s - loss: 0.5216 - accuracy: 0.7983\n",
            "Epoch 769/1000\n",
            "57/57 - 3s - loss: 0.5130 - accuracy: 0.8005\n",
            "Epoch 770/1000\n",
            "57/57 - 3s - loss: 0.5220 - accuracy: 0.8026\n",
            "Epoch 771/1000\n",
            "57/57 - 3s - loss: 0.5171 - accuracy: 0.7969\n",
            "Epoch 772/1000\n",
            "57/57 - 3s - loss: 0.5147 - accuracy: 0.8019\n",
            "Epoch 773/1000\n",
            "57/57 - 3s - loss: 0.5169 - accuracy: 0.8020\n",
            "Epoch 774/1000\n",
            "57/57 - 3s - loss: 0.5145 - accuracy: 0.8006\n",
            "Epoch 775/1000\n",
            "57/57 - 3s - loss: 0.5075 - accuracy: 0.8059\n",
            "Epoch 776/1000\n",
            "57/57 - 3s - loss: 0.5149 - accuracy: 0.8012\n",
            "Epoch 777/1000\n",
            "57/57 - 3s - loss: 0.5119 - accuracy: 0.8041\n",
            "Epoch 778/1000\n",
            "57/57 - 3s - loss: 0.5166 - accuracy: 0.7971\n",
            "Epoch 779/1000\n",
            "57/57 - 3s - loss: 0.5108 - accuracy: 0.8015\n",
            "Epoch 780/1000\n",
            "57/57 - 3s - loss: 0.5059 - accuracy: 0.8012\n",
            "Epoch 781/1000\n",
            "57/57 - 3s - loss: 0.5143 - accuracy: 0.8028\n",
            "Epoch 782/1000\n",
            "57/57 - 3s - loss: 0.5455 - accuracy: 0.7977\n",
            "Epoch 783/1000\n",
            "57/57 - 3s - loss: 0.4989 - accuracy: 0.8114\n",
            "Epoch 784/1000\n",
            "57/57 - 3s - loss: 0.5017 - accuracy: 0.8057\n",
            "Epoch 785/1000\n",
            "57/57 - 3s - loss: 0.5157 - accuracy: 0.8060\n",
            "Epoch 786/1000\n",
            "57/57 - 3s - loss: 0.5099 - accuracy: 0.8030\n",
            "Epoch 787/1000\n",
            "57/57 - 3s - loss: 0.5024 - accuracy: 0.8042\n",
            "Epoch 788/1000\n",
            "57/57 - 3s - loss: 0.4985 - accuracy: 0.8079\n",
            "Epoch 789/1000\n",
            "57/57 - 3s - loss: 0.5032 - accuracy: 0.8052\n",
            "Epoch 790/1000\n",
            "57/57 - 3s - loss: 0.5065 - accuracy: 0.8049\n",
            "Epoch 791/1000\n",
            "57/57 - 3s - loss: 0.5033 - accuracy: 0.8086\n",
            "Epoch 792/1000\n",
            "57/57 - 3s - loss: 0.5070 - accuracy: 0.8016\n",
            "Epoch 793/1000\n",
            "57/57 - 3s - loss: 0.5015 - accuracy: 0.8067\n",
            "Epoch 794/1000\n",
            "57/57 - 3s - loss: 0.4979 - accuracy: 0.8088\n",
            "Epoch 795/1000\n",
            "57/57 - 3s - loss: 0.4991 - accuracy: 0.8024\n",
            "Epoch 796/1000\n",
            "57/57 - 3s - loss: 0.4921 - accuracy: 0.8114\n",
            "Epoch 797/1000\n",
            "57/57 - 3s - loss: 0.4905 - accuracy: 0.8088\n",
            "Epoch 798/1000\n",
            "57/57 - 3s - loss: 0.4923 - accuracy: 0.8116\n",
            "Epoch 799/1000\n",
            "57/57 - 3s - loss: 0.4903 - accuracy: 0.8112\n",
            "Epoch 800/1000\n",
            "57/57 - 3s - loss: 0.4982 - accuracy: 0.8104\n",
            "Epoch 801/1000\n",
            "57/57 - 3s - loss: 0.4933 - accuracy: 0.8089\n",
            "Epoch 802/1000\n",
            "57/57 - 3s - loss: 0.4929 - accuracy: 0.8122\n",
            "Epoch 803/1000\n",
            "57/57 - 3s - loss: 0.5082 - accuracy: 0.8038\n",
            "Epoch 804/1000\n",
            "57/57 - 3s - loss: 0.4947 - accuracy: 0.8077\n",
            "Epoch 805/1000\n",
            "57/57 - 3s - loss: 0.4917 - accuracy: 0.8121\n",
            "Epoch 806/1000\n",
            "57/57 - 3s - loss: 0.4942 - accuracy: 0.8108\n",
            "Epoch 807/1000\n",
            "57/57 - 3s - loss: 0.4789 - accuracy: 0.8155\n",
            "Epoch 808/1000\n",
            "57/57 - 3s - loss: 0.4944 - accuracy: 0.8057\n",
            "Epoch 809/1000\n",
            "57/57 - 3s - loss: 0.4859 - accuracy: 0.8094\n",
            "Epoch 810/1000\n",
            "57/57 - 3s - loss: 0.4956 - accuracy: 0.8053\n",
            "Epoch 811/1000\n",
            "57/57 - 3s - loss: 0.4886 - accuracy: 0.8129\n",
            "Epoch 812/1000\n",
            "57/57 - 3s - loss: 0.4823 - accuracy: 0.8111\n",
            "Epoch 813/1000\n",
            "57/57 - 3s - loss: 0.4858 - accuracy: 0.8133\n",
            "Epoch 814/1000\n",
            "57/57 - 3s - loss: 0.4979 - accuracy: 0.8066\n",
            "Epoch 815/1000\n",
            "57/57 - 3s - loss: 0.4845 - accuracy: 0.8159\n",
            "Epoch 816/1000\n",
            "57/57 - 3s - loss: 0.4812 - accuracy: 0.8129\n",
            "Epoch 817/1000\n",
            "57/57 - 3s - loss: 0.4829 - accuracy: 0.8116\n",
            "Epoch 818/1000\n",
            "57/57 - 3s - loss: 0.4892 - accuracy: 0.8096\n",
            "Epoch 819/1000\n",
            "57/57 - 3s - loss: 0.5015 - accuracy: 0.8042\n",
            "Epoch 820/1000\n",
            "57/57 - 3s - loss: 0.4896 - accuracy: 0.8119\n",
            "Epoch 821/1000\n",
            "57/57 - 3s - loss: 0.4870 - accuracy: 0.8141\n",
            "Epoch 822/1000\n",
            "57/57 - 3s - loss: 0.4816 - accuracy: 0.8140\n",
            "Epoch 823/1000\n",
            "57/57 - 3s - loss: 0.4743 - accuracy: 0.8162\n",
            "Epoch 824/1000\n",
            "57/57 - 3s - loss: 0.4739 - accuracy: 0.8188\n",
            "Epoch 825/1000\n",
            "57/57 - 3s - loss: 0.4891 - accuracy: 0.8056\n",
            "Epoch 826/1000\n",
            "57/57 - 3s - loss: 0.4776 - accuracy: 0.8158\n",
            "Epoch 827/1000\n",
            "57/57 - 3s - loss: 0.4707 - accuracy: 0.8213\n",
            "Epoch 828/1000\n",
            "57/57 - 3s - loss: 0.4757 - accuracy: 0.8162\n",
            "Epoch 829/1000\n",
            "57/57 - 3s - loss: 0.4751 - accuracy: 0.8158\n",
            "Epoch 830/1000\n",
            "57/57 - 3s - loss: 0.4770 - accuracy: 0.8163\n",
            "Epoch 831/1000\n",
            "57/57 - 3s - loss: 0.4741 - accuracy: 0.8218\n",
            "Epoch 832/1000\n",
            "57/57 - 3s - loss: 0.4761 - accuracy: 0.8130\n",
            "Epoch 833/1000\n",
            "57/57 - 3s - loss: 0.4727 - accuracy: 0.8198\n",
            "Epoch 834/1000\n",
            "57/57 - 3s - loss: 0.4801 - accuracy: 0.8140\n",
            "Epoch 835/1000\n",
            "57/57 - 3s - loss: 0.4747 - accuracy: 0.8129\n",
            "Epoch 836/1000\n",
            "57/57 - 3s - loss: 0.4624 - accuracy: 0.8191\n",
            "Epoch 837/1000\n",
            "57/57 - 3s - loss: 0.4714 - accuracy: 0.8181\n",
            "Epoch 838/1000\n",
            "57/57 - 3s - loss: 0.4735 - accuracy: 0.8162\n",
            "Epoch 839/1000\n",
            "57/57 - 3s - loss: 0.4694 - accuracy: 0.8184\n",
            "Epoch 840/1000\n",
            "57/57 - 3s - loss: 0.4661 - accuracy: 0.8159\n",
            "Epoch 841/1000\n",
            "57/57 - 3s - loss: 0.4702 - accuracy: 0.8218\n",
            "Epoch 842/1000\n",
            "57/57 - 3s - loss: 0.4633 - accuracy: 0.8253\n",
            "Epoch 843/1000\n",
            "57/57 - 3s - loss: 0.4640 - accuracy: 0.8265\n",
            "Epoch 844/1000\n",
            "57/57 - 3s - loss: 0.4650 - accuracy: 0.8183\n",
            "Epoch 845/1000\n",
            "57/57 - 3s - loss: 0.4681 - accuracy: 0.8162\n",
            "Epoch 846/1000\n",
            "57/57 - 3s - loss: 0.4803 - accuracy: 0.8178\n",
            "Epoch 847/1000\n",
            "57/57 - 3s - loss: 0.4574 - accuracy: 0.8220\n",
            "Epoch 848/1000\n",
            "57/57 - 3s - loss: 0.4575 - accuracy: 0.8242\n",
            "Epoch 849/1000\n",
            "57/57 - 3s - loss: 0.4629 - accuracy: 0.8209\n",
            "Epoch 850/1000\n",
            "57/57 - 3s - loss: 0.4653 - accuracy: 0.8184\n",
            "Epoch 851/1000\n",
            "57/57 - 3s - loss: 0.4646 - accuracy: 0.8232\n",
            "Epoch 852/1000\n",
            "57/57 - 3s - loss: 0.4649 - accuracy: 0.8167\n",
            "Epoch 853/1000\n",
            "57/57 - 3s - loss: 0.4523 - accuracy: 0.8271\n",
            "Epoch 854/1000\n",
            "57/57 - 3s - loss: 0.4671 - accuracy: 0.8224\n",
            "Epoch 855/1000\n",
            "57/57 - 3s - loss: 0.4658 - accuracy: 0.8213\n",
            "Epoch 856/1000\n",
            "57/57 - 3s - loss: 0.4498 - accuracy: 0.8207\n",
            "Epoch 857/1000\n",
            "57/57 - 3s - loss: 0.4554 - accuracy: 0.8246\n",
            "Epoch 858/1000\n",
            "57/57 - 3s - loss: 0.4545 - accuracy: 0.8245\n",
            "Epoch 859/1000\n",
            "57/57 - 3s - loss: 0.4674 - accuracy: 0.8181\n",
            "Epoch 860/1000\n",
            "57/57 - 3s - loss: 0.4541 - accuracy: 0.8214\n",
            "Epoch 861/1000\n",
            "57/57 - 3s - loss: 0.4563 - accuracy: 0.8247\n",
            "Epoch 862/1000\n",
            "57/57 - 3s - loss: 0.4609 - accuracy: 0.8187\n",
            "Epoch 863/1000\n",
            "57/57 - 3s - loss: 0.4535 - accuracy: 0.8243\n",
            "Epoch 864/1000\n",
            "57/57 - 3s - loss: 0.4500 - accuracy: 0.8290\n",
            "Epoch 865/1000\n",
            "57/57 - 3s - loss: 0.4532 - accuracy: 0.8227\n",
            "Epoch 866/1000\n",
            "57/57 - 3s - loss: 0.4486 - accuracy: 0.8268\n",
            "Epoch 867/1000\n",
            "57/57 - 3s - loss: 0.4539 - accuracy: 0.8250\n",
            "Epoch 868/1000\n",
            "57/57 - 3s - loss: 0.4544 - accuracy: 0.8247\n",
            "Epoch 869/1000\n",
            "57/57 - 3s - loss: 0.4534 - accuracy: 0.8228\n",
            "Epoch 870/1000\n",
            "57/57 - 3s - loss: 0.4597 - accuracy: 0.8221\n",
            "Epoch 871/1000\n",
            "57/57 - 3s - loss: 0.4466 - accuracy: 0.8293\n",
            "Epoch 872/1000\n",
            "57/57 - 3s - loss: 0.4428 - accuracy: 0.8247\n",
            "Epoch 873/1000\n",
            "57/57 - 3s - loss: 0.4512 - accuracy: 0.8245\n",
            "Epoch 874/1000\n",
            "57/57 - 3s - loss: 0.4389 - accuracy: 0.8351\n",
            "Epoch 875/1000\n",
            "57/57 - 3s - loss: 0.4391 - accuracy: 0.8362\n",
            "Epoch 876/1000\n",
            "57/57 - 3s - loss: 0.4436 - accuracy: 0.8294\n",
            "Epoch 877/1000\n",
            "57/57 - 3s - loss: 0.4365 - accuracy: 0.8319\n",
            "Epoch 878/1000\n",
            "57/57 - 3s - loss: 0.4420 - accuracy: 0.8298\n",
            "Epoch 879/1000\n",
            "57/57 - 3s - loss: 0.4375 - accuracy: 0.8264\n",
            "Epoch 880/1000\n",
            "57/57 - 3s - loss: 0.4472 - accuracy: 0.8229\n",
            "Epoch 881/1000\n",
            "57/57 - 3s - loss: 0.4387 - accuracy: 0.8342\n",
            "Epoch 882/1000\n",
            "57/57 - 3s - loss: 0.4393 - accuracy: 0.8286\n",
            "Epoch 883/1000\n",
            "57/57 - 3s - loss: 0.4481 - accuracy: 0.8254\n",
            "Epoch 884/1000\n",
            "57/57 - 3s - loss: 0.4359 - accuracy: 0.8279\n",
            "Epoch 885/1000\n",
            "57/57 - 3s - loss: 0.4366 - accuracy: 0.8320\n",
            "Epoch 886/1000\n",
            "57/57 - 3s - loss: 0.4363 - accuracy: 0.8294\n",
            "Epoch 887/1000\n",
            "57/57 - 3s - loss: 0.4432 - accuracy: 0.8278\n",
            "Epoch 888/1000\n",
            "57/57 - 3s - loss: 0.4421 - accuracy: 0.8280\n",
            "Epoch 889/1000\n",
            "57/57 - 3s - loss: 0.4415 - accuracy: 0.8311\n",
            "Epoch 890/1000\n",
            "57/57 - 3s - loss: 0.4445 - accuracy: 0.8284\n",
            "Epoch 891/1000\n",
            "57/57 - 3s - loss: 0.4335 - accuracy: 0.8289\n",
            "Epoch 892/1000\n",
            "57/57 - 3s - loss: 0.4450 - accuracy: 0.8275\n",
            "Epoch 893/1000\n",
            "57/57 - 3s - loss: 0.4317 - accuracy: 0.8374\n",
            "Epoch 894/1000\n",
            "57/57 - 3s - loss: 0.4311 - accuracy: 0.8367\n",
            "Epoch 895/1000\n",
            "57/57 - 3s - loss: 0.4260 - accuracy: 0.8320\n",
            "Epoch 896/1000\n",
            "57/57 - 3s - loss: 0.4226 - accuracy: 0.8399\n",
            "Epoch 897/1000\n",
            "57/57 - 3s - loss: 0.4363 - accuracy: 0.8301\n",
            "Epoch 898/1000\n",
            "57/57 - 3s - loss: 0.4283 - accuracy: 0.8311\n",
            "Epoch 899/1000\n",
            "57/57 - 3s - loss: 0.4278 - accuracy: 0.8311\n",
            "Epoch 900/1000\n",
            "57/57 - 3s - loss: 0.4269 - accuracy: 0.8323\n",
            "Epoch 901/1000\n",
            "57/57 - 3s - loss: 0.4216 - accuracy: 0.8382\n",
            "Epoch 902/1000\n",
            "57/57 - 3s - loss: 0.4267 - accuracy: 0.8329\n",
            "Epoch 903/1000\n",
            "57/57 - 3s - loss: 0.4236 - accuracy: 0.8401\n",
            "Epoch 904/1000\n",
            "57/57 - 3s - loss: 0.4161 - accuracy: 0.8370\n",
            "Epoch 905/1000\n",
            "57/57 - 3s - loss: 0.4260 - accuracy: 0.8315\n",
            "Epoch 906/1000\n",
            "57/57 - 3s - loss: 0.4285 - accuracy: 0.8323\n",
            "Epoch 907/1000\n",
            "57/57 - 3s - loss: 0.4273 - accuracy: 0.8324\n",
            "Epoch 908/1000\n",
            "57/57 - 3s - loss: 0.4274 - accuracy: 0.8367\n",
            "Epoch 909/1000\n",
            "57/57 - 3s - loss: 0.4239 - accuracy: 0.8366\n",
            "Epoch 910/1000\n",
            "57/57 - 3s - loss: 0.4209 - accuracy: 0.8363\n",
            "Epoch 911/1000\n",
            "57/57 - 3s - loss: 0.4179 - accuracy: 0.8300\n",
            "Epoch 912/1000\n",
            "57/57 - 3s - loss: 0.4277 - accuracy: 0.8381\n",
            "Epoch 913/1000\n",
            "57/57 - 3s - loss: 0.4173 - accuracy: 0.8425\n",
            "Epoch 914/1000\n",
            "57/57 - 3s - loss: 0.4146 - accuracy: 0.8397\n",
            "Epoch 915/1000\n",
            "57/57 - 3s - loss: 0.4115 - accuracy: 0.8476\n",
            "Epoch 916/1000\n",
            "57/57 - 3s - loss: 0.4247 - accuracy: 0.8324\n",
            "Epoch 917/1000\n",
            "57/57 - 3s - loss: 0.4193 - accuracy: 0.8396\n",
            "Epoch 918/1000\n",
            "57/57 - 3s - loss: 0.4199 - accuracy: 0.8344\n",
            "Epoch 919/1000\n",
            "57/57 - 3s - loss: 0.4224 - accuracy: 0.8364\n",
            "Epoch 920/1000\n",
            "57/57 - 3s - loss: 0.4081 - accuracy: 0.8459\n",
            "Epoch 921/1000\n",
            "57/57 - 3s - loss: 0.4116 - accuracy: 0.8392\n",
            "Epoch 922/1000\n",
            "57/57 - 3s - loss: 0.4101 - accuracy: 0.8397\n",
            "Epoch 923/1000\n",
            "57/57 - 3s - loss: 0.4182 - accuracy: 0.8390\n",
            "Epoch 924/1000\n",
            "57/57 - 3s - loss: 0.4171 - accuracy: 0.8374\n",
            "Epoch 925/1000\n",
            "57/57 - 3s - loss: 0.4148 - accuracy: 0.8367\n",
            "Epoch 926/1000\n",
            "57/57 - 3s - loss: 0.4149 - accuracy: 0.8342\n",
            "Epoch 927/1000\n",
            "57/57 - 3s - loss: 0.4125 - accuracy: 0.8378\n",
            "Epoch 928/1000\n",
            "57/57 - 3s - loss: 0.4077 - accuracy: 0.8401\n",
            "Epoch 929/1000\n",
            "57/57 - 3s - loss: 0.4239 - accuracy: 0.8340\n",
            "Epoch 930/1000\n",
            "57/57 - 3s - loss: 0.4060 - accuracy: 0.8404\n",
            "Epoch 931/1000\n",
            "57/57 - 3s - loss: 0.4129 - accuracy: 0.8385\n",
            "Epoch 932/1000\n",
            "57/57 - 3s - loss: 0.4092 - accuracy: 0.8422\n",
            "Epoch 933/1000\n",
            "57/57 - 3s - loss: 0.4089 - accuracy: 0.8400\n",
            "Epoch 934/1000\n",
            "57/57 - 3s - loss: 0.4178 - accuracy: 0.8373\n",
            "Epoch 935/1000\n",
            "57/57 - 3s - loss: 0.4211 - accuracy: 0.8355\n",
            "Epoch 936/1000\n",
            "57/57 - 3s - loss: 0.4001 - accuracy: 0.8448\n",
            "Epoch 937/1000\n",
            "57/57 - 3s - loss: 0.4069 - accuracy: 0.8439\n",
            "Epoch 938/1000\n",
            "57/57 - 3s - loss: 0.4016 - accuracy: 0.8463\n",
            "Epoch 939/1000\n",
            "57/57 - 3s - loss: 0.4119 - accuracy: 0.8393\n",
            "Epoch 940/1000\n",
            "57/57 - 3s - loss: 0.4092 - accuracy: 0.8466\n",
            "Epoch 941/1000\n",
            "57/57 - 3s - loss: 0.4165 - accuracy: 0.8334\n",
            "Epoch 942/1000\n",
            "57/57 - 3s - loss: 0.4065 - accuracy: 0.8360\n",
            "Epoch 943/1000\n",
            "57/57 - 3s - loss: 0.4013 - accuracy: 0.8476\n",
            "Epoch 944/1000\n",
            "57/57 - 3s - loss: 0.4141 - accuracy: 0.8397\n",
            "Epoch 945/1000\n",
            "57/57 - 3s - loss: 0.3986 - accuracy: 0.8501\n",
            "Epoch 946/1000\n",
            "57/57 - 3s - loss: 0.4121 - accuracy: 0.8411\n",
            "Epoch 947/1000\n",
            "57/57 - 3s - loss: 0.3966 - accuracy: 0.8472\n",
            "Epoch 948/1000\n",
            "57/57 - 3s - loss: 0.4074 - accuracy: 0.8454\n",
            "Epoch 949/1000\n",
            "57/57 - 3s - loss: 0.4079 - accuracy: 0.8399\n",
            "Epoch 950/1000\n",
            "57/57 - 3s - loss: 0.3962 - accuracy: 0.8480\n",
            "Epoch 951/1000\n",
            "57/57 - 3s - loss: 0.3992 - accuracy: 0.8399\n",
            "Epoch 952/1000\n",
            "57/57 - 3s - loss: 0.3955 - accuracy: 0.8422\n",
            "Epoch 953/1000\n",
            "57/57 - 3s - loss: 0.4110 - accuracy: 0.8404\n",
            "Epoch 954/1000\n",
            "57/57 - 3s - loss: 0.3983 - accuracy: 0.8455\n",
            "Epoch 955/1000\n",
            "57/57 - 3s - loss: 0.3981 - accuracy: 0.8465\n",
            "Epoch 956/1000\n",
            "57/57 - 3s - loss: 0.4097 - accuracy: 0.8417\n",
            "Epoch 957/1000\n",
            "57/57 - 3s - loss: 0.3992 - accuracy: 0.8468\n",
            "Epoch 958/1000\n",
            "57/57 - 3s - loss: 0.3992 - accuracy: 0.8441\n",
            "Epoch 959/1000\n",
            "57/57 - 3s - loss: 0.3957 - accuracy: 0.8440\n",
            "Epoch 960/1000\n",
            "57/57 - 3s - loss: 0.3952 - accuracy: 0.8463\n",
            "Epoch 961/1000\n",
            "57/57 - 3s - loss: 0.3948 - accuracy: 0.8444\n",
            "Epoch 962/1000\n",
            "57/57 - 3s - loss: 0.3905 - accuracy: 0.8490\n",
            "Epoch 963/1000\n",
            "57/57 - 3s - loss: 0.3880 - accuracy: 0.8528\n",
            "Epoch 964/1000\n",
            "57/57 - 3s - loss: 0.3892 - accuracy: 0.8474\n",
            "Epoch 965/1000\n",
            "57/57 - 3s - loss: 0.3905 - accuracy: 0.8508\n",
            "Epoch 966/1000\n",
            "57/57 - 3s - loss: 0.3893 - accuracy: 0.8484\n",
            "Epoch 967/1000\n",
            "57/57 - 3s - loss: 0.3941 - accuracy: 0.8439\n",
            "Epoch 968/1000\n",
            "57/57 - 3s - loss: 0.3887 - accuracy: 0.8469\n",
            "Epoch 969/1000\n",
            "57/57 - 3s - loss: 0.3918 - accuracy: 0.8492\n",
            "Epoch 970/1000\n",
            "57/57 - 3s - loss: 0.3912 - accuracy: 0.8508\n",
            "Epoch 971/1000\n",
            "57/57 - 3s - loss: 0.3831 - accuracy: 0.8521\n",
            "Epoch 972/1000\n",
            "57/57 - 3s - loss: 0.3817 - accuracy: 0.8491\n",
            "Epoch 973/1000\n",
            "57/57 - 3s - loss: 0.3929 - accuracy: 0.8469\n",
            "Epoch 974/1000\n",
            "57/57 - 3s - loss: 0.3954 - accuracy: 0.8477\n",
            "Epoch 975/1000\n",
            "57/57 - 3s - loss: 0.3945 - accuracy: 0.8505\n",
            "Epoch 976/1000\n",
            "57/57 - 3s - loss: 0.3787 - accuracy: 0.8571\n",
            "Epoch 977/1000\n",
            "57/57 - 3s - loss: 0.3781 - accuracy: 0.8549\n",
            "Epoch 978/1000\n",
            "57/57 - 3s - loss: 0.3913 - accuracy: 0.8491\n",
            "Epoch 979/1000\n",
            "57/57 - 3s - loss: 0.3850 - accuracy: 0.8494\n",
            "Epoch 980/1000\n",
            "57/57 - 3s - loss: 0.3812 - accuracy: 0.8513\n",
            "Epoch 981/1000\n",
            "57/57 - 3s - loss: 0.3775 - accuracy: 0.8520\n",
            "Epoch 982/1000\n",
            "57/57 - 3s - loss: 0.3745 - accuracy: 0.8538\n",
            "Epoch 983/1000\n",
            "57/57 - 3s - loss: 0.3845 - accuracy: 0.8512\n",
            "Epoch 984/1000\n",
            "57/57 - 3s - loss: 0.3807 - accuracy: 0.8530\n",
            "Epoch 985/1000\n",
            "57/57 - 3s - loss: 0.3764 - accuracy: 0.8556\n",
            "Epoch 986/1000\n",
            "57/57 - 3s - loss: 0.3809 - accuracy: 0.8569\n",
            "Epoch 987/1000\n",
            "57/57 - 3s - loss: 0.3804 - accuracy: 0.8505\n",
            "Epoch 988/1000\n",
            "57/57 - 3s - loss: 0.3670 - accuracy: 0.8583\n",
            "Epoch 989/1000\n",
            "57/57 - 3s - loss: 0.3771 - accuracy: 0.8538\n",
            "Epoch 990/1000\n",
            "57/57 - 3s - loss: 0.3769 - accuracy: 0.8565\n",
            "Epoch 991/1000\n",
            "57/57 - 3s - loss: 0.3766 - accuracy: 0.8519\n",
            "Epoch 992/1000\n",
            "57/57 - 3s - loss: 0.3784 - accuracy: 0.8505\n",
            "Epoch 993/1000\n",
            "57/57 - 3s - loss: 0.3823 - accuracy: 0.8528\n",
            "Epoch 994/1000\n",
            "57/57 - 3s - loss: 0.3719 - accuracy: 0.8538\n",
            "Epoch 995/1000\n",
            "57/57 - 3s - loss: 0.3772 - accuracy: 0.8525\n",
            "Epoch 996/1000\n",
            "57/57 - 3s - loss: 0.3818 - accuracy: 0.8501\n",
            "Epoch 997/1000\n",
            "57/57 - 3s - loss: 0.3841 - accuracy: 0.8498\n",
            "Epoch 998/1000\n",
            "57/57 - 3s - loss: 0.3854 - accuracy: 0.8480\n",
            "Epoch 999/1000\n",
            "57/57 - 3s - loss: 0.3666 - accuracy: 0.8549\n",
            "Epoch 1000/1000\n",
            "57/57 - 3s - loss: 0.3782 - accuracy: 0.8535\n",
            "41.08577072620392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "aE1oSpU6M07Q",
        "outputId": "3cad1ff5-4734-4ea6-b1b0-e7cb92f1b218"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Aqw-bWhfcBKL",
        "outputId": "5f722e65-f166-4555-c489-c7c0b529413e"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3epqPo3VPZsS",
        "outputId": "5516928a-6061-4856-936b-420a9067b189"
      },
      "source": [
        "prediction = model.predict(final_input_test)\n",
        "\n",
        "max_given_input = np.argmax(test_labels, axis=1)\n",
        "max_predicted_output = np.argmax(prediction, axis=1)\n",
        "print(max_given_input)\n",
        "print(max_predicted_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 8 2 ... 7 0 0]\n",
            "[3 3 2 ... 0 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlYKKLWJPbuZ",
        "outputId": "41653991-80b0-40ec-805c-43ee54faef42"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "FKwLcLSdPfAe",
        "outputId": "66a6cb44-1757-4032-a95b-b84b34e7a54d"
      },
      "source": [
        "from scikitplot.metrics import plot_confusion_matrix\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,12))\n",
        "plot_confusion_matrix(max_given_input, max_predicted_output, ax=ax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f54ed55bc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x864 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62w-aOTd6cKr"
      },
      "source": [
        "# Top 10 Types (rand)\n",
        "Added some random shuffling to the numpy arrays before split into training and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo-X7Z820HTl"
      },
      "source": [
        "Remove rows not in the top 10 types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSQT8li26cK1",
        "outputId": "da3695da-6ff3-4400-b04f-01b9d0bf8378"
      },
      "source": [
        "\n",
        "train_df = train_df[train_df['Type'].isin(list(Percentages[:10].index))]\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "994       008DC6  0.088502  0.570442  0.578876  1596723690985  P28A\n",
            "995       008DC6  0.089647  0.570432  0.578902  1596723703073  P28A\n",
            "996       008DC6  0.090028  0.570430  0.578911  1596723717541  P28A\n",
            "997       008DC6  0.090028  0.570430  0.578911  1596723719963  P28A\n",
            "998       008DC6  0.136568  0.570992  0.578782  1596724125875  P28A\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "29550390  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550391  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550392  E94C42  0.286107  0.601955  0.314975  1596733965728  B738\n",
            "29550393  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "29550394  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "\n",
            "[13141213 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm7uRejT0O58"
      },
      "source": [
        "Replace types with numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m-bu76F6cK4",
        "outputId": "bf496f65-9f0a-4fb5-d8f1-77e72d5fd5a3"
      },
      "source": [
        "type_dict = {k: v for v, k in enumerate(list(Percentages[:10].index))}\n",
        "print(type_dict)\n",
        "train_df['Type'].replace(type_dict, inplace = True)\n",
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B738': 0, 'A320': 1, 'C172': 2, 'A321': 3, 'B737': 4, 'A319': 5, 'P28A': 6, 'A20N': 7, 'B763': 8, 'B739': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsvYCCTv6cK7",
        "outputId": "81382707-a7a5-4711-e4d1-b6aa664e0257"
      },
      "source": [
        "#turn train dataframe into a multi-dimensional numpy array\n",
        "train_df = np.array(list(train_df.groupby('Icao').apply(pd.DataFrame.to_numpy)))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_count = train_df.shape[0]\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16046,)\n",
            "16046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZkdvO456cK8",
        "outputId": "28309164-ffc0-485d-fc8c-52457ff2615b"
      },
      "source": [
        "#load in first dataframe\n",
        "train_input = pd.DataFrame(data = train_df[1], columns = [\"Icao\", \"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "train_input = train_input.set_index('Time')\n",
        "train_input = train_input.drop('PosTime', axis = 1)\n",
        "train_input = train_input.drop('Icao', axis = 1)\n",
        "print(train_input)\n",
        "#Get Species Type\n",
        "unique_species = train_input.Type[0]\n",
        "print(unique_species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                Alt       Lat      Long Type\n",
            "Time                                                        \n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:13:29.760    0.995056  0.540866  0.551703    0\n",
            "2020-08-06 07:13:44.242    0.998108  0.540902  0.551694    0\n",
            "2020-08-06 07:13:56.289  0.00572213  0.540932  0.551686    0\n",
            "...                             ...       ...       ...  ...\n",
            "2020-08-06 16:02:45.713    0.999252   0.54098  0.551676    0\n",
            "2020-08-06 16:02:57.784    0.996963  0.540951  0.551683    0\n",
            "2020-08-06 16:03:55.777    0.994675  0.540866  0.551703    0\n",
            "2020-08-06 16:04:10.278    0.994675  0.540864  0.551703    0\n",
            "2020-08-06 16:04:27.227    0.994675  0.540863  0.551702    0\n",
            "\n",
            "[373 rows x 4 columns]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Cnj2mFn6cK9",
        "outputId": "35b7a7e9-268a-4f4a-ece1-bec338247605"
      },
      "source": [
        "#Resampling/Interpolating (1 sample every 5 minutes for 6 hours)\n",
        "norm_train_df = pd.DataFrame()\n",
        "norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "norm_train_df.reset_index(inplace = True)\n",
        "norm_train_df = norm_train_df.iloc[0:73]\n",
        "print(norm_train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Time       Lat      Long       Alt\n",
            "0  2020-08-06 07:10:00  0.541109  0.551641  0.026703\n",
            "1  2020-08-06 07:15:00  0.542472  0.552251  0.217823\n",
            "2  2020-08-06 07:20:00  0.544178  0.553254  0.402075\n",
            "3  2020-08-06 07:25:00  0.546072  0.554713  0.501640\n",
            "4  2020-08-06 07:30:00  0.547895  0.556523  0.586328\n",
            "..                 ...       ...       ...       ...\n",
            "68 2020-08-06 12:50:00  0.575555  0.585123 -1.378310\n",
            "69 2020-08-06 12:55:00  0.575441  0.584925 -1.338937\n",
            "70 2020-08-06 13:00:00  0.575300  0.584686 -1.292159\n",
            "71 2020-08-06 13:05:00  0.575129  0.584407 -1.237701\n",
            "72 2020-08-06 13:10:00  0.574928  0.584084 -1.175291\n",
            "\n",
            "[73 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qze0fAjS6cK-",
        "outputId": "274e3726-caae-4110-87d9-e544b72d8f4c"
      },
      "source": [
        "#add species to label list\n",
        "train_labels = []\n",
        "train_labels.append(unique_species)\n",
        "print(train_labels)\n",
        "#convert dataframe to numpy\n",
        "norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "norm_train_df = norm_train_df.to_numpy()\n",
        "print(norm_train_df)\n",
        "final_input_train = norm_train_df\n",
        "print(final_input_train.shape)\n",
        "final_input_train = np.reshape(final_input_train, (1,73,3))\n",
        "print(final_input_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[ 0.54110926  0.55164051  0.02670329]\n",
            " [ 0.54247236  0.55225104  0.21782254]\n",
            " [ 0.54417837  0.55325353  0.40207523]\n",
            " [ 0.54607177  0.55471271  0.50164034]\n",
            " [ 0.54789543  0.5565232   0.58632792]\n",
            " [ 0.54969102  0.55826527  0.59510185]\n",
            " [ 0.55004507  0.55860418  0.59510185]\n",
            " [ 0.55061809  0.55913722  0.60817557]\n",
            " [ 0.55184827  0.56027639  0.62872997]\n",
            " [ 0.55359598  0.56188938  0.65039623]\n",
            " [ 0.55572157  0.5638439   0.66680553]\n",
            " [ 0.55808541  0.56600764  0.67158908]\n",
            " [ 0.56054785  0.56824831  0.65837804]\n",
            " [ 0.56296924  0.5704336   0.62080362]\n",
            " [ 0.56520995  0.57243121  0.55249699]\n",
            " [ 0.56713033  0.57410884  0.44708934]\n",
            " [ 0.56859511  0.57544625  0.30861372]\n",
            " [ 0.56961566  0.57667202  0.17662318]\n",
            " [ 0.57040614  0.5773856   0.08812085]\n",
            " [ 0.57044345  0.57741934  0.08392462]\n",
            " [ 0.57031141  0.57733422  0.09457798]\n",
            " [ 0.57020701  0.57728254  0.09927008]\n",
            " [ 0.57012913  0.57726283  0.09827373]\n",
            " [ 0.57007663  0.57727358  0.09186173]\n",
            " [ 0.57004836  0.5773133   0.0803069 ]\n",
            " [ 0.5700432   0.57738052  0.06388204]\n",
            " [ 0.57006001  0.57747373  0.04285995]\n",
            " [ 0.57009765  0.57759144  0.01751345]\n",
            " [ 0.57015498  0.57773217 -0.01188467]\n",
            " [ 0.57023088  0.57789442 -0.04506159]\n",
            " [ 0.5703242   0.57807671 -0.08174451]\n",
            " [ 0.5704338   0.57827755 -0.12166062]\n",
            " [ 0.57055856  0.57849543 -0.16453711]\n",
            " [ 0.57069733  0.57872888 -0.21010118]\n",
            " [ 0.57084898  0.5789764  -0.25808002]\n",
            " [ 0.57101237  0.5792365  -0.30820083]\n",
            " [ 0.57118636  0.5795077  -0.36019079]\n",
            " [ 0.57136983  0.57978849 -0.41377711]\n",
            " [ 0.57156163  0.5800774  -0.46868697]\n",
            " [ 0.57176063  0.58037292 -0.52464756]\n",
            " [ 0.57196568  0.58067358 -0.58138609]\n",
            " [ 0.57217567  0.58097787 -0.63862974]\n",
            " [ 0.57238944  0.58128432 -0.69610571]\n",
            " [ 0.57260586  0.58159142 -0.75354119]\n",
            " [ 0.5728238   0.58189769 -0.81066338]\n",
            " [ 0.57304211  0.58220164 -0.86719946]\n",
            " [ 0.57325968  0.58250177 -0.92287663]\n",
            " [ 0.57347534  0.58279661 -0.97742209]\n",
            " [ 0.57368798  0.58308465 -1.03056303]\n",
            " [ 0.57389646  0.5833644  -1.08202663]\n",
            " [ 0.57409963  0.58363438 -1.1315401 ]\n",
            " [ 0.57429636  0.5838931  -1.17883063]\n",
            " [ 0.57448553  0.58413906 -1.22362541]\n",
            " [ 0.57466598  0.58437077 -1.26565163]\n",
            " [ 0.57483658  0.58458675 -1.30463649]\n",
            " [ 0.5749962   0.5847855  -1.34030718]\n",
            " [ 0.5751437   0.58496553 -1.3723909 ]\n",
            " [ 0.57527795  0.58512536 -1.40061483]\n",
            " [ 0.57539781  0.58526349 -1.42470618]\n",
            " [ 0.57550214  0.58537843 -1.44439212]\n",
            " [ 0.5755898   0.58546869 -1.45939987]\n",
            " [ 0.57565966  0.58553279 -1.46945661]\n",
            " [ 0.57571059  0.58556922 -1.47428953]\n",
            " [ 0.57574145  0.5855765  -1.47362583]\n",
            " [ 0.57575109  0.58555314 -1.4671927 ]\n",
            " [ 0.57573839  0.58549765 -1.45471733]\n",
            " [ 0.57570221  0.58540854 -1.43592692]\n",
            " [ 0.57564142  0.58528432 -1.41054866]\n",
            " [ 0.57555487  0.5851235  -1.37830975]\n",
            " [ 0.57544142  0.58492458 -1.33893737]\n",
            " [ 0.57529996  0.58468608 -1.29215873]\n",
            " [ 0.57512933  0.58440651 -1.23770101]\n",
            " [ 0.5749284   0.58408437 -1.1752914 ]]\n",
            "(73, 3)\n",
            "(1, 73, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlifWA4C6cK_",
        "outputId": "46af7830-3e4f-45dd-8bbf-0f4b59c54b75"
      },
      "source": [
        "for j in range(2,16046):\n",
        "    try:\n",
        "        train_input = pd.DataFrame(data = train_df[j], columns = [\"Icao\",\"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "        train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "        train_input = train_input.set_index('Time')\n",
        "        train_input = train_input.drop('PosTime', axis = 1)\n",
        "        unique_species = train_input.Type[0]\n",
        "        norm_train_df = pd.DataFrame()\n",
        "        norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "        norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "        norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "        norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "        norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "        norm_train_df.reset_index(inplace = True)\n",
        "        #norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "        norm_train_df = norm_train_df.iloc[0:73]\n",
        "        norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "        norm_train_df = norm_train_df.to_numpy()\n",
        "        norm_train_df = np.reshape(norm_train_df, (1,73,3))\n",
        "        final_input_train = np.append(final_input_train, norm_train_df, axis = 0)\n",
        "        train_labels.append(unique_species)\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "print(final_input_train.shape)\n",
        "print(len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10376, 73, 3)\n",
            "10376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsI7JLBl7F6Q",
        "outputId": "f094b665-35e0-416a-8a67-6f4f94c66d3a"
      },
      "source": [
        "#convert lists to numpy array\n",
        "final_input_train = np.array(final_input_train)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "#shuffle arrays\n",
        "shuffler = np.random.permutation(len(final_input_train))\n",
        "final_input_train = final_input_train[shuffler]\n",
        "train_labels = train_labels[shuffler]\n",
        "\n",
        "#split into train and test\n",
        "final_input_test = final_input_train[7263:]\n",
        "arr = list(range(7263,final_input_train.shape[0] ))\n",
        "print(final_input_test.shape)\n",
        "\n",
        "final_input_train = np.delete(final_input_train, arr, 0)\n",
        "print(final_input_train.shape)\n",
        "\n",
        "test_labels = train_labels[7263:]\n",
        "print(len(test_labels))\n",
        "\n",
        "train_labels_final = train_labels[:7263]\n",
        "print(len(train_labels_final))\n",
        "\n",
        "#Get Unique values in each dataframe\n",
        "unique = list(dict.fromkeys(test_labels))\n",
        "unique2 = list(dict.fromkeys(train_labels_final))\n",
        "print(unique)\n",
        "print(unique2)\n",
        "\n",
        "#One Hot Encode Types\n",
        "from keras.utils.np_utils import to_categorical\n",
        "test_labels = to_categorical(test_labels,num_classes = 10)\n",
        "train_labels_final = to_categorical(train_labels_final,num_classes = 10)\n",
        "print(len(test_labels))\n",
        "print(len(train_labels_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3113, 73, 3)\n",
            "(7263, 73, 3)\n",
            "3113\n",
            "7263\n",
            "[0, 4, 2, 5, 3, 9, 6, 7, 1, 8]\n",
            "[1, 4, 2, 0, 7, 6, 8, 5, 3, 9]\n",
            "3113\n",
            "7263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHbi44ym6cLC",
        "outputId": "32725913-17f7-4f25-ca72-e9e9e7b02d82"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "import keras\n",
        "# fit and evaluate a model\n",
        "verbose, epochs, batch_size = 2, 300, 128\n",
        "n_timesteps, n_features, n_outputs = final_input_train.shape[1], final_input_train.shape[2], 10\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "# fit network\n",
        "history =  model.fit(final_input_train, train_labels_final, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle = True)\n",
        "# evaluate model\n",
        "_, accuracy = model.evaluate(final_input_test, test_labels, batch_size=batch_size, verbose=0)\n",
        "print(accuracy *100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "57/57 - 4s - loss: 2.2994 - accuracy: 0.2221\n",
            "Epoch 2/300\n",
            "57/57 - 3s - loss: 2.0940 - accuracy: 0.3007\n",
            "Epoch 3/300\n",
            "57/57 - 3s - loss: 2.0621 - accuracy: 0.3591\n",
            "Epoch 4/300\n",
            "57/57 - 3s - loss: 1.8707 - accuracy: 0.3693\n",
            "Epoch 5/300\n",
            "57/57 - 3s - loss: 1.7801 - accuracy: 0.3848\n",
            "Epoch 6/300\n",
            "57/57 - 3s - loss: 1.7727 - accuracy: 0.3931\n",
            "Epoch 7/300\n",
            "57/57 - 3s - loss: 1.7689 - accuracy: 0.3963\n",
            "Epoch 8/300\n",
            "57/57 - 3s - loss: 1.6792 - accuracy: 0.4037\n",
            "Epoch 9/300\n",
            "57/57 - 3s - loss: 1.7575 - accuracy: 0.4036\n",
            "Epoch 10/300\n",
            "57/57 - 3s - loss: 1.6615 - accuracy: 0.4117\n",
            "Epoch 11/300\n",
            "57/57 - 3s - loss: 1.6862 - accuracy: 0.4102\n",
            "Epoch 12/300\n",
            "57/57 - 3s - loss: 1.6552 - accuracy: 0.4078\n",
            "Epoch 13/300\n",
            "57/57 - 3s - loss: 1.6324 - accuracy: 0.4146\n",
            "Epoch 14/300\n",
            "57/57 - 3s - loss: 1.6412 - accuracy: 0.4153\n",
            "Epoch 15/300\n",
            "57/57 - 3s - loss: 1.6114 - accuracy: 0.4154\n",
            "Epoch 16/300\n",
            "57/57 - 3s - loss: 1.6121 - accuracy: 0.4184\n",
            "Epoch 17/300\n",
            "57/57 - 3s - loss: 1.5792 - accuracy: 0.4215\n",
            "Epoch 18/300\n",
            "57/57 - 3s - loss: 1.5810 - accuracy: 0.4227\n",
            "Epoch 19/300\n",
            "57/57 - 3s - loss: 1.5811 - accuracy: 0.4241\n",
            "Epoch 20/300\n",
            "57/57 - 3s - loss: 1.5566 - accuracy: 0.4216\n",
            "Epoch 21/300\n",
            "57/57 - 3s - loss: 1.5562 - accuracy: 0.4278\n",
            "Epoch 22/300\n",
            "57/57 - 3s - loss: 1.5403 - accuracy: 0.4279\n",
            "Epoch 23/300\n",
            "57/57 - 3s - loss: 1.5343 - accuracy: 0.4239\n",
            "Epoch 24/300\n",
            "57/57 - 3s - loss: 1.5441 - accuracy: 0.4325\n",
            "Epoch 25/300\n",
            "57/57 - 3s - loss: 1.5381 - accuracy: 0.4305\n",
            "Epoch 26/300\n",
            "57/57 - 3s - loss: 1.5370 - accuracy: 0.4318\n",
            "Epoch 27/300\n",
            "57/57 - 3s - loss: 1.5157 - accuracy: 0.4325\n",
            "Epoch 28/300\n",
            "57/57 - 3s - loss: 1.5044 - accuracy: 0.4382\n",
            "Epoch 29/300\n",
            "57/57 - 3s - loss: 1.5027 - accuracy: 0.4394\n",
            "Epoch 30/300\n",
            "57/57 - 3s - loss: 1.5224 - accuracy: 0.4371\n",
            "Epoch 31/300\n",
            "57/57 - 3s - loss: 1.5292 - accuracy: 0.4385\n",
            "Epoch 32/300\n",
            "57/57 - 3s - loss: 1.4934 - accuracy: 0.4388\n",
            "Epoch 33/300\n",
            "57/57 - 3s - loss: 1.4850 - accuracy: 0.4442\n",
            "Epoch 34/300\n",
            "57/57 - 3s - loss: 1.5003 - accuracy: 0.4409\n",
            "Epoch 35/300\n",
            "57/57 - 3s - loss: 1.4772 - accuracy: 0.4471\n",
            "Epoch 36/300\n",
            "57/57 - 3s - loss: 1.4891 - accuracy: 0.4453\n",
            "Epoch 37/300\n",
            "57/57 - 3s - loss: 1.4837 - accuracy: 0.4428\n",
            "Epoch 38/300\n",
            "57/57 - 3s - loss: 1.4798 - accuracy: 0.4461\n",
            "Epoch 39/300\n",
            "57/57 - 3s - loss: 1.4765 - accuracy: 0.4465\n",
            "Epoch 40/300\n",
            "57/57 - 3s - loss: 1.4706 - accuracy: 0.4506\n",
            "Epoch 41/300\n",
            "57/57 - 3s - loss: 1.4762 - accuracy: 0.4486\n",
            "Epoch 42/300\n",
            "57/57 - 3s - loss: 1.4641 - accuracy: 0.4567\n",
            "Epoch 43/300\n",
            "57/57 - 3s - loss: 1.4606 - accuracy: 0.4589\n",
            "Epoch 44/300\n",
            "57/57 - 3s - loss: 1.4548 - accuracy: 0.4526\n",
            "Epoch 45/300\n",
            "57/57 - 3s - loss: 1.4626 - accuracy: 0.4520\n",
            "Epoch 46/300\n",
            "57/57 - 3s - loss: 1.4544 - accuracy: 0.4541\n",
            "Epoch 47/300\n",
            "57/57 - 3s - loss: 1.4533 - accuracy: 0.4559\n",
            "Epoch 48/300\n",
            "57/57 - 3s - loss: 1.4513 - accuracy: 0.4563\n",
            "Epoch 49/300\n",
            "57/57 - 3s - loss: 1.4457 - accuracy: 0.4515\n",
            "Epoch 50/300\n",
            "57/57 - 3s - loss: 1.4476 - accuracy: 0.4527\n",
            "Epoch 51/300\n",
            "57/57 - 3s - loss: 1.4513 - accuracy: 0.4515\n",
            "Epoch 52/300\n",
            "57/57 - 3s - loss: 1.4380 - accuracy: 0.4574\n",
            "Epoch 53/300\n",
            "57/57 - 3s - loss: 1.4425 - accuracy: 0.4574\n",
            "Epoch 54/300\n",
            "57/57 - 3s - loss: 1.4398 - accuracy: 0.4608\n",
            "Epoch 55/300\n",
            "57/57 - 3s - loss: 1.4317 - accuracy: 0.4639\n",
            "Epoch 56/300\n",
            "57/57 - 3s - loss: 1.4289 - accuracy: 0.4601\n",
            "Epoch 57/300\n",
            "57/57 - 3s - loss: 1.4349 - accuracy: 0.4628\n",
            "Epoch 58/300\n",
            "57/57 - 3s - loss: 1.4301 - accuracy: 0.4622\n",
            "Epoch 59/300\n",
            "57/57 - 3s - loss: 1.4287 - accuracy: 0.4680\n",
            "Epoch 60/300\n",
            "57/57 - 3s - loss: 1.4275 - accuracy: 0.4670\n",
            "Epoch 61/300\n",
            "57/57 - 3s - loss: 1.4269 - accuracy: 0.4651\n",
            "Epoch 62/300\n",
            "57/57 - 3s - loss: 1.4354 - accuracy: 0.4656\n",
            "Epoch 63/300\n",
            "57/57 - 3s - loss: 1.4548 - accuracy: 0.4637\n",
            "Epoch 64/300\n",
            "57/57 - 3s - loss: 1.4317 - accuracy: 0.4679\n",
            "Epoch 65/300\n",
            "57/57 - 3s - loss: 1.4229 - accuracy: 0.4633\n",
            "Epoch 66/300\n",
            "57/57 - 3s - loss: 1.4207 - accuracy: 0.4720\n",
            "Epoch 67/300\n",
            "57/57 - 3s - loss: 1.4090 - accuracy: 0.4738\n",
            "Epoch 68/300\n",
            "57/57 - 3s - loss: 1.4091 - accuracy: 0.4647\n",
            "Epoch 69/300\n",
            "57/57 - 3s - loss: 1.4114 - accuracy: 0.4699\n",
            "Epoch 70/300\n",
            "57/57 - 3s - loss: 1.4089 - accuracy: 0.4740\n",
            "Epoch 71/300\n",
            "57/57 - 3s - loss: 1.4060 - accuracy: 0.4768\n",
            "Epoch 72/300\n",
            "57/57 - 3s - loss: 1.3999 - accuracy: 0.4765\n",
            "Epoch 73/300\n",
            "57/57 - 3s - loss: 1.4000 - accuracy: 0.4762\n",
            "Epoch 74/300\n",
            "57/57 - 3s - loss: 1.3986 - accuracy: 0.4736\n",
            "Epoch 75/300\n",
            "57/57 - 3s - loss: 1.4002 - accuracy: 0.4687\n",
            "Epoch 76/300\n",
            "57/57 - 3s - loss: 1.3914 - accuracy: 0.4749\n",
            "Epoch 77/300\n",
            "57/57 - 3s - loss: 1.3935 - accuracy: 0.4786\n",
            "Epoch 78/300\n",
            "57/57 - 3s - loss: 1.3923 - accuracy: 0.4785\n",
            "Epoch 79/300\n",
            "57/57 - 3s - loss: 1.3881 - accuracy: 0.4786\n",
            "Epoch 80/300\n",
            "57/57 - 3s - loss: 1.3934 - accuracy: 0.4716\n",
            "Epoch 81/300\n",
            "57/57 - 3s - loss: 1.3859 - accuracy: 0.4782\n",
            "Epoch 82/300\n",
            "57/57 - 3s - loss: 1.3865 - accuracy: 0.4731\n",
            "Epoch 83/300\n",
            "57/57 - 3s - loss: 1.3823 - accuracy: 0.4823\n",
            "Epoch 84/300\n",
            "57/57 - 3s - loss: 1.3833 - accuracy: 0.4815\n",
            "Epoch 85/300\n",
            "57/57 - 3s - loss: 1.3765 - accuracy: 0.4776\n",
            "Epoch 86/300\n",
            "57/57 - 3s - loss: 1.3718 - accuracy: 0.4785\n",
            "Epoch 87/300\n",
            "57/57 - 3s - loss: 1.3798 - accuracy: 0.4772\n",
            "Epoch 88/300\n",
            "57/57 - 3s - loss: 1.3750 - accuracy: 0.4802\n",
            "Epoch 89/300\n",
            "57/57 - 3s - loss: 1.3744 - accuracy: 0.4846\n",
            "Epoch 90/300\n",
            "57/57 - 3s - loss: 1.3668 - accuracy: 0.4878\n",
            "Epoch 91/300\n",
            "57/57 - 3s - loss: 1.3699 - accuracy: 0.4819\n",
            "Epoch 92/300\n",
            "57/57 - 3s - loss: 1.3636 - accuracy: 0.4860\n",
            "Epoch 93/300\n",
            "57/57 - 3s - loss: 1.3650 - accuracy: 0.4848\n",
            "Epoch 94/300\n",
            "57/57 - 3s - loss: 1.3610 - accuracy: 0.4891\n",
            "Epoch 95/300\n",
            "57/57 - 3s - loss: 1.3679 - accuracy: 0.4857\n",
            "Epoch 96/300\n",
            "57/57 - 3s - loss: 1.3573 - accuracy: 0.4925\n",
            "Epoch 97/300\n",
            "57/57 - 3s - loss: 1.3615 - accuracy: 0.4899\n",
            "Epoch 98/300\n",
            "57/57 - 3s - loss: 1.3567 - accuracy: 0.4907\n",
            "Epoch 99/300\n",
            "57/57 - 3s - loss: 1.3557 - accuracy: 0.4935\n",
            "Epoch 100/300\n",
            "57/57 - 3s - loss: 1.3537 - accuracy: 0.4951\n",
            "Epoch 101/300\n",
            "57/57 - 3s - loss: 1.3472 - accuracy: 0.4906\n",
            "Epoch 102/300\n",
            "57/57 - 3s - loss: 1.3489 - accuracy: 0.4918\n",
            "Epoch 103/300\n",
            "57/57 - 3s - loss: 1.3548 - accuracy: 0.4875\n",
            "Epoch 104/300\n",
            "57/57 - 3s - loss: 1.3439 - accuracy: 0.4935\n",
            "Epoch 105/300\n",
            "57/57 - 3s - loss: 1.3449 - accuracy: 0.4951\n",
            "Epoch 106/300\n",
            "57/57 - 3s - loss: 1.3400 - accuracy: 0.4910\n",
            "Epoch 107/300\n",
            "57/57 - 3s - loss: 1.3431 - accuracy: 0.4958\n",
            "Epoch 108/300\n",
            "57/57 - 3s - loss: 1.3398 - accuracy: 0.4952\n",
            "Epoch 109/300\n",
            "57/57 - 3s - loss: 1.3358 - accuracy: 0.4964\n",
            "Epoch 110/300\n",
            "57/57 - 3s - loss: 1.3298 - accuracy: 0.4995\n",
            "Epoch 111/300\n",
            "57/57 - 3s - loss: 1.3268 - accuracy: 0.4994\n",
            "Epoch 112/300\n",
            "57/57 - 3s - loss: 1.3283 - accuracy: 0.4977\n",
            "Epoch 113/300\n",
            "57/57 - 3s - loss: 1.3315 - accuracy: 0.5005\n",
            "Epoch 114/300\n",
            "57/57 - 3s - loss: 1.3264 - accuracy: 0.5038\n",
            "Epoch 115/300\n",
            "57/57 - 3s - loss: 1.3217 - accuracy: 0.5019\n",
            "Epoch 116/300\n",
            "57/57 - 3s - loss: 1.3213 - accuracy: 0.5035\n",
            "Epoch 117/300\n",
            "57/57 - 3s - loss: 1.3236 - accuracy: 0.4977\n",
            "Epoch 118/300\n",
            "57/57 - 3s - loss: 1.3177 - accuracy: 0.4992\n",
            "Epoch 119/300\n",
            "57/57 - 3s - loss: 1.3161 - accuracy: 0.5082\n",
            "Epoch 120/300\n",
            "57/57 - 3s - loss: 1.3144 - accuracy: 0.5089\n",
            "Epoch 121/300\n",
            "57/57 - 3s - loss: 1.3108 - accuracy: 0.5027\n",
            "Epoch 122/300\n",
            "57/57 - 3s - loss: 1.3058 - accuracy: 0.5035\n",
            "Epoch 123/300\n",
            "57/57 - 3s - loss: 1.3018 - accuracy: 0.5100\n",
            "Epoch 124/300\n",
            "57/57 - 3s - loss: 1.3102 - accuracy: 0.5031\n",
            "Epoch 125/300\n",
            "57/57 - 3s - loss: 1.3026 - accuracy: 0.5104\n",
            "Epoch 126/300\n",
            "57/57 - 3s - loss: 1.3020 - accuracy: 0.5131\n",
            "Epoch 127/300\n",
            "57/57 - 3s - loss: 1.3029 - accuracy: 0.5089\n",
            "Epoch 128/300\n",
            "57/57 - 3s - loss: 1.2984 - accuracy: 0.5096\n",
            "Epoch 129/300\n",
            "57/57 - 3s - loss: 1.2969 - accuracy: 0.5127\n",
            "Epoch 130/300\n",
            "57/57 - 3s - loss: 1.2959 - accuracy: 0.5143\n",
            "Epoch 131/300\n",
            "57/57 - 3s - loss: 1.2927 - accuracy: 0.5075\n",
            "Epoch 132/300\n",
            "57/57 - 3s - loss: 1.3056 - accuracy: 0.5119\n",
            "Epoch 133/300\n",
            "57/57 - 3s - loss: 1.2921 - accuracy: 0.5126\n",
            "Epoch 134/300\n",
            "57/57 - 3s - loss: 1.2930 - accuracy: 0.5210\n",
            "Epoch 135/300\n",
            "57/57 - 3s - loss: 1.2904 - accuracy: 0.5140\n",
            "Epoch 136/300\n",
            "57/57 - 3s - loss: 1.2908 - accuracy: 0.5147\n",
            "Epoch 137/300\n",
            "57/57 - 3s - loss: 1.2788 - accuracy: 0.5123\n",
            "Epoch 138/300\n",
            "57/57 - 3s - loss: 1.2831 - accuracy: 0.5123\n",
            "Epoch 139/300\n",
            "57/57 - 3s - loss: 1.2770 - accuracy: 0.5173\n",
            "Epoch 140/300\n",
            "57/57 - 3s - loss: 1.2744 - accuracy: 0.5177\n",
            "Epoch 141/300\n",
            "57/57 - 3s - loss: 1.2723 - accuracy: 0.5232\n",
            "Epoch 142/300\n",
            "57/57 - 3s - loss: 1.2727 - accuracy: 0.5224\n",
            "Epoch 143/300\n",
            "57/57 - 3s - loss: 1.2703 - accuracy: 0.5280\n",
            "Epoch 144/300\n",
            "57/57 - 3s - loss: 1.2665 - accuracy: 0.5233\n",
            "Epoch 145/300\n",
            "57/57 - 3s - loss: 1.2665 - accuracy: 0.5271\n",
            "Epoch 146/300\n",
            "57/57 - 3s - loss: 1.2646 - accuracy: 0.5226\n",
            "Epoch 147/300\n",
            "57/57 - 3s - loss: 1.2684 - accuracy: 0.5217\n",
            "Epoch 148/300\n",
            "57/57 - 3s - loss: 1.2669 - accuracy: 0.5222\n",
            "Epoch 149/300\n",
            "57/57 - 3s - loss: 1.2647 - accuracy: 0.5210\n",
            "Epoch 150/300\n",
            "57/57 - 3s - loss: 1.2597 - accuracy: 0.5240\n",
            "Epoch 151/300\n",
            "57/57 - 3s - loss: 1.2604 - accuracy: 0.5290\n",
            "Epoch 152/300\n",
            "57/57 - 3s - loss: 1.2533 - accuracy: 0.5312\n",
            "Epoch 153/300\n",
            "57/57 - 3s - loss: 1.2517 - accuracy: 0.5265\n",
            "Epoch 154/300\n",
            "57/57 - 3s - loss: 1.2476 - accuracy: 0.5316\n",
            "Epoch 155/300\n",
            "57/57 - 3s - loss: 1.2498 - accuracy: 0.5243\n",
            "Epoch 156/300\n",
            "57/57 - 3s - loss: 1.2475 - accuracy: 0.5225\n",
            "Epoch 157/300\n",
            "57/57 - 3s - loss: 1.2500 - accuracy: 0.5306\n",
            "Epoch 158/300\n",
            "57/57 - 3s - loss: 1.2423 - accuracy: 0.5288\n",
            "Epoch 159/300\n",
            "57/57 - 3s - loss: 1.2421 - accuracy: 0.5316\n",
            "Epoch 160/300\n",
            "57/57 - 3s - loss: 1.2384 - accuracy: 0.5338\n",
            "Epoch 161/300\n",
            "57/57 - 3s - loss: 1.2378 - accuracy: 0.5346\n",
            "Epoch 162/300\n",
            "57/57 - 3s - loss: 1.2301 - accuracy: 0.5377\n",
            "Epoch 163/300\n",
            "57/57 - 3s - loss: 1.2328 - accuracy: 0.5357\n",
            "Epoch 164/300\n",
            "57/57 - 3s - loss: 1.2376 - accuracy: 0.5315\n",
            "Epoch 165/300\n",
            "57/57 - 3s - loss: 1.2314 - accuracy: 0.5342\n",
            "Epoch 166/300\n",
            "57/57 - 3s - loss: 1.2261 - accuracy: 0.5399\n",
            "Epoch 167/300\n",
            "57/57 - 3s - loss: 1.2232 - accuracy: 0.5386\n",
            "Epoch 168/300\n",
            "57/57 - 3s - loss: 1.2246 - accuracy: 0.5399\n",
            "Epoch 169/300\n",
            "57/57 - 3s - loss: 1.2221 - accuracy: 0.5374\n",
            "Epoch 170/300\n",
            "57/57 - 3s - loss: 1.2212 - accuracy: 0.5410\n",
            "Epoch 171/300\n",
            "57/57 - 3s - loss: 1.2187 - accuracy: 0.5441\n",
            "Epoch 172/300\n",
            "57/57 - 3s - loss: 1.2139 - accuracy: 0.5388\n",
            "Epoch 173/300\n",
            "57/57 - 3s - loss: 1.2152 - accuracy: 0.5437\n",
            "Epoch 174/300\n",
            "57/57 - 3s - loss: 1.2153 - accuracy: 0.5411\n",
            "Epoch 175/300\n",
            "57/57 - 3s - loss: 1.2114 - accuracy: 0.5425\n",
            "Epoch 176/300\n",
            "57/57 - 3s - loss: 1.2071 - accuracy: 0.5441\n",
            "Epoch 177/300\n",
            "57/57 - 3s - loss: 1.2102 - accuracy: 0.5496\n",
            "Epoch 178/300\n",
            "57/57 - 3s - loss: 1.2069 - accuracy: 0.5405\n",
            "Epoch 179/300\n",
            "57/57 - 3s - loss: 1.1953 - accuracy: 0.5535\n",
            "Epoch 180/300\n",
            "57/57 - 3s - loss: 1.2017 - accuracy: 0.5491\n",
            "Epoch 181/300\n",
            "57/57 - 3s - loss: 1.2012 - accuracy: 0.5492\n",
            "Epoch 182/300\n",
            "57/57 - 3s - loss: 1.2000 - accuracy: 0.5525\n",
            "Epoch 183/300\n",
            "57/57 - 3s - loss: 1.1940 - accuracy: 0.5489\n",
            "Epoch 184/300\n",
            "57/57 - 3s - loss: 1.1947 - accuracy: 0.5498\n",
            "Epoch 185/300\n",
            "57/57 - 3s - loss: 1.1932 - accuracy: 0.5496\n",
            "Epoch 186/300\n",
            "57/57 - 3s - loss: 1.1899 - accuracy: 0.5459\n",
            "Epoch 187/300\n",
            "57/57 - 3s - loss: 1.1902 - accuracy: 0.5534\n",
            "Epoch 188/300\n",
            "57/57 - 3s - loss: 1.1818 - accuracy: 0.5549\n",
            "Epoch 189/300\n",
            "57/57 - 3s - loss: 1.1858 - accuracy: 0.5557\n",
            "Epoch 190/300\n",
            "57/57 - 3s - loss: 1.1860 - accuracy: 0.5476\n",
            "Epoch 191/300\n",
            "57/57 - 3s - loss: 1.1811 - accuracy: 0.5488\n",
            "Epoch 192/300\n",
            "57/57 - 3s - loss: 1.1791 - accuracy: 0.5520\n",
            "Epoch 193/300\n",
            "57/57 - 3s - loss: 1.1782 - accuracy: 0.5578\n",
            "Epoch 194/300\n",
            "57/57 - 3s - loss: 1.1758 - accuracy: 0.5531\n",
            "Epoch 195/300\n",
            "57/57 - 3s - loss: 1.1736 - accuracy: 0.5545\n",
            "Epoch 196/300\n",
            "57/57 - 3s - loss: 1.1676 - accuracy: 0.5609\n",
            "Epoch 197/300\n",
            "57/57 - 3s - loss: 1.1766 - accuracy: 0.5582\n",
            "Epoch 198/300\n",
            "57/57 - 3s - loss: 1.1656 - accuracy: 0.5591\n",
            "Epoch 199/300\n",
            "57/57 - 3s - loss: 1.1699 - accuracy: 0.5611\n",
            "Epoch 200/300\n",
            "57/57 - 3s - loss: 1.1632 - accuracy: 0.5670\n",
            "Epoch 201/300\n",
            "57/57 - 3s - loss: 1.1634 - accuracy: 0.5580\n",
            "Epoch 202/300\n",
            "57/57 - 3s - loss: 1.1595 - accuracy: 0.5642\n",
            "Epoch 203/300\n",
            "57/57 - 3s - loss: 1.1651 - accuracy: 0.5642\n",
            "Epoch 204/300\n",
            "57/57 - 3s - loss: 1.1581 - accuracy: 0.5608\n",
            "Epoch 205/300\n",
            "57/57 - 3s - loss: 1.1634 - accuracy: 0.5597\n",
            "Epoch 206/300\n",
            "57/57 - 3s - loss: 1.1538 - accuracy: 0.5718\n",
            "Epoch 207/300\n",
            "57/57 - 3s - loss: 1.1566 - accuracy: 0.5713\n",
            "Epoch 208/300\n",
            "57/57 - 3s - loss: 1.1486 - accuracy: 0.5673\n",
            "Epoch 209/300\n",
            "57/57 - 3s - loss: 1.1458 - accuracy: 0.5662\n",
            "Epoch 210/300\n",
            "57/57 - 3s - loss: 1.1497 - accuracy: 0.5673\n",
            "Epoch 211/300\n",
            "57/57 - 3s - loss: 1.1503 - accuracy: 0.5725\n",
            "Epoch 212/300\n",
            "57/57 - 3s - loss: 1.1469 - accuracy: 0.5715\n",
            "Epoch 213/300\n",
            "57/57 - 3s - loss: 1.1467 - accuracy: 0.5637\n",
            "Epoch 214/300\n",
            "57/57 - 3s - loss: 1.1387 - accuracy: 0.5719\n",
            "Epoch 215/300\n",
            "57/57 - 3s - loss: 1.1428 - accuracy: 0.5646\n",
            "Epoch 216/300\n",
            "57/57 - 3s - loss: 1.1367 - accuracy: 0.5697\n",
            "Epoch 217/300\n",
            "57/57 - 3s - loss: 1.1406 - accuracy: 0.5707\n",
            "Epoch 218/300\n",
            "57/57 - 3s - loss: 1.1284 - accuracy: 0.5763\n",
            "Epoch 219/300\n",
            "57/57 - 3s - loss: 1.1331 - accuracy: 0.5724\n",
            "Epoch 220/300\n",
            "57/57 - 3s - loss: 1.1329 - accuracy: 0.5719\n",
            "Epoch 221/300\n",
            "57/57 - 3s - loss: 1.1329 - accuracy: 0.5719\n",
            "Epoch 222/300\n",
            "57/57 - 3s - loss: 1.1538 - accuracy: 0.5737\n",
            "Epoch 223/300\n",
            "57/57 - 3s - loss: 1.1258 - accuracy: 0.5757\n",
            "Epoch 224/300\n",
            "57/57 - 3s - loss: 1.1211 - accuracy: 0.5757\n",
            "Epoch 225/300\n",
            "57/57 - 3s - loss: 1.1283 - accuracy: 0.5783\n",
            "Epoch 226/300\n",
            "57/57 - 3s - loss: 1.1201 - accuracy: 0.5703\n",
            "Epoch 227/300\n",
            "57/57 - 3s - loss: 1.1290 - accuracy: 0.5784\n",
            "Epoch 228/300\n",
            "57/57 - 3s - loss: 1.1175 - accuracy: 0.5780\n",
            "Epoch 229/300\n",
            "57/57 - 3s - loss: 1.1140 - accuracy: 0.5761\n",
            "Epoch 230/300\n",
            "57/57 - 3s - loss: 1.1116 - accuracy: 0.5797\n",
            "Epoch 231/300\n",
            "57/57 - 3s - loss: 1.1137 - accuracy: 0.5798\n",
            "Epoch 232/300\n",
            "57/57 - 3s - loss: 1.1053 - accuracy: 0.5725\n",
            "Epoch 233/300\n",
            "57/57 - 3s - loss: 1.1098 - accuracy: 0.5806\n",
            "Epoch 234/300\n",
            "57/57 - 3s - loss: 1.1048 - accuracy: 0.5788\n",
            "Epoch 235/300\n",
            "57/57 - 3s - loss: 1.1071 - accuracy: 0.5809\n",
            "Epoch 236/300\n",
            "57/57 - 3s - loss: 1.1011 - accuracy: 0.5798\n",
            "Epoch 237/300\n",
            "57/57 - 3s - loss: 1.0976 - accuracy: 0.5842\n",
            "Epoch 238/300\n",
            "57/57 - 3s - loss: 1.0968 - accuracy: 0.5907\n",
            "Epoch 239/300\n",
            "57/57 - 3s - loss: 1.0948 - accuracy: 0.5896\n",
            "Epoch 240/300\n",
            "57/57 - 3s - loss: 1.0945 - accuracy: 0.5872\n",
            "Epoch 241/300\n",
            "57/57 - 3s - loss: 1.0998 - accuracy: 0.5813\n",
            "Epoch 242/300\n",
            "57/57 - 3s - loss: 1.0939 - accuracy: 0.5823\n",
            "Epoch 243/300\n",
            "57/57 - 3s - loss: 1.0915 - accuracy: 0.5865\n",
            "Epoch 244/300\n",
            "57/57 - 3s - loss: 1.0922 - accuracy: 0.5874\n",
            "Epoch 245/300\n",
            "57/57 - 3s - loss: 1.0861 - accuracy: 0.5926\n",
            "Epoch 246/300\n",
            "57/57 - 3s - loss: 1.0911 - accuracy: 0.5864\n",
            "Epoch 247/300\n",
            "57/57 - 3s - loss: 1.0866 - accuracy: 0.5865\n",
            "Epoch 248/300\n",
            "57/57 - 3s - loss: 1.0844 - accuracy: 0.5938\n",
            "Epoch 249/300\n",
            "57/57 - 3s - loss: 1.0782 - accuracy: 0.5880\n",
            "Epoch 250/300\n",
            "57/57 - 3s - loss: 1.0770 - accuracy: 0.5934\n",
            "Epoch 251/300\n",
            "57/57 - 3s - loss: 1.0759 - accuracy: 0.5998\n",
            "Epoch 252/300\n",
            "57/57 - 3s - loss: 1.0752 - accuracy: 0.5942\n",
            "Epoch 253/300\n",
            "57/57 - 3s - loss: 1.0801 - accuracy: 0.5898\n",
            "Epoch 254/300\n",
            "57/57 - 3s - loss: 1.0771 - accuracy: 0.5958\n",
            "Epoch 255/300\n",
            "57/57 - 3s - loss: 1.0636 - accuracy: 0.5984\n",
            "Epoch 256/300\n",
            "57/57 - 3s - loss: 1.0673 - accuracy: 0.5991\n",
            "Epoch 257/300\n",
            "57/57 - 3s - loss: 1.0679 - accuracy: 0.5955\n",
            "Epoch 258/300\n",
            "57/57 - 3s - loss: 1.0640 - accuracy: 0.5985\n",
            "Epoch 259/300\n",
            "57/57 - 3s - loss: 1.0674 - accuracy: 0.5922\n",
            "Epoch 260/300\n",
            "57/57 - 3s - loss: 1.0616 - accuracy: 0.5967\n",
            "Epoch 261/300\n",
            "57/57 - 3s - loss: 1.0646 - accuracy: 0.5977\n",
            "Epoch 262/300\n",
            "57/57 - 3s - loss: 1.0619 - accuracy: 0.6011\n",
            "Epoch 263/300\n",
            "57/57 - 3s - loss: 1.0645 - accuracy: 0.6024\n",
            "Epoch 264/300\n",
            "57/57 - 3s - loss: 1.0571 - accuracy: 0.6002\n",
            "Epoch 265/300\n",
            "57/57 - 3s - loss: 1.0553 - accuracy: 0.6003\n",
            "Epoch 266/300\n",
            "57/57 - 3s - loss: 1.0514 - accuracy: 0.6057\n",
            "Epoch 267/300\n",
            "57/57 - 3s - loss: 1.0506 - accuracy: 0.6044\n",
            "Epoch 268/300\n",
            "57/57 - 3s - loss: 1.0467 - accuracy: 0.6068\n",
            "Epoch 269/300\n",
            "57/57 - 3s - loss: 1.0467 - accuracy: 0.6066\n",
            "Epoch 270/300\n",
            "57/57 - 3s - loss: 1.0432 - accuracy: 0.6036\n",
            "Epoch 271/300\n",
            "57/57 - 3s - loss: 1.0456 - accuracy: 0.6077\n",
            "Epoch 272/300\n",
            "57/57 - 3s - loss: 1.0482 - accuracy: 0.6036\n",
            "Epoch 273/300\n",
            "57/57 - 3s - loss: 1.0358 - accuracy: 0.6072\n",
            "Epoch 274/300\n",
            "57/57 - 3s - loss: 1.0382 - accuracy: 0.6113\n",
            "Epoch 275/300\n",
            "57/57 - 3s - loss: 1.0379 - accuracy: 0.6095\n",
            "Epoch 276/300\n",
            "57/57 - 3s - loss: 1.0417 - accuracy: 0.6040\n",
            "Epoch 277/300\n",
            "57/57 - 3s - loss: 1.0391 - accuracy: 0.6087\n",
            "Epoch 278/300\n",
            "57/57 - 3s - loss: 1.0307 - accuracy: 0.6090\n",
            "Epoch 279/300\n",
            "57/57 - 3s - loss: 1.0350 - accuracy: 0.6050\n",
            "Epoch 280/300\n",
            "57/57 - 3s - loss: 1.0380 - accuracy: 0.6042\n",
            "Epoch 281/300\n",
            "57/57 - 3s - loss: 1.0284 - accuracy: 0.6126\n",
            "Epoch 282/300\n",
            "57/57 - 3s - loss: 1.0269 - accuracy: 0.6168\n",
            "Epoch 283/300\n",
            "57/57 - 3s - loss: 1.0275 - accuracy: 0.6123\n",
            "Epoch 284/300\n",
            "57/57 - 3s - loss: 1.0234 - accuracy: 0.6179\n",
            "Epoch 285/300\n",
            "57/57 - 3s - loss: 1.0254 - accuracy: 0.6117\n",
            "Epoch 286/300\n",
            "57/57 - 3s - loss: 1.0161 - accuracy: 0.6148\n",
            "Epoch 287/300\n",
            "57/57 - 3s - loss: 1.0210 - accuracy: 0.6117\n",
            "Epoch 288/300\n",
            "57/57 - 3s - loss: 1.0187 - accuracy: 0.6156\n",
            "Epoch 289/300\n",
            "57/57 - 3s - loss: 1.0181 - accuracy: 0.6188\n",
            "Epoch 290/300\n",
            "57/57 - 3s - loss: 1.0214 - accuracy: 0.6130\n",
            "Epoch 291/300\n",
            "57/57 - 3s - loss: 1.0189 - accuracy: 0.6178\n",
            "Epoch 292/300\n",
            "57/57 - 3s - loss: 1.0168 - accuracy: 0.6204\n",
            "Epoch 293/300\n",
            "57/57 - 3s - loss: 1.0097 - accuracy: 0.6201\n",
            "Epoch 294/300\n",
            "57/57 - 3s - loss: 1.0129 - accuracy: 0.6161\n",
            "Epoch 295/300\n",
            "57/57 - 3s - loss: 1.0076 - accuracy: 0.6161\n",
            "Epoch 296/300\n",
            "57/57 - 3s - loss: 1.0077 - accuracy: 0.6203\n",
            "Epoch 297/300\n",
            "57/57 - 3s - loss: 1.0038 - accuracy: 0.6203\n",
            "Epoch 298/300\n",
            "57/57 - 3s - loss: 0.9981 - accuracy: 0.6248\n",
            "Epoch 299/300\n",
            "57/57 - 3s - loss: 1.0079 - accuracy: 0.6192\n",
            "Epoch 300/300\n",
            "57/57 - 3s - loss: 0.9982 - accuracy: 0.6263\n",
            "41.7282372713089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ET8vNQB66cLD",
        "outputId": "12799307-4648-4456-a72f-72c90a08b020"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "c0-35BSp6cLG",
        "outputId": "c372da71-f5c6-45ca-e9e2-ba63f9fcc638"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEPIjzcsCHlU"
      },
      "source": [
        "# Top 10 Types (rocket)\n",
        "Rocket is another type of model from sklearn that is also well suited for time series data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsC5ZJIcCHlr",
        "outputId": "8fe957ad-c1ac-47ae-bb26-a1886a329f43"
      },
      "source": [
        "#remove rows not in the top 16 types\n",
        "train_df = train_df[train_df['Type'].isin(list(Percentages[:10].index))]\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "994       008DC6  0.088502  0.570442  0.578876  1596723690985  P28A\n",
            "995       008DC6  0.089647  0.570432  0.578902  1596723703073  P28A\n",
            "996       008DC6  0.090028  0.570430  0.578911  1596723717541  P28A\n",
            "997       008DC6  0.090028  0.570430  0.578911  1596723719963  P28A\n",
            "998       008DC6  0.136568  0.570992  0.578782  1596724125875  P28A\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "29550390  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550391  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550392  E94C42  0.286107  0.601955  0.314975  1596733965728  B738\n",
            "29550393  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "29550394  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "\n",
            "[13141213 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7DH2XbkCHlt",
        "outputId": "8984e196-a9b6-4fef-bde7-f0d0166c719b"
      },
      "source": [
        "type_dict = {k: v for v, k in enumerate(list(Percentages[:10].index))}\n",
        "print(type_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B738': 0, 'A320': 1, 'C172': 2, 'A321': 3, 'B737': 4, 'A319': 5, 'P28A': 6, 'A20N': 7, 'B763': 8, 'B739': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU-poqc4CHlt"
      },
      "source": [
        "train_df['Type'].replace(type_dict, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GOngAOvCHlu",
        "outputId": "0923da87-3dd2-4e2b-a64b-a8af9b4146c4"
      },
      "source": [
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "0         008DC6  0.088502  0.570442  0.578876  1596723690985     6\n",
            "1         008DC6  0.089647  0.570432  0.578902  1596723703073     6\n",
            "2         008DC6  0.090028  0.570430  0.578911  1596723717541     6\n",
            "3         008DC6  0.090028  0.570430  0.578911  1596723719963     6\n",
            "4         008DC6  0.136568  0.570992  0.578782  1596724125875     6\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "13141208  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "13141209  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "13141210  E94C42  0.286107  0.601955  0.314975  1596733965728     0\n",
            "13141211  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "13141212  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "\n",
            "[13141213 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg1TJPYuCHlu",
        "outputId": "edc4e278-e3cf-457a-e1fc-4b50f5e2c113"
      },
      "source": [
        "#turn train dataframe into a multi-dimensional numpy array\n",
        "train_df = np.array(list(train_df.groupby('Icao').apply(pd.DataFrame.to_numpy)))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_count = train_df.shape[0]\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16046,)\n",
            "16046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYYPPQ-GCHlu",
        "outputId": "2cc55d52-7e4c-410e-9640-cd16b9d37e42"
      },
      "source": [
        "#load in first dataframe\n",
        "train_input = pd.DataFrame(data = train_df[1], columns = [\"Icao\", \"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "train_input = train_input.set_index('Time')\n",
        "train_input = train_input.drop('PosTime', axis = 1)\n",
        "train_input = train_input.drop('Icao', axis = 1)\n",
        "print(train_input)\n",
        "#Get Species Type\n",
        "unique_species = train_input.Type[0]\n",
        "print(unique_species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                Alt       Lat      Long Type\n",
            "Time                                                        \n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:13:29.760    0.995056  0.540866  0.551703    0\n",
            "2020-08-06 07:13:44.242    0.998108  0.540902  0.551694    0\n",
            "2020-08-06 07:13:56.289  0.00572213  0.540932  0.551686    0\n",
            "...                             ...       ...       ...  ...\n",
            "2020-08-06 16:02:45.713    0.999252   0.54098  0.551676    0\n",
            "2020-08-06 16:02:57.784    0.996963  0.540951  0.551683    0\n",
            "2020-08-06 16:03:55.777    0.994675  0.540866  0.551703    0\n",
            "2020-08-06 16:04:10.278    0.994675  0.540864  0.551703    0\n",
            "2020-08-06 16:04:27.227    0.994675  0.540863  0.551702    0\n",
            "\n",
            "[373 rows x 4 columns]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaJDRM6zCHlv",
        "outputId": "ac1095c5-46c1-4811-8a38-129fc90f77de"
      },
      "source": [
        "#Resampling/Interpolating\n",
        "norm_train_df = pd.DataFrame()\n",
        "norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "norm_train_df.reset_index(inplace = True)\n",
        "#norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "norm_train_df = norm_train_df.iloc[0:73]\n",
        "print(norm_train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Time       Lat      Long       Alt\n",
            "0  2020-08-06 07:10:00  0.541109  0.551641  0.026703\n",
            "1  2020-08-06 07:15:00  0.542472  0.552251  0.217823\n",
            "2  2020-08-06 07:20:00  0.544178  0.553254  0.402075\n",
            "3  2020-08-06 07:25:00  0.546072  0.554713  0.501640\n",
            "4  2020-08-06 07:30:00  0.547895  0.556523  0.586328\n",
            "..                 ...       ...       ...       ...\n",
            "68 2020-08-06 12:50:00  0.575555  0.585123 -1.378310\n",
            "69 2020-08-06 12:55:00  0.575441  0.584925 -1.338937\n",
            "70 2020-08-06 13:00:00  0.575300  0.584686 -1.292159\n",
            "71 2020-08-06 13:05:00  0.575129  0.584407 -1.237701\n",
            "72 2020-08-06 13:10:00  0.574928  0.584084 -1.175291\n",
            "\n",
            "[73 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-t0dckOCHlv",
        "outputId": "017256f5-ae93-4b6d-becc-aaa7bab6c4f0"
      },
      "source": [
        "#add species to label list\n",
        "train_labels = []\n",
        "train_labels.append(unique_species)\n",
        "print(train_labels)\n",
        "#convert dataframe to numpy\n",
        "norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "norm_train_df = norm_train_df.to_numpy()\n",
        "print(norm_train_df)\n",
        "final_input_train = norm_train_df\n",
        "print(final_input_train.shape)\n",
        "final_input_train = np.reshape(final_input_train, (1,73,3))\n",
        "print(final_input_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[ 0.54110926  0.55164051  0.02670329]\n",
            " [ 0.54247236  0.55225104  0.21782254]\n",
            " [ 0.54417837  0.55325353  0.40207523]\n",
            " [ 0.54607177  0.55471271  0.50164034]\n",
            " [ 0.54789543  0.5565232   0.58632792]\n",
            " [ 0.54969102  0.55826527  0.59510185]\n",
            " [ 0.55004507  0.55860418  0.59510185]\n",
            " [ 0.55061809  0.55913722  0.60817557]\n",
            " [ 0.55184827  0.56027639  0.62872997]\n",
            " [ 0.55359598  0.56188938  0.65039623]\n",
            " [ 0.55572157  0.5638439   0.66680553]\n",
            " [ 0.55808541  0.56600764  0.67158908]\n",
            " [ 0.56054785  0.56824831  0.65837804]\n",
            " [ 0.56296924  0.5704336   0.62080362]\n",
            " [ 0.56520995  0.57243121  0.55249699]\n",
            " [ 0.56713033  0.57410884  0.44708934]\n",
            " [ 0.56859511  0.57544625  0.30861372]\n",
            " [ 0.56961566  0.57667202  0.17662318]\n",
            " [ 0.57040614  0.5773856   0.08812085]\n",
            " [ 0.57044345  0.57741934  0.08392462]\n",
            " [ 0.57031141  0.57733422  0.09457798]\n",
            " [ 0.57020701  0.57728254  0.09927008]\n",
            " [ 0.57012913  0.57726283  0.09827373]\n",
            " [ 0.57007663  0.57727358  0.09186173]\n",
            " [ 0.57004836  0.5773133   0.0803069 ]\n",
            " [ 0.5700432   0.57738052  0.06388204]\n",
            " [ 0.57006001  0.57747373  0.04285995]\n",
            " [ 0.57009765  0.57759144  0.01751345]\n",
            " [ 0.57015498  0.57773217 -0.01188467]\n",
            " [ 0.57023088  0.57789442 -0.04506159]\n",
            " [ 0.5703242   0.57807671 -0.08174451]\n",
            " [ 0.5704338   0.57827755 -0.12166062]\n",
            " [ 0.57055856  0.57849543 -0.16453711]\n",
            " [ 0.57069733  0.57872888 -0.21010118]\n",
            " [ 0.57084898  0.5789764  -0.25808002]\n",
            " [ 0.57101237  0.5792365  -0.30820083]\n",
            " [ 0.57118636  0.5795077  -0.36019079]\n",
            " [ 0.57136983  0.57978849 -0.41377711]\n",
            " [ 0.57156163  0.5800774  -0.46868697]\n",
            " [ 0.57176063  0.58037292 -0.52464756]\n",
            " [ 0.57196568  0.58067358 -0.58138609]\n",
            " [ 0.57217567  0.58097787 -0.63862974]\n",
            " [ 0.57238944  0.58128432 -0.69610571]\n",
            " [ 0.57260586  0.58159142 -0.75354119]\n",
            " [ 0.5728238   0.58189769 -0.81066338]\n",
            " [ 0.57304211  0.58220164 -0.86719946]\n",
            " [ 0.57325968  0.58250177 -0.92287663]\n",
            " [ 0.57347534  0.58279661 -0.97742209]\n",
            " [ 0.57368798  0.58308465 -1.03056303]\n",
            " [ 0.57389646  0.5833644  -1.08202663]\n",
            " [ 0.57409963  0.58363438 -1.1315401 ]\n",
            " [ 0.57429636  0.5838931  -1.17883063]\n",
            " [ 0.57448553  0.58413906 -1.22362541]\n",
            " [ 0.57466598  0.58437077 -1.26565163]\n",
            " [ 0.57483658  0.58458675 -1.30463649]\n",
            " [ 0.5749962   0.5847855  -1.34030718]\n",
            " [ 0.5751437   0.58496553 -1.3723909 ]\n",
            " [ 0.57527795  0.58512536 -1.40061483]\n",
            " [ 0.57539781  0.58526349 -1.42470618]\n",
            " [ 0.57550214  0.58537843 -1.44439212]\n",
            " [ 0.5755898   0.58546869 -1.45939987]\n",
            " [ 0.57565966  0.58553279 -1.46945661]\n",
            " [ 0.57571059  0.58556922 -1.47428953]\n",
            " [ 0.57574145  0.5855765  -1.47362583]\n",
            " [ 0.57575109  0.58555314 -1.4671927 ]\n",
            " [ 0.57573839  0.58549765 -1.45471733]\n",
            " [ 0.57570221  0.58540854 -1.43592692]\n",
            " [ 0.57564142  0.58528432 -1.41054866]\n",
            " [ 0.57555487  0.5851235  -1.37830975]\n",
            " [ 0.57544142  0.58492458 -1.33893737]\n",
            " [ 0.57529996  0.58468608 -1.29215873]\n",
            " [ 0.57512933  0.58440651 -1.23770101]\n",
            " [ 0.5749284   0.58408437 -1.1752914 ]]\n",
            "(73, 3)\n",
            "(1, 73, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqrRwCYnCHlw",
        "outputId": "e980f6c9-4eb0-4952-f646-13cdaa42bf96"
      },
      "source": [
        "for j in range(2,16046):\n",
        "    try:\n",
        "        train_input = pd.DataFrame(data = train_df[j], columns = [\"Icao\",\"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "        train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "        train_input = train_input.set_index('Time')\n",
        "        train_input = train_input.drop('PosTime', axis = 1)\n",
        "        unique_species = train_input.Type[0]\n",
        "        norm_train_df = pd.DataFrame()\n",
        "        norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "        norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "        norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "        norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "        norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "        norm_train_df.reset_index(inplace = True)\n",
        "        #norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "        norm_train_df = norm_train_df.iloc[0:73]\n",
        "        norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "        norm_train_df = norm_train_df.to_numpy()\n",
        "        norm_train_df = np.reshape(norm_train_df, (1,73,3))\n",
        "        final_input_train = np.append(final_input_train, norm_train_df, axis = 0)\n",
        "        train_labels.append(unique_species)\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "print(final_input_train.shape)\n",
        "print(len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10376, 73, 3)\n",
            "10376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "St5h1JXSCHlw",
        "outputId": "dddfdca0-b7a5-4a49-f171-16c4444510ae"
      },
      "source": [
        "#convert lists to numpy array\n",
        "final_input_train = np.array(final_input_train)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "#shuffle arrays\n",
        "shuffler = np.random.permutation(len(final_input_train))\n",
        "final_input_train = final_input_train[shuffler]\n",
        "train_labels = train_labels[shuffler]\n",
        "\n",
        "#split into train and test\n",
        "final_input_test = final_input_train[7263:]\n",
        "arr = list(range(7263,final_input_train.shape[0] ))\n",
        "print(final_input_test.shape)\n",
        "\n",
        "final_input_train = np.delete(final_input_train, arr, 0)\n",
        "print(final_input_train.shape)\n",
        "\n",
        "test_labels = train_labels[7263:]\n",
        "print(len(test_labels))\n",
        "\n",
        "train_labels_final = train_labels[:7263]\n",
        "print(len(train_labels_final))\n",
        "\n",
        "unique = list(dict.fromkeys(test_labels))\n",
        "unique2 = list(dict.fromkeys(train_labels_final))\n",
        "print(unique)\n",
        "print(unique2)\n",
        "\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "#test_labels = to_categorical(test_labels,num_classes = 10)\n",
        "#train_labels_final = to_categorical(train_labels_final,num_classes = 10)\n",
        "print(len(test_labels))\n",
        "print(len(train_labels_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3113, 73, 3)\n",
            "(7263, 73, 3)\n",
            "3113\n",
            "7263\n",
            "[9, 8, 0, 2, 1, 4, 7, 5, 3, 6]\n",
            "[0, 9, 3, 2, 1, 8, 5, 6, 4, 7]\n",
            "3113\n",
            "7263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyiNOb_SCHlx"
      },
      "source": [
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sktime.transformations.panel.rocket import Rocket\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07oxoqxDeJ51"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALKPX-rhIt8U"
      },
      "source": [
        "rocket = Rocket()\n",
        "rocket.fit(final_input_train)\n",
        "X_train_transform = rocket.transform(final_input_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaP5vLsMKPca",
        "outputId": "6823fb8c-2d72-4b4e-c0c5-5deeba21add3"
      },
      "source": [
        "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10), normalize= True)\n",
        "classifier.fit(X_train_transform, train_labels_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
              "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
              "       2.15443469e+02, 1.00000000e+03]),\n",
              "                  normalize=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qQ-AdTwKTJD",
        "outputId": "91442a95-11d7-454a-e119-9e878e4bf587"
      },
      "source": [
        "X_test_transform = rocket.transform(final_input_test)\n",
        "classifier.score(X_test_transform, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35721169290073884"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXHZh75NeRdI"
      },
      "source": [
        "rocket = Rocket()\n",
        "rocket.fit(final_input_train)\n",
        "X_train_transform = rocket.transform(final_input_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ6e91UHeXfy",
        "outputId": "02bfc6ee-0355-4bca-fc0b-9035cfabc4c7"
      },
      "source": [
        "classifier = SGDClassifier(loss='log')\n",
        "classifier.fit(X_train_transform, train_labels_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(loss='log')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJUWbAiVehPH",
        "outputId": "11d463f6-868f-432a-cab4-91af28f96b39"
      },
      "source": [
        "X_test_transform = rocket.transform(final_input_test)\n",
        "classifier.score(X_test_transform, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1831031159653068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEVQnpvnjXCn"
      },
      "source": [
        "# Top 50 Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq3-cvfZjXCx",
        "outputId": "0a42018e-0444-44a1-ab30-5088f799ad3e"
      },
      "source": [
        "#remove rows not in the top 16 types\n",
        "train_df = train_df[train_df['Type'].isin(list(Percentages[:50].index))]\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "242       0085A0  0.077821  0.570471  0.577568  1596699295274  SR20\n",
            "243       0085A0  0.078965  0.570457  0.577557  1596699307326  SR20\n",
            "244       0085A0  0.078965  0.570446  0.577549  1596699331462  SR20\n",
            "245       0085A0  0.078965  0.570446  0.577549  1596699336293  SR20\n",
            "246       0085A0  0.078965  0.570446  0.577549  1596699336293  SR20\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "29550390  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550391  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550392  E94C42  0.286107  0.601955  0.314975  1596733965728  B738\n",
            "29550393  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "29550394  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "\n",
            "[21206266 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA0Y00VsjXCy",
        "outputId": "09a6488b-49ae-43a0-9f78-44b2e53f4aa1"
      },
      "source": [
        "type_dict = {k: v for v, k in enumerate(list(Percentages[:50].index))}\n",
        "print(type_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B738': 0, 'A320': 1, 'C172': 2, 'A321': 3, 'B737': 4, 'A319': 5, 'P28A': 6, 'A20N': 7, 'B763': 8, 'B739': 9, 'E75L': 10, 'B752': 11, 'B789': 12, 'B773': 13, 'CRJ9': 14, 'B77L': 15, 'C182': 16, 'PC12': 17, 'E190': 18, 'C208': 19, 'B744': 20, 'A333': 21, 'A21N': 22, 'BE20': 23, 'E170': 24, 'CRJ7': 25, 'A359': 26, 'DA40': 27, 'C152': 28, 'SR22': 29, 'A306': 30, 'CRJ2': 31, 'C56X': 32, 'A332': 33, 'DH8D': 34, 'B748': 35, 'MD11': 36, 'E55P': 37, 'B788': 38, 'B350': 39, 'BE9L': 40, 'AT76': 41, 'TEX2': 42, 'EC35': 43, 'SR20': 44, 'AS50': 45, 'E145': 46, 'B734': 47, 'B77W': 48, 'R44': 49}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrvrPvwzjXC0"
      },
      "source": [
        "train_df['Type'].replace(type_dict, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNX4KmT0jXC1",
        "outputId": "7398fafa-0a5f-458a-ad49-4a836153cd01"
      },
      "source": [
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "0         0085A0  0.077821  0.570471  0.577568  1596699295274    44\n",
            "1         0085A0  0.078965  0.570457  0.577557  1596699307326    44\n",
            "2         0085A0  0.078965  0.570446  0.577549  1596699331462    44\n",
            "3         0085A0  0.078965  0.570446  0.577549  1596699336293    44\n",
            "4         0085A0  0.078965  0.570446  0.577549  1596699336293    44\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "21206261  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "21206262  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "21206263  E94C42  0.286107  0.601955  0.314975  1596733965728     0\n",
            "21206264  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "21206265  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "\n",
            "[21206266 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnhylL4zjXC1",
        "outputId": "0ccd6204-39f8-415b-b222-985e8c42636d"
      },
      "source": [
        "#turn train dataframe into a multi-dimensional numpy array\n",
        "train_df = np.array(list(train_df.groupby('Icao').apply(pd.DataFrame.to_numpy)))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_count = train_df.shape[0]\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(28280,)\n",
            "28280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWizosV_jXC1",
        "outputId": "1aeb304b-f4d1-4a2c-b220-e90706ce6403"
      },
      "source": [
        "#load in first dataframe\n",
        "train_input = pd.DataFrame(data = train_df[0], columns = [\"Icao\", \"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "train_input = train_input.set_index('Time')\n",
        "train_input = train_input.drop('PosTime', axis = 1)\n",
        "train_input = train_input.drop('Icao', axis = 1)\n",
        "print(train_input)\n",
        "#Get Species Type\n",
        "unique_species = train_input.Type[0]\n",
        "print(unique_species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                               Alt       Lat      Long Type\n",
            "Time                                                       \n",
            "2020-08-06 07:34:55.274   0.077821  0.570471  0.577568   44\n",
            "2020-08-06 07:35:07.326  0.0789654  0.570457  0.577557   44\n",
            "2020-08-06 07:35:31.462  0.0789654  0.570446  0.577549   44\n",
            "2020-08-06 07:35:36.293  0.0789654  0.570446  0.577549   44\n",
            "2020-08-06 07:35:36.293  0.0789654  0.570446  0.577549   44\n",
            "...                            ...       ...       ...  ...\n",
            "2020-08-06 15:41:24.882  0.0804913  0.571008  0.577433   44\n",
            "2020-08-06 15:41:24.882  0.0804913  0.571008  0.577433   44\n",
            "2020-08-06 15:48:30.146  0.0793469  0.570518  0.577572   44\n",
            "2020-08-06 15:48:39.992  0.0804913   0.57053  0.577587   44\n",
            "2020-08-06 15:48:39.992  0.0804913   0.57053  0.577587   44\n",
            "\n",
            "[201 rows x 4 columns]\n",
            "44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFQKIHv5jXC2",
        "outputId": "5b6ef215-43a6-4ae0-94ce-68bf63fc1b27"
      },
      "source": [
        "#Resampling/Interpolating\n",
        "norm_train_df = pd.DataFrame()\n",
        "norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "norm_train_df.reset_index(inplace = True)\n",
        "norm_train_df = norm_train_df.iloc[0:73]\n",
        "print(norm_train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Time       Lat      Long       Alt\n",
            "0  2020-08-06 07:30:00  0.570471  0.577568  0.077821\n",
            "1  2020-08-06 07:35:00  0.570446  0.577549  0.078965\n",
            "2  2020-08-06 07:40:00  0.570541  0.577507  0.078202\n",
            "3  2020-08-06 07:45:00  0.570466  0.577541  0.078584\n",
            "4  2020-08-06 07:50:00  0.570452  0.577545  0.078965\n",
            "..                 ...       ...       ...       ...\n",
            "68 2020-08-06 13:10:00  0.572265  0.580598  0.066191\n",
            "69 2020-08-06 13:15:00  0.572310  0.580571  0.065826\n",
            "70 2020-08-06 13:20:00  0.572348  0.580534  0.065575\n",
            "71 2020-08-06 13:25:00  0.572381  0.580485  0.065450\n",
            "72 2020-08-06 13:30:00  0.572406  0.580425  0.065460\n",
            "\n",
            "[73 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT2UzORFjXC2",
        "outputId": "67ac490f-de48-49f4-d28e-bc08f606829c"
      },
      "source": [
        "#add species to label list\n",
        "train_labels = []\n",
        "train_labels.append(unique_species)\n",
        "print(train_labels)\n",
        "#convert dataframe to numpy\n",
        "norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "norm_train_df = norm_train_df.to_numpy()\n",
        "print(norm_train_df)\n",
        "final_input_train = norm_train_df\n",
        "print(final_input_train.shape)\n",
        "final_input_train = np.reshape(final_input_train, (1,73,3))\n",
        "print(final_input_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[44]\n",
            "[[0.57047081 0.57756847 0.07782101]\n",
            " [0.57044649 0.5775491  0.07896544]\n",
            " [0.57054144 0.57750708 0.07820249]\n",
            " [0.5704658  0.57754093 0.07858396]\n",
            " [0.57045233 0.5775454  0.07896544]\n",
            " [0.57048124 0.57752782 0.07858396]\n",
            " [0.57042021 0.57742244 0.07972839]\n",
            " [0.57044011 0.57752955 0.07896544]\n",
            " [0.5704692  0.57754183 0.07934691]\n",
            " [0.57046342 0.57752645 0.07934691]\n",
            " [0.57046199 0.57755584 0.07934691]\n",
            " [0.57044059 0.57754016 0.08010986]\n",
            " [0.57043159 0.57753521 0.08010986]\n",
            " [0.57049078 0.57750815 0.07858396]\n",
            " [0.57055104 0.57747464 0.07706896]\n",
            " [0.57059288 0.57744333 0.07596602]\n",
            " [0.57061848 0.57741485 0.07523251]\n",
            " [0.57062998 0.57738987 0.0748258 ]\n",
            " [0.57062955 0.57736903 0.07470325]\n",
            " [0.57061935 0.57735299 0.07482225]\n",
            " [0.57060153 0.57734239 0.07514015]\n",
            " [0.57057825 0.57733788 0.07561433]\n",
            " [0.57055167 0.57734012 0.07620215]\n",
            " [0.57052396 0.57734976 0.07686099]\n",
            " [0.57049726 0.57736744 0.07754822]\n",
            " [0.57047375 0.57739382 0.0782212 ]\n",
            " [0.57045557 0.57742954 0.07883731]\n",
            " [0.57044489 0.57747527 0.07935392]\n",
            " [0.57044387 0.57753164 0.07972839]\n",
            " [0.57043171 0.57757884 0.08049134]\n",
            " [0.57039893 0.57754618 0.08163577]\n",
            " [0.57051682 0.57751048 0.07820249]\n",
            " [0.57045531 0.57760358 0.07972839]\n",
            " [0.57042158 0.57753563 0.08087282]\n",
            " [0.57032907 0.57741809 0.08087282]\n",
            " [0.57041842 0.57739824 0.08010986]\n",
            " [0.5704363  0.57753056 0.08087282]\n",
            " [0.57042771 0.57769556 0.08192844]\n",
            " [0.57042804 0.5778589  0.08278947]\n",
            " [0.57043681 0.57802031 0.08346561]\n",
            " [0.57045355 0.5781795  0.08396653]\n",
            " [0.57047781 0.57833619 0.08430193]\n",
            " [0.5705091  0.57849011 0.0844815 ]\n",
            " [0.57054698 0.57864097 0.08451493]\n",
            " [0.57059096 0.57878849 0.08441189]\n",
            " [0.57064058 0.57893239 0.08418209]\n",
            " [0.57069538 0.57907239 0.0838352 ]\n",
            " [0.57075488 0.57920821 0.08338093]\n",
            " [0.57081862 0.57933957 0.08282895]\n",
            " [0.57088614 0.57946619 0.08218895]\n",
            " [0.57095697 0.5795878  0.08147063]\n",
            " [0.57103063 0.5797041  0.08068366]\n",
            " [0.57110666 0.57981481 0.07983775]\n",
            " [0.5711846  0.57991967 0.07894258]\n",
            " [0.57126398 0.58001839 0.07800783]\n",
            " [0.57134433 0.58011068 0.07704319]\n",
            " [0.57142518 0.58019627 0.07605836]\n",
            " [0.57150607 0.58027487 0.07506301]\n",
            " [0.57158653 0.58034621 0.07406685]\n",
            " [0.57166609 0.58041001 0.07307955]\n",
            " [0.57174429 0.58046598 0.07211081]\n",
            " [0.57182065 0.58051385 0.07117031]\n",
            " [0.57189472 0.58055333 0.07026775]\n",
            " [0.57196602 0.58058414 0.0694128 ]\n",
            " [0.57203409 0.58060601 0.06861517]\n",
            " [0.57209847 0.58061865 0.06788453]\n",
            " [0.57215867 0.58062179 0.06723058]\n",
            " [0.57221424 0.58061513 0.066663  ]\n",
            " [0.57226471 0.58059841 0.06619148]\n",
            " [0.57230961 0.58057134 0.06582571]\n",
            " [0.57234848 0.58053364 0.06557539]\n",
            " [0.57238085 0.58048504 0.06545018]\n",
            " [0.57240625 0.58042524 0.0654598 ]]\n",
            "(73, 3)\n",
            "(1, 73, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "183FlWy8jXC2",
        "outputId": "882d4591-6ea3-4998-b392-aefe4da10263"
      },
      "source": [
        "for j in range(1,28280):\n",
        "    try:\n",
        "        train_input = pd.DataFrame(data = train_df[j], columns = [\"Icao\",\"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "        train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "        train_input = train_input.set_index('Time')\n",
        "        train_input = train_input.drop('PosTime', axis = 1)\n",
        "        unique_species = train_input.Type[0]\n",
        "        norm_train_df = pd.DataFrame()\n",
        "        norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "        norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "        norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "        norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "        norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "        norm_train_df.reset_index(inplace = True)\n",
        "        norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "        norm_train_df = norm_train_df.iloc[0:73]\n",
        "        norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "        norm_train_df = norm_train_df.to_numpy()\n",
        "        norm_train_df = np.reshape(norm_train_df, (1,73,3))\n",
        "        final_input_train = np.append(final_input_train, norm_train_df, axis = 0)\n",
        "        train_labels.append(unique_species)\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "print(final_input_train.shape)\n",
        "print(len(train_labels))\n",
        "DATA = final_input_train\n",
        "LABELS = train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17018, 73, 3)\n",
            "17018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPy4rLfujXC3",
        "outputId": "7df5c00b-ab2e-41bd-cb08-1cf6c77f6484"
      },
      "source": [
        "final_input_train = DATA\n",
        "train_labels = LABELS\n",
        "final_input_test = final_input_train[11913:]\n",
        "arr = list(range(11913,final_input_train.shape[0] ))\n",
        "#arr = list(range(6000,final_input_train.shape[0] ))\n",
        "print(final_input_test.shape)\n",
        "final_input_train = np.delete(final_input_train, arr, 0)\n",
        "print(final_input_train.shape)\n",
        "test_labels = train_labels[11913:]\n",
        "print(len(test_labels))\n",
        "\n",
        "train_labels_final = train_labels[:11913]\n",
        "#train_labels_final = train_labels[:6000]\n",
        "print(len(train_labels_final))\n",
        "\n",
        "unique = list(dict.fromkeys(test_labels))\n",
        "unique2 = list(dict.fromkeys(train_labels_final))\n",
        "print(unique)\n",
        "print(unique2)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "test_labels = to_categorical(test_labels,num_classes = 50)\n",
        "train_labels_final = to_categorical(train_labels_final,num_classes = 50)\n",
        "print(len(test_labels))\n",
        "print(len(train_labels_final))\n",
        "\n",
        "train_labels_final = np.array(train_labels_final)\n",
        "test_labels = np.array(test_labels)\n",
        "print(train_labels_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5105, 73, 3)\n",
            "(11913, 73, 3)\n",
            "5105\n",
            "11913\n",
            "[2, 25, 0, 1, 5, 32, 40, 29, 43, 6, 49, 36, 16, 3, 28, 45, 17, 19, 27, 7, 23, 8, 22, 9, 11, 44, 39, 14, 4, 37, 20, 31, 46, 10, 35, 24, 47, 30, 15, 41, 48, 34, 38, 21, 12, 33, 42, 13, 18, 26]\n",
            "[44, 0, 18, 39, 1, 17, 33, 13, 5, 12, 14, 7, 4, 38, 15, 26, 47, 34, 19, 3, 48, 35, 40, 6, 11, 41, 32, 46, 37, 30, 31, 27, 2, 21, 28, 23, 43, 16, 24, 45, 29, 22, 36, 49, 8, 20, 9, 42, 10, 25]\n",
            "5105\n",
            "11913\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92oLrThXjXC3",
        "outputId": "03758639-2d02-47b3-dc10-e158dff1352f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "import keras\n",
        "# fit and evaluate a model\n",
        "verbose, epochs, batch_size = 2, 300, 128\n",
        "n_timesteps, n_features, n_outputs = final_input_train.shape[1], final_input_train.shape[2], 50\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "# fit network\n",
        "history =  model.fit(final_input_train, train_labels_final, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle = True)\n",
        "# evaluate model\n",
        "_, accuracy = model.evaluate(final_input_test, test_labels, batch_size=batch_size, verbose=0)\n",
        "print(accuracy *100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "94/94 - 6s - loss: 3.6381 - accuracy: 0.1749\n",
            "Epoch 2/300\n",
            "94/94 - 5s - loss: 3.1542 - accuracy: 0.2329\n",
            "Epoch 3/300\n",
            "94/94 - 5s - loss: 3.0602 - accuracy: 0.2373\n",
            "Epoch 4/300\n",
            "94/94 - 5s - loss: 2.9598 - accuracy: 0.2421\n",
            "Epoch 5/300\n",
            "94/94 - 5s - loss: 2.9557 - accuracy: 0.2413\n",
            "Epoch 6/300\n",
            "94/94 - 5s - loss: 2.8695 - accuracy: 0.2464\n",
            "Epoch 7/300\n",
            "94/94 - 5s - loss: 2.8435 - accuracy: 0.2462\n",
            "Epoch 8/300\n",
            "94/94 - 5s - loss: 2.7911 - accuracy: 0.2515\n",
            "Epoch 9/300\n",
            "94/94 - 5s - loss: 2.7788 - accuracy: 0.2569\n",
            "Epoch 10/300\n",
            "94/94 - 5s - loss: 2.7319 - accuracy: 0.2567\n",
            "Epoch 11/300\n",
            "94/94 - 5s - loss: 2.6963 - accuracy: 0.2590\n",
            "Epoch 12/300\n",
            "94/94 - 5s - loss: 2.6745 - accuracy: 0.2664\n",
            "Epoch 13/300\n",
            "94/94 - 5s - loss: 2.6642 - accuracy: 0.2637\n",
            "Epoch 14/300\n",
            "94/94 - 5s - loss: 2.6420 - accuracy: 0.2705\n",
            "Epoch 15/300\n",
            "94/94 - 5s - loss: 2.6447 - accuracy: 0.2701\n",
            "Epoch 16/300\n",
            "94/94 - 5s - loss: 2.6223 - accuracy: 0.2727\n",
            "Epoch 17/300\n",
            "94/94 - 5s - loss: 2.6071 - accuracy: 0.2726\n",
            "Epoch 18/300\n",
            "94/94 - 5s - loss: 2.5924 - accuracy: 0.2720\n",
            "Epoch 19/300\n",
            "94/94 - 5s - loss: 2.5937 - accuracy: 0.2718\n",
            "Epoch 20/300\n",
            "94/94 - 5s - loss: 2.5774 - accuracy: 0.2746\n",
            "Epoch 21/300\n",
            "94/94 - 5s - loss: 2.5776 - accuracy: 0.2756\n",
            "Epoch 22/300\n",
            "94/94 - 5s - loss: 2.5578 - accuracy: 0.2786\n",
            "Epoch 23/300\n",
            "94/94 - 5s - loss: 2.5465 - accuracy: 0.2794\n",
            "Epoch 24/300\n",
            "94/94 - 5s - loss: 2.5421 - accuracy: 0.2816\n",
            "Epoch 25/300\n",
            "94/94 - 5s - loss: 2.5450 - accuracy: 0.2798\n",
            "Epoch 26/300\n",
            "94/94 - 5s - loss: 2.5257 - accuracy: 0.2839\n",
            "Epoch 27/300\n",
            "94/94 - 5s - loss: 2.5246 - accuracy: 0.2832\n",
            "Epoch 28/300\n",
            "94/94 - 5s - loss: 2.5303 - accuracy: 0.2820\n",
            "Epoch 29/300\n",
            "94/94 - 5s - loss: 2.5229 - accuracy: 0.2824\n",
            "Epoch 30/300\n",
            "94/94 - 5s - loss: 2.5050 - accuracy: 0.2849\n",
            "Epoch 31/300\n",
            "94/94 - 5s - loss: 2.4946 - accuracy: 0.2914\n",
            "Epoch 32/300\n",
            "94/94 - 5s - loss: 2.4891 - accuracy: 0.2845\n",
            "Epoch 33/300\n",
            "94/94 - 5s - loss: 2.4886 - accuracy: 0.2871\n",
            "Epoch 34/300\n",
            "94/94 - 5s - loss: 2.4853 - accuracy: 0.2901\n",
            "Epoch 35/300\n",
            "94/94 - 5s - loss: 2.4718 - accuracy: 0.2851\n",
            "Epoch 36/300\n",
            "94/94 - 5s - loss: 2.4784 - accuracy: 0.2882\n",
            "Epoch 37/300\n",
            "94/94 - 5s - loss: 2.4696 - accuracy: 0.2908\n",
            "Epoch 38/300\n",
            "94/94 - 5s - loss: 2.4595 - accuracy: 0.2883\n",
            "Epoch 39/300\n",
            "94/94 - 5s - loss: 2.4537 - accuracy: 0.2867\n",
            "Epoch 40/300\n",
            "94/94 - 5s - loss: 2.4466 - accuracy: 0.2900\n",
            "Epoch 41/300\n",
            "94/94 - 5s - loss: 2.4425 - accuracy: 0.2906\n",
            "Epoch 42/300\n",
            "94/94 - 5s - loss: 2.4324 - accuracy: 0.2940\n",
            "Epoch 43/300\n",
            "94/94 - 5s - loss: 2.4287 - accuracy: 0.2959\n",
            "Epoch 44/300\n",
            "94/94 - 5s - loss: 2.4286 - accuracy: 0.2943\n",
            "Epoch 45/300\n",
            "94/94 - 5s - loss: 2.4452 - accuracy: 0.2976\n",
            "Epoch 46/300\n",
            "94/94 - 5s - loss: 2.4152 - accuracy: 0.2940\n",
            "Epoch 47/300\n",
            "94/94 - 5s - loss: 2.4116 - accuracy: 0.2984\n",
            "Epoch 48/300\n",
            "94/94 - 5s - loss: 2.4059 - accuracy: 0.2977\n",
            "Epoch 49/300\n",
            "94/94 - 5s - loss: 2.4011 - accuracy: 0.3011\n",
            "Epoch 50/300\n",
            "94/94 - 5s - loss: 2.3918 - accuracy: 0.2981\n",
            "Epoch 51/300\n",
            "94/94 - 5s - loss: 2.3847 - accuracy: 0.3019\n",
            "Epoch 52/300\n",
            "94/94 - 5s - loss: 2.3798 - accuracy: 0.3008\n",
            "Epoch 53/300\n",
            "94/94 - 5s - loss: 2.3768 - accuracy: 0.3050\n",
            "Epoch 54/300\n",
            "94/94 - 5s - loss: 2.3752 - accuracy: 0.2996\n",
            "Epoch 55/300\n",
            "94/94 - 5s - loss: 2.3659 - accuracy: 0.3033\n",
            "Epoch 56/300\n",
            "94/94 - 5s - loss: 2.3543 - accuracy: 0.3056\n",
            "Epoch 57/300\n",
            "94/94 - 5s - loss: 2.3548 - accuracy: 0.3067\n",
            "Epoch 58/300\n",
            "94/94 - 5s - loss: 2.3448 - accuracy: 0.3079\n",
            "Epoch 59/300\n",
            "94/94 - 5s - loss: 2.3503 - accuracy: 0.3034\n",
            "Epoch 60/300\n",
            "94/94 - 5s - loss: 2.3457 - accuracy: 0.3082\n",
            "Epoch 61/300\n",
            "94/94 - 5s - loss: 2.3332 - accuracy: 0.3111\n",
            "Epoch 62/300\n",
            "94/94 - 5s - loss: 2.3391 - accuracy: 0.3107\n",
            "Epoch 63/300\n",
            "94/94 - 5s - loss: 2.3242 - accuracy: 0.3147\n",
            "Epoch 64/300\n",
            "94/94 - 5s - loss: 2.3178 - accuracy: 0.3108\n",
            "Epoch 65/300\n",
            "94/94 - 5s - loss: 2.3148 - accuracy: 0.3072\n",
            "Epoch 66/300\n",
            "94/94 - 5s - loss: 2.3113 - accuracy: 0.3134\n",
            "Epoch 67/300\n",
            "94/94 - 5s - loss: 2.3062 - accuracy: 0.3132\n",
            "Epoch 68/300\n",
            "94/94 - 5s - loss: 2.3086 - accuracy: 0.3156\n",
            "Epoch 69/300\n",
            "94/94 - 5s - loss: 2.3000 - accuracy: 0.3162\n",
            "Epoch 70/300\n",
            "94/94 - 5s - loss: 2.2897 - accuracy: 0.3205\n",
            "Epoch 71/300\n",
            "94/94 - 5s - loss: 2.3060 - accuracy: 0.3183\n",
            "Epoch 72/300\n",
            "94/94 - 5s - loss: 2.2857 - accuracy: 0.3202\n",
            "Epoch 73/300\n",
            "94/94 - 5s - loss: 2.2753 - accuracy: 0.3202\n",
            "Epoch 74/300\n",
            "94/94 - 5s - loss: 2.2761 - accuracy: 0.3203\n",
            "Epoch 75/300\n",
            "94/94 - 5s - loss: 2.2682 - accuracy: 0.3221\n",
            "Epoch 76/300\n",
            "94/94 - 5s - loss: 2.2629 - accuracy: 0.3259\n",
            "Epoch 77/300\n",
            "94/94 - 5s - loss: 2.2599 - accuracy: 0.3226\n",
            "Epoch 78/300\n",
            "94/94 - 5s - loss: 2.2584 - accuracy: 0.3259\n",
            "Epoch 79/300\n",
            "94/94 - 5s - loss: 2.2486 - accuracy: 0.3249\n",
            "Epoch 80/300\n",
            "94/94 - 5s - loss: 2.2453 - accuracy: 0.3223\n",
            "Epoch 81/300\n",
            "94/94 - 5s - loss: 2.2380 - accuracy: 0.3279\n",
            "Epoch 82/300\n",
            "94/94 - 5s - loss: 2.2337 - accuracy: 0.3270\n",
            "Epoch 83/300\n",
            "94/94 - 5s - loss: 2.2326 - accuracy: 0.3283\n",
            "Epoch 84/300\n",
            "94/94 - 5s - loss: 2.2316 - accuracy: 0.3315\n",
            "Epoch 85/300\n",
            "94/94 - 5s - loss: 2.2299 - accuracy: 0.3334\n",
            "Epoch 86/300\n",
            "94/94 - 5s - loss: 2.2231 - accuracy: 0.3312\n",
            "Epoch 87/300\n",
            "94/94 - 5s - loss: 2.2157 - accuracy: 0.3322\n",
            "Epoch 88/300\n",
            "94/94 - 5s - loss: 2.2114 - accuracy: 0.3311\n",
            "Epoch 89/300\n",
            "94/94 - 5s - loss: 2.2137 - accuracy: 0.3365\n",
            "Epoch 90/300\n",
            "94/94 - 5s - loss: 2.2071 - accuracy: 0.3379\n",
            "Epoch 91/300\n",
            "94/94 - 5s - loss: 2.2067 - accuracy: 0.3349\n",
            "Epoch 92/300\n",
            "94/94 - 5s - loss: 2.2014 - accuracy: 0.3335\n",
            "Epoch 93/300\n",
            "94/94 - 5s - loss: 2.1927 - accuracy: 0.3370\n",
            "Epoch 94/300\n",
            "94/94 - 5s - loss: 2.1877 - accuracy: 0.3368\n",
            "Epoch 95/300\n",
            "94/94 - 5s - loss: 2.1838 - accuracy: 0.3374\n",
            "Epoch 96/300\n",
            "94/94 - 5s - loss: 2.1827 - accuracy: 0.3398\n",
            "Epoch 97/300\n",
            "94/94 - 5s - loss: 2.1817 - accuracy: 0.3387\n",
            "Epoch 98/300\n",
            "94/94 - 5s - loss: 2.1816 - accuracy: 0.3383\n",
            "Epoch 99/300\n",
            "94/94 - 5s - loss: 2.1751 - accuracy: 0.3406\n",
            "Epoch 100/300\n",
            "94/94 - 5s - loss: 2.1671 - accuracy: 0.3377\n",
            "Epoch 101/300\n",
            "94/94 - 5s - loss: 2.1610 - accuracy: 0.3444\n",
            "Epoch 102/300\n",
            "94/94 - 5s - loss: 2.1561 - accuracy: 0.3443\n",
            "Epoch 103/300\n",
            "94/94 - 5s - loss: 2.1521 - accuracy: 0.3432\n",
            "Epoch 104/300\n",
            "94/94 - 5s - loss: 2.1518 - accuracy: 0.3490\n",
            "Epoch 105/300\n",
            "94/94 - 5s - loss: 2.1461 - accuracy: 0.3458\n",
            "Epoch 106/300\n",
            "94/94 - 5s - loss: 2.1429 - accuracy: 0.3490\n",
            "Epoch 107/300\n",
            "94/94 - 5s - loss: 2.1413 - accuracy: 0.3463\n",
            "Epoch 108/300\n",
            "94/94 - 5s - loss: 2.1299 - accuracy: 0.3546\n",
            "Epoch 109/300\n",
            "94/94 - 5s - loss: 2.1301 - accuracy: 0.3518\n",
            "Epoch 110/300\n",
            "94/94 - 5s - loss: 2.1220 - accuracy: 0.3543\n",
            "Epoch 111/300\n",
            "94/94 - 5s - loss: 2.1187 - accuracy: 0.3544\n",
            "Epoch 112/300\n",
            "94/94 - 5s - loss: 2.1190 - accuracy: 0.3514\n",
            "Epoch 113/300\n",
            "94/94 - 5s - loss: 2.1229 - accuracy: 0.3470\n",
            "Epoch 114/300\n",
            "94/94 - 5s - loss: 2.1133 - accuracy: 0.3556\n",
            "Epoch 115/300\n",
            "94/94 - 5s - loss: 2.1143 - accuracy: 0.3544\n",
            "Epoch 116/300\n",
            "94/94 - 5s - loss: 2.1176 - accuracy: 0.3547\n",
            "Epoch 117/300\n",
            "94/94 - 5s - loss: 2.1157 - accuracy: 0.3558\n",
            "Epoch 118/300\n",
            "94/94 - 5s - loss: 2.1057 - accuracy: 0.3554\n",
            "Epoch 119/300\n",
            "94/94 - 5s - loss: 2.0975 - accuracy: 0.3583\n",
            "Epoch 120/300\n",
            "94/94 - 5s - loss: 2.0870 - accuracy: 0.3576\n",
            "Epoch 121/300\n",
            "94/94 - 5s - loss: 2.0863 - accuracy: 0.3606\n",
            "Epoch 122/300\n",
            "94/94 - 5s - loss: 2.0782 - accuracy: 0.3637\n",
            "Epoch 123/300\n",
            "94/94 - 5s - loss: 2.0817 - accuracy: 0.3637\n",
            "Epoch 124/300\n",
            "94/94 - 5s - loss: 2.0723 - accuracy: 0.3651\n",
            "Epoch 125/300\n",
            "94/94 - 5s - loss: 2.0713 - accuracy: 0.3611\n",
            "Epoch 126/300\n",
            "94/94 - 5s - loss: 2.0633 - accuracy: 0.3673\n",
            "Epoch 127/300\n",
            "94/94 - 5s - loss: 2.0635 - accuracy: 0.3605\n",
            "Epoch 128/300\n",
            "94/94 - 5s - loss: 2.0598 - accuracy: 0.3643\n",
            "Epoch 129/300\n",
            "94/94 - 5s - loss: 2.0569 - accuracy: 0.3687\n",
            "Epoch 130/300\n",
            "94/94 - 5s - loss: 2.0583 - accuracy: 0.3646\n",
            "Epoch 131/300\n",
            "94/94 - 5s - loss: 2.0519 - accuracy: 0.3684\n",
            "Epoch 132/300\n",
            "94/94 - 5s - loss: 2.0480 - accuracy: 0.3682\n",
            "Epoch 133/300\n",
            "94/94 - 5s - loss: 2.0414 - accuracy: 0.3709\n",
            "Epoch 134/300\n",
            "94/94 - 5s - loss: 2.0339 - accuracy: 0.3716\n",
            "Epoch 135/300\n",
            "94/94 - 5s - loss: 2.0380 - accuracy: 0.3728\n",
            "Epoch 136/300\n",
            "94/94 - 5s - loss: 2.0314 - accuracy: 0.3719\n",
            "Epoch 137/300\n",
            "94/94 - 5s - loss: 2.0308 - accuracy: 0.3737\n",
            "Epoch 138/300\n",
            "94/94 - 5s - loss: 2.0333 - accuracy: 0.3689\n",
            "Epoch 139/300\n",
            "94/94 - 5s - loss: 2.0161 - accuracy: 0.3775\n",
            "Epoch 140/300\n",
            "94/94 - 5s - loss: 2.0160 - accuracy: 0.3751\n",
            "Epoch 141/300\n",
            "94/94 - 5s - loss: 2.0177 - accuracy: 0.3792\n",
            "Epoch 142/300\n",
            "94/94 - 5s - loss: 2.0061 - accuracy: 0.3782\n",
            "Epoch 143/300\n",
            "94/94 - 5s - loss: 1.9998 - accuracy: 0.3834\n",
            "Epoch 144/300\n",
            "94/94 - 5s - loss: 2.0007 - accuracy: 0.3786\n",
            "Epoch 145/300\n",
            "94/94 - 5s - loss: 1.9993 - accuracy: 0.3809\n",
            "Epoch 146/300\n",
            "94/94 - 5s - loss: 2.0020 - accuracy: 0.3782\n",
            "Epoch 147/300\n",
            "94/94 - 5s - loss: 1.9943 - accuracy: 0.3821\n",
            "Epoch 148/300\n",
            "94/94 - 5s - loss: 1.9979 - accuracy: 0.3819\n",
            "Epoch 149/300\n",
            "94/94 - 5s - loss: 1.9835 - accuracy: 0.3819\n",
            "Epoch 150/300\n",
            "94/94 - 5s - loss: 1.9908 - accuracy: 0.3818\n",
            "Epoch 151/300\n",
            "94/94 - 5s - loss: 1.9738 - accuracy: 0.3871\n",
            "Epoch 152/300\n",
            "94/94 - 5s - loss: 1.9813 - accuracy: 0.3822\n",
            "Epoch 153/300\n",
            "94/94 - 5s - loss: 1.9730 - accuracy: 0.3922\n",
            "Epoch 154/300\n",
            "94/94 - 5s - loss: 1.9747 - accuracy: 0.3847\n",
            "Epoch 155/300\n",
            "94/94 - 5s - loss: 1.9684 - accuracy: 0.3894\n",
            "Epoch 156/300\n",
            "94/94 - 5s - loss: 1.9732 - accuracy: 0.3881\n",
            "Epoch 157/300\n",
            "94/94 - 5s - loss: 1.9660 - accuracy: 0.3895\n",
            "Epoch 158/300\n",
            "94/94 - 5s - loss: 1.9487 - accuracy: 0.3971\n",
            "Epoch 159/300\n",
            "94/94 - 5s - loss: 1.9590 - accuracy: 0.3856\n",
            "Epoch 160/300\n",
            "94/94 - 5s - loss: 1.9562 - accuracy: 0.3905\n",
            "Epoch 161/300\n",
            "94/94 - 5s - loss: 1.9395 - accuracy: 0.3952\n",
            "Epoch 162/300\n",
            "94/94 - 5s - loss: 1.9452 - accuracy: 0.3939\n",
            "Epoch 163/300\n",
            "94/94 - 5s - loss: 1.9388 - accuracy: 0.3917\n",
            "Epoch 164/300\n",
            "94/94 - 5s - loss: 1.9386 - accuracy: 0.3939\n",
            "Epoch 165/300\n",
            "94/94 - 5s - loss: 1.9358 - accuracy: 0.3911\n",
            "Epoch 166/300\n",
            "94/94 - 5s - loss: 1.9288 - accuracy: 0.3980\n",
            "Epoch 167/300\n",
            "94/94 - 5s - loss: 1.9290 - accuracy: 0.3963\n",
            "Epoch 168/300\n",
            "94/94 - 5s - loss: 1.9182 - accuracy: 0.3986\n",
            "Epoch 169/300\n",
            "94/94 - 5s - loss: 1.9220 - accuracy: 0.3993\n",
            "Epoch 170/300\n",
            "94/94 - 5s - loss: 1.9231 - accuracy: 0.4010\n",
            "Epoch 171/300\n",
            "94/94 - 5s - loss: 1.9083 - accuracy: 0.4022\n",
            "Epoch 172/300\n",
            "94/94 - 5s - loss: 1.9135 - accuracy: 0.4005\n",
            "Epoch 173/300\n",
            "94/94 - 5s - loss: 1.9066 - accuracy: 0.4020\n",
            "Epoch 174/300\n",
            "94/94 - 5s - loss: 1.9091 - accuracy: 0.3998\n",
            "Epoch 175/300\n",
            "94/94 - 5s - loss: 1.9058 - accuracy: 0.4011\n",
            "Epoch 176/300\n",
            "94/94 - 5s - loss: 1.9011 - accuracy: 0.4021\n",
            "Epoch 177/300\n",
            "94/94 - 5s - loss: 1.8939 - accuracy: 0.4109\n",
            "Epoch 178/300\n",
            "94/94 - 5s - loss: 1.8855 - accuracy: 0.4064\n",
            "Epoch 179/300\n",
            "94/94 - 5s - loss: 1.8831 - accuracy: 0.4122\n",
            "Epoch 180/300\n",
            "94/94 - 5s - loss: 1.8890 - accuracy: 0.4107\n",
            "Epoch 181/300\n",
            "94/94 - 5s - loss: 1.8774 - accuracy: 0.4104\n",
            "Epoch 182/300\n",
            "94/94 - 5s - loss: 1.8823 - accuracy: 0.4033\n",
            "Epoch 183/300\n",
            "94/94 - 5s - loss: 1.8714 - accuracy: 0.4092\n",
            "Epoch 184/300\n",
            "94/94 - 5s - loss: 1.8775 - accuracy: 0.4081\n",
            "Epoch 185/300\n",
            "94/94 - 5s - loss: 1.8729 - accuracy: 0.4105\n",
            "Epoch 186/300\n",
            "94/94 - 5s - loss: 1.8693 - accuracy: 0.4111\n",
            "Epoch 187/300\n",
            "94/94 - 5s - loss: 1.8704 - accuracy: 0.4084\n",
            "Epoch 188/300\n",
            "94/94 - 5s - loss: 1.8598 - accuracy: 0.4148\n",
            "Epoch 189/300\n",
            "94/94 - 5s - loss: 1.8571 - accuracy: 0.4132\n",
            "Epoch 190/300\n",
            "94/94 - 5s - loss: 1.8552 - accuracy: 0.4162\n",
            "Epoch 191/300\n",
            "94/94 - 5s - loss: 1.8633 - accuracy: 0.4178\n",
            "Epoch 192/300\n",
            "94/94 - 5s - loss: 1.8549 - accuracy: 0.4237\n",
            "Epoch 193/300\n",
            "94/94 - 5s - loss: 1.8479 - accuracy: 0.4167\n",
            "Epoch 194/300\n",
            "94/94 - 5s - loss: 1.8493 - accuracy: 0.4174\n",
            "Epoch 195/300\n",
            "94/94 - 5s - loss: 1.8495 - accuracy: 0.4123\n",
            "Epoch 196/300\n",
            "94/94 - 5s - loss: 1.8443 - accuracy: 0.4169\n",
            "Epoch 197/300\n",
            "94/94 - 5s - loss: 1.8405 - accuracy: 0.4154\n",
            "Epoch 198/300\n",
            "94/94 - 5s - loss: 1.8375 - accuracy: 0.4188\n",
            "Epoch 199/300\n",
            "94/94 - 5s - loss: 1.8292 - accuracy: 0.4227\n",
            "Epoch 200/300\n",
            "94/94 - 5s - loss: 1.8318 - accuracy: 0.4126\n",
            "Epoch 201/300\n",
            "94/94 - 5s - loss: 1.8256 - accuracy: 0.4268\n",
            "Epoch 202/300\n",
            "94/94 - 5s - loss: 1.8195 - accuracy: 0.4258\n",
            "Epoch 203/300\n",
            "94/94 - 5s - loss: 1.8192 - accuracy: 0.4252\n",
            "Epoch 204/300\n",
            "94/94 - 5s - loss: 1.8159 - accuracy: 0.4284\n",
            "Epoch 205/300\n",
            "94/94 - 5s - loss: 1.8107 - accuracy: 0.4252\n",
            "Epoch 206/300\n",
            "94/94 - 5s - loss: 1.8111 - accuracy: 0.4217\n",
            "Epoch 207/300\n",
            "94/94 - 5s - loss: 1.8017 - accuracy: 0.4305\n",
            "Epoch 208/300\n",
            "94/94 - 5s - loss: 1.8029 - accuracy: 0.4262\n",
            "Epoch 209/300\n",
            "94/94 - 5s - loss: 1.8021 - accuracy: 0.4290\n",
            "Epoch 210/300\n",
            "94/94 - 5s - loss: 1.7971 - accuracy: 0.4307\n",
            "Epoch 211/300\n",
            "94/94 - 5s - loss: 1.8062 - accuracy: 0.4295\n",
            "Epoch 212/300\n",
            "94/94 - 5s - loss: 1.7899 - accuracy: 0.4333\n",
            "Epoch 213/300\n",
            "94/94 - 5s - loss: 1.7919 - accuracy: 0.4328\n",
            "Epoch 214/300\n",
            "94/94 - 5s - loss: 1.7907 - accuracy: 0.4320\n",
            "Epoch 215/300\n",
            "94/94 - 5s - loss: 1.7810 - accuracy: 0.4352\n",
            "Epoch 216/300\n",
            "94/94 - 5s - loss: 1.7862 - accuracy: 0.4324\n",
            "Epoch 217/300\n",
            "94/94 - 5s - loss: 1.7838 - accuracy: 0.4355\n",
            "Epoch 218/300\n",
            "94/94 - 5s - loss: 1.7761 - accuracy: 0.4349\n",
            "Epoch 219/300\n",
            "94/94 - 5s - loss: 1.7825 - accuracy: 0.4380\n",
            "Epoch 220/300\n",
            "94/94 - 5s - loss: 1.7779 - accuracy: 0.4339\n",
            "Epoch 221/300\n",
            "94/94 - 5s - loss: 1.7679 - accuracy: 0.4410\n",
            "Epoch 222/300\n",
            "94/94 - 5s - loss: 1.7630 - accuracy: 0.4416\n",
            "Epoch 223/300\n",
            "94/94 - 5s - loss: 1.7624 - accuracy: 0.4417\n",
            "Epoch 224/300\n",
            "94/94 - 5s - loss: 1.7636 - accuracy: 0.4384\n",
            "Epoch 225/300\n",
            "94/94 - 5s - loss: 1.7696 - accuracy: 0.4347\n",
            "Epoch 226/300\n",
            "94/94 - 5s - loss: 1.7554 - accuracy: 0.4466\n",
            "Epoch 227/300\n",
            "94/94 - 5s - loss: 1.7529 - accuracy: 0.4397\n",
            "Epoch 228/300\n",
            "94/94 - 5s - loss: 1.7561 - accuracy: 0.4453\n",
            "Epoch 229/300\n",
            "94/94 - 5s - loss: 1.7503 - accuracy: 0.4438\n",
            "Epoch 230/300\n",
            "94/94 - 5s - loss: 1.7476 - accuracy: 0.4432\n",
            "Epoch 231/300\n",
            "94/94 - 5s - loss: 1.7503 - accuracy: 0.4447\n",
            "Epoch 232/300\n",
            "94/94 - 5s - loss: 1.7408 - accuracy: 0.4413\n",
            "Epoch 233/300\n",
            "94/94 - 5s - loss: 1.7315 - accuracy: 0.4482\n",
            "Epoch 234/300\n",
            "94/94 - 5s - loss: 1.7337 - accuracy: 0.4507\n",
            "Epoch 235/300\n",
            "94/94 - 5s - loss: 1.7326 - accuracy: 0.4456\n",
            "Epoch 236/300\n",
            "94/94 - 5s - loss: 1.7334 - accuracy: 0.4480\n",
            "Epoch 237/300\n",
            "94/94 - 5s - loss: 1.7444 - accuracy: 0.4395\n",
            "Epoch 238/300\n",
            "94/94 - 5s - loss: 1.7367 - accuracy: 0.4483\n",
            "Epoch 239/300\n",
            "94/94 - 5s - loss: 1.7264 - accuracy: 0.4477\n",
            "Epoch 240/300\n",
            "94/94 - 5s - loss: 1.7305 - accuracy: 0.4509\n",
            "Epoch 241/300\n",
            "94/94 - 5s - loss: 1.7202 - accuracy: 0.4482\n",
            "Epoch 242/300\n",
            "94/94 - 5s - loss: 1.7166 - accuracy: 0.4495\n",
            "Epoch 243/300\n",
            "94/94 - 5s - loss: 1.7058 - accuracy: 0.4545\n",
            "Epoch 244/300\n",
            "94/94 - 5s - loss: 1.7136 - accuracy: 0.4541\n",
            "Epoch 245/300\n",
            "94/94 - 5s - loss: 1.7111 - accuracy: 0.4463\n",
            "Epoch 246/300\n",
            "94/94 - 5s - loss: 1.7107 - accuracy: 0.4523\n",
            "Epoch 247/300\n",
            "94/94 - 5s - loss: 1.7009 - accuracy: 0.4561\n",
            "Epoch 248/300\n",
            "94/94 - 5s - loss: 1.7009 - accuracy: 0.4544\n",
            "Epoch 249/300\n",
            "94/94 - 5s - loss: 1.7105 - accuracy: 0.4558\n",
            "Epoch 250/300\n",
            "94/94 - 5s - loss: 1.7032 - accuracy: 0.4566\n",
            "Epoch 251/300\n",
            "94/94 - 5s - loss: 1.6903 - accuracy: 0.4564\n",
            "Epoch 252/300\n",
            "94/94 - 5s - loss: 1.6922 - accuracy: 0.4549\n",
            "Epoch 253/300\n",
            "94/94 - 5s - loss: 1.6816 - accuracy: 0.4606\n",
            "Epoch 254/300\n",
            "94/94 - 5s - loss: 1.6792 - accuracy: 0.4647\n",
            "Epoch 255/300\n",
            "94/94 - 5s - loss: 1.6938 - accuracy: 0.4539\n",
            "Epoch 256/300\n",
            "94/94 - 5s - loss: 1.6805 - accuracy: 0.4655\n",
            "Epoch 257/300\n",
            "94/94 - 5s - loss: 1.6835 - accuracy: 0.4587\n",
            "Epoch 258/300\n",
            "94/94 - 5s - loss: 1.6692 - accuracy: 0.4665\n",
            "Epoch 259/300\n",
            "94/94 - 5s - loss: 1.6674 - accuracy: 0.4681\n",
            "Epoch 260/300\n",
            "94/94 - 5s - loss: 1.6653 - accuracy: 0.4660\n",
            "Epoch 261/300\n",
            "94/94 - 5s - loss: 1.6762 - accuracy: 0.4639\n",
            "Epoch 262/300\n",
            "94/94 - 5s - loss: 1.6668 - accuracy: 0.4632\n",
            "Epoch 263/300\n",
            "94/94 - 5s - loss: 1.6621 - accuracy: 0.4687\n",
            "Epoch 264/300\n",
            "94/94 - 5s - loss: 1.6600 - accuracy: 0.4659\n",
            "Epoch 265/300\n",
            "94/94 - 5s - loss: 1.6722 - accuracy: 0.4617\n",
            "Epoch 266/300\n",
            "94/94 - 5s - loss: 1.6588 - accuracy: 0.4697\n",
            "Epoch 267/300\n",
            "94/94 - 5s - loss: 1.6507 - accuracy: 0.4689\n",
            "Epoch 268/300\n",
            "94/94 - 5s - loss: 1.6529 - accuracy: 0.4709\n",
            "Epoch 269/300\n",
            "94/94 - 5s - loss: 1.6441 - accuracy: 0.4747\n",
            "Epoch 270/300\n",
            "94/94 - 5s - loss: 1.6475 - accuracy: 0.4723\n",
            "Epoch 271/300\n",
            "94/94 - 5s - loss: 1.6485 - accuracy: 0.4697\n",
            "Epoch 272/300\n",
            "94/94 - 5s - loss: 1.6483 - accuracy: 0.4649\n",
            "Epoch 273/300\n",
            "94/94 - 5s - loss: 1.6450 - accuracy: 0.4720\n",
            "Epoch 274/300\n",
            "94/94 - 5s - loss: 1.6307 - accuracy: 0.4724\n",
            "Epoch 275/300\n",
            "94/94 - 5s - loss: 1.6316 - accuracy: 0.4740\n",
            "Epoch 276/300\n",
            "94/94 - 5s - loss: 1.6396 - accuracy: 0.4728\n",
            "Epoch 277/300\n",
            "94/94 - 5s - loss: 1.6293 - accuracy: 0.4717\n",
            "Epoch 278/300\n",
            "94/94 - 5s - loss: 1.6249 - accuracy: 0.4744\n",
            "Epoch 279/300\n",
            "94/94 - 5s - loss: 1.6268 - accuracy: 0.4750\n",
            "Epoch 280/300\n",
            "94/94 - 5s - loss: 1.6231 - accuracy: 0.4753\n",
            "Epoch 281/300\n",
            "94/94 - 5s - loss: 1.6280 - accuracy: 0.4754\n",
            "Epoch 282/300\n",
            "94/94 - 5s - loss: 1.6211 - accuracy: 0.4833\n",
            "Epoch 283/300\n",
            "94/94 - 5s - loss: 1.6189 - accuracy: 0.4761\n",
            "Epoch 284/300\n",
            "94/94 - 5s - loss: 1.6180 - accuracy: 0.4792\n",
            "Epoch 285/300\n",
            "94/94 - 5s - loss: 1.6106 - accuracy: 0.4768\n",
            "Epoch 286/300\n",
            "94/94 - 5s - loss: 1.6113 - accuracy: 0.4793\n",
            "Epoch 287/300\n",
            "94/94 - 5s - loss: 1.6101 - accuracy: 0.4831\n",
            "Epoch 288/300\n",
            "94/94 - 5s - loss: 1.6051 - accuracy: 0.4792\n",
            "Epoch 289/300\n",
            "94/94 - 5s - loss: 1.6020 - accuracy: 0.4811\n",
            "Epoch 290/300\n",
            "94/94 - 5s - loss: 1.6055 - accuracy: 0.4827\n",
            "Epoch 291/300\n",
            "94/94 - 5s - loss: 1.6012 - accuracy: 0.4812\n",
            "Epoch 292/300\n",
            "94/94 - 5s - loss: 1.6005 - accuracy: 0.4875\n",
            "Epoch 293/300\n",
            "94/94 - 5s - loss: 1.5919 - accuracy: 0.4823\n",
            "Epoch 294/300\n",
            "94/94 - 5s - loss: 1.5860 - accuracy: 0.4855\n",
            "Epoch 295/300\n",
            "94/94 - 5s - loss: 1.5898 - accuracy: 0.4835\n",
            "Epoch 296/300\n",
            "94/94 - 5s - loss: 1.5847 - accuracy: 0.4870\n",
            "Epoch 297/300\n",
            "94/94 - 5s - loss: 1.5857 - accuracy: 0.4847\n",
            "Epoch 298/300\n",
            "94/94 - 5s - loss: 1.5822 - accuracy: 0.4844\n",
            "Epoch 299/300\n",
            "94/94 - 5s - loss: 1.5856 - accuracy: 0.4860\n",
            "Epoch 300/300\n",
            "94/94 - 5s - loss: 1.5713 - accuracy: 0.4873\n",
            "24.172380566596985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "JTKVrx64jXC4",
        "outputId": "e5359c05-d948-4f45-fbff-44e5b47ef8b2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1c192bebd86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "PdCjkksXjXC5",
        "outputId": "4b0dfad9-a9a0-4bd6-f497-f4c8b55162d5"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV1b3//9cncwIJISEESAgEkUlUkIhYqPOAWKutVm1LB9tebG97q632VjvX1g7f3l9v660WqXqrvRVn1KpUUdFqURAQZJ7HECAQAknInM/vj7OJx/QkJMjhZHg/H4882Gfttc/+7ByST/Zaa69l7o6IiEhLcbEOQEREOiclCBERiUgJQkREIlKCEBGRiJQgREQkIiUIERGJSAlC5Dgwsz+b2c/bWXermV30Yd9HJNqUIEREJCIlCBERiUgJQnqMoGnnO2b2nplVmdn9ZpZrZnPNrMLMXjazvmH1P25mq8ys3MxeM7PRYfvGm9nS4LhHgZQW5/qYmS0Ljl1gZqcdY8z/ZmYbzazMzJ41s0FBuZnZf5vZXjM7ZGYrzGxssG+ama0OYis2s1uP6RsmPZ4ShPQ0VwMXAyOAK4C5wPeAHEI/D98EMLMRwGzg5mDfC8DfzCzJzJKAp4G/AFnA48H7Ehw7HngAuBHIBu4FnjWz5I4EamYXAL8ErgUGAtuAR4LdlwDnBNfRJ6izP9h3P3Cju6cDY4FXO3JekSOUIKSn+R933+PuxcAbwEJ3f9fda4A5wPig3nXA8+4+z93rgf8CUoGPAJOAROB37l7v7k8A74SdYwZwr7svdPdGd38QqA2O64jPAg+4+1J3rwVuB842s6FAPZAOjALM3de4e0lwXD0wxswy3P2Auy/t4HlFACUI6Xn2hG1XR3jdO9geROgvdgDcvQnYAeQF+4r9gzNdbgvbHgLcEjQvlZtZOTA4OK4jWsZQSeguIc/dXwX+ANwN7DWzWWaWEVS9GpgGbDOz183s7A6eVwRQghBpzS5Cv+iBUJs/oV/yxUAJkBeUHVEQtr0DuNPdM8O+0tx99oeMoRehJqtiAHe/y90nAGMINTV9Jyh/x92vBPoTagp7rIPnFQGUIERa8xhwuZldaGaJwC2EmokWAG8BDcA3zSzRzD4JTAw79k/AV83srKAzuZeZXW5m6R2MYTZwg5mNC/ovfkGoSWyrmZ0ZvH8iUAXUAE1BH8lnzaxP0DR2CGj6EN8H6cGUIEQicPd1wHTgf4B9hDq0r3D3OnevAz4JfBEoI9Rf8VTYsYuBfyPUBHQA2BjU7WgMLwM/BJ4kdNdyEnB9sDuDUCI6QKgZaj/wm2Df54CtZnYI+CqhvgyRDjMtGCQiIpHoDkJERCJSghARkYiUIEREJCIlCBERiSgh1gEcT/369fOhQ4fGOgwRkS5jyZIl+9w9J9K+bpUghg4dyuLFi2MdhohIl2Fm21rbpyYmERGJSAlCREQiUoIQEZGIulUfRCT19fXs3LmTmpqaWIcSVSkpKeTn55OYmBjrUESkm+j2CWLnzp2kp6czdOhQPjj5Zvfh7uzfv5+dO3dSWFgY63BEpJvo9k1MNTU1ZGdnd9vkAGBmZGdnd/u7JBE5sbp9ggC6dXI4oidco4icWD0iQRzNnkM1VNTUxzoMEZFORQkCKK2opbKmISrvXV5ezj333NPh46ZNm0Z5eXkUIhIRaR8lCMAMorUqRmsJoqGh7YT0wgsvkJmZGaWoRESOrtuPYmoPw2iK0sJJt912G5s2bWLcuHEkJiaSkpJC3759Wbt2LevXr+eqq65ix44d1NTUcNNNNzFjxgzg/WlDKisrueyyy5gyZQoLFiwgLy+PZ555htTU1KjEKyJyRI9KED/92ypW7zr0L+WH6xqJjzOSEzp+QzVmUAY/vuKUVvf/6le/YuXKlSxbtozXXnuNyy+/nJUrVzYPR33ggQfIysqiurqaM888k6uvvprs7OwPvMeGDRuYPXs2f/rTn7j22mt58sknmT59eodjFRHpiB6VIFpzIsf/TJw48QPPKtx1113MmTMHgB07drBhw4Z/SRCFhYWMGzcOgAkTJrB169YTFq+I9FxRSxBmlgL8A0gOzvOEu/+4RZ0vElpovTgo+oO73xfs+wLwg6D85+7+4IeNqbW/9NfvriA5MY4h2b0+7CmOqlev98/x2muv8fLLL/PWW2+RlpbGeeedF/FZhuTk5Obt+Ph4qqurox6niEg07yBqgQvcvdLMEoE3zWyuu7/dot6j7v6N8AIzywJ+DBQR6j9eYmbPuvuBaARqBlHqgiA9PZ2KioqI+w4ePEjfvn1JS0tj7dq1vP12y2+NiEjsRC1BuLsDlcHLxOCrvb+GLwXmuXsZgJnNA6YCs493nMH7R20UU3Z2NpMnT2bs2LGkpqaSm5vbvG/q1KnMnDmT0aNHM3LkSCZNmhSlKEREOi6qfRBmFg8sAYYDd7v7wgjVrjazc4D1wLfcfQeQB+wIq7MzKIt0jhnADICCgoJji5PQfEbR8vDDD0csT05OZu7cuRH3Heln6NevHytXrmwuv/XWW497fCIikUT1OQh3b3T3cUA+MNHMxrao8jdgqLufBswDOtzP4O6z3L3I3YtyciKumndUZtAUvfwgItIlnZAH5dy9HJhPqJkovHy/u9cGL+8DJgTbxcDgsKr5vN+RfdyFmpiUIUREwkUtQZhZjpllBtupwMXA2hZ1Boa9/DiwJth+EbjEzPqaWV/gkqDsmByt+SjUxHSs7945RLOJTER6pmj2QQwEHgz6IeKAx9z9OTO7A1js7s8C3zSzjwMNQBnwRQB3LzOznwHvBO91x5EO645KSUlh//79bU75Hc1RTCfCkfUgUlJSYh2KiHQj1p3+8iwqKvLFixd/oKw9K8qVVdVR19DEgD5d9xesVpQTkWNhZkvcvSjSvm7/JHViYuJRV1n77hPv8fr6Mt7+3oUnKCoRkc5Ps7kCiQlGXWNTrMMQEelUlCCApPh46huUIEREwilBoDsIEZFIlCCApPg46pUgREQ+QAmCUIJocmhQkhARaaYEASQGCwXVN3afIb8iIh+WEgSQGB/6NqgfQkTkfUoQQFJ86AnrOo1kEhFppgQBJDU3MSlBiIgcoQTB+01MShAiIu9TgiCsD0JNTCIizZQgeL+JSZ3UIiLvU4Ig9BwEaJiriEg4JQjUByEiEokSBGFNTOqDEBFpFs0lR1PMbJGZLTezVWb20wh1vm1mq83sPTN7xcyGhO1rNLNlwdez0YoTIPHIcxC6gxARaRbNBYNqgQvcvdLMEoE3zWyuu78dVuddoMjdD5vZ14D/B1wX7Kt293FRjK9ZcxOT7iBERJpF7Q7CQyqDl4nBl7eoM9/dDwcv3wbyoxVPW5I1iklE5F9EtQ/CzOLNbBmwF5jn7gvbqP5lYG7Y6xQzW2xmb5vZVW2cY0ZQb3FpaekxxalOahGRfxXVBOHujUEzUT4w0czGRqpnZtOBIuA3YcVDgoW0PwP8zsxOauUcs9y9yN2LcnJyjinO5tlcGzTMVUTkiBMyisndy4H5wNSW+8zsIuD7wMfdvTbsmOLg383Aa8D4aMV35DmIWt1BiIg0i+Yophwzywy2U4GLgbUt6owH7iWUHPaGlfc1s+Rgux8wGVgdrViT1EktIvIvojmKaSDwoJnFE0pEj7n7c2Z2B7DY3Z8l1KTUG3jczAC2u/vHgdHAvWbWFBz7K3ePWoJITAgNc1UfhIjI+6KWINz9PSI0C7n7j8K2L2rl2AXAqdGKrSV1UouI/Cs9SQ0kxBlmepJaRCScEgRgZiTGx1GnyfpERJopQQSS4+OoqW+MdRgiIp2GEkQgu3cS+6vqYh2GiEinoQQR6J+ewt5DNbEOQ0Sk01CCCORkJFNaUXv0iiIiPYQSRKB/ejJ7dAchItJMCSKQm5FCVV0jVbUNsQ5FRKRTUIII9E9PBmCvmplERAAliGb901MA1MwkIhJQggj0z9AdhIhIOCWIQG5wB6GhriIiIUoQgYzUBJIS4nQHISISUIIImBkDMlIoOag7CBERUIL4gIF9Uigpr451GCIinYISRJi8zFTdQYiIBKK55GiKmS0ys+VmtsrMfhqhTrKZPWpmG81soZkNDdt3e1C+zswujVac4QZmprD7UA2NTZr2W0QkmncQtcAF7n46MA6YamaTWtT5MnDA3YcD/w38GsDMxgDXA6cAU4F7gqVLo2pgn1Qam5y9FbqLEBGJWoLwkMrgZWLw1fJP8yuBB4PtJ4ALLbQ49ZXAI+5e6+5bgI3AxGjFekReZioAu8qVIEREotoHYWbxZrYM2AvMc/eFLarkATsA3L0BOAhkh5cHdgZlkc4xw8wWm9ni0tLSDxXvwMzQsxAlB9VRLSIS1QTh7o3uPg7IByaa2dgonGOWuxe5e1FOTs6Heq+BfY7cQShBiIickFFM7l4OzCfUnxCuGBgMYGYJQB9gf3h5ID8oi6qMlAR6JyeoiUlEhOiOYsoxs8xgOxW4GFjbotqzwBeC7WuAV93dg/Lrg1FOhcDJwKJoxRoWM4X9erGptPLolUVEurmEKL73QODBYPRRHPCYuz9nZncAi939WeB+4C9mthEoIzRyCXdfZWaPAauBBuDr7t4YxVibjRyQzuvrP1xfhohIdxC1BOHu7wHjI5T/KGy7BvhUK8ffCdwZrfhaM2pAOk8s2UlZVR1ZvZJO9OlFRDoNPUndwojcdADW7j4U40hERGJLCaKFUQNCCWLd7ooYRyIiEltKEC3kpCfTNy1RCUJEejwliBbMjJED0lmrBCEiPZwSRASjBmSwYU8FTZq0T0R6MCWICEbkplNV10ixnqgWkR5MCSKCkQOOjGRSM5OI9FxKEBGMbB7JpKGuItJzKUFE0Ds5gYKsNFYWK0GISM+lBNGKM4dmsXDLfnVUi0iPpQTRirNPyubA4XrW7VE/hIj0TEoQrTj7pGwA3tq0P8aRiIjEhhJEK/IyUxmancbLa/bEOhQRkZhQgmjDNRPyWbBpP5u1PoSI9EBKEG249szBJMYbDy/cHutQREROuGiuKDfYzOab2WozW2VmN0Wo8x0zWxZ8rTSzRjPLCvZtNbMVwb7F0YqzLf3TUzhvZH+eX1FCaKE7EZGeI5p3EA3ALe4+BpgEfN3MxoRXcPffuPs4dx8H3A687u5lYVXOD/YXRTHONl16ygBKDtbomQgR6XGiliDcvcTdlwbbFcAaIK+NQz4NzI5WPMfqwlH9iY8z5q4siXUoIiIn1AnpgzCzoYSWH13Yyv40YCrwZFixAy+Z2RIzmxHtGFvTt1cSF47qz/1vbmFNie4iRKTniHqCMLPehH7x3+zurf2GvQL4Z4vmpSnufgZwGaHmqXNaef8ZZrbYzBaXlpYe19iPuPMTp5KRmsiPnlkZlfcXEemMopogzCyRUHL4q7s/1UbV62nRvOTuxcG/e4E5wMRIB7r7LHcvcveinJyc4xN4CznpyXxlSiHvbD3ABj1ZLSI9RDRHMRlwP7DG3X/bRr0+wLnAM2Flvcws/cg2cAkQ0z/fr56QT2K8MXvRjliGISJywkTzDmIy8DnggrChrNPM7Ktm9tWwep8AXnL3qrCyXOBNM1sOLAKed/e/RzHWo+rXO5lLxgzgqXd3UlPfGMtQREROiIRovbG7vwlYO+r9Gfhzi7LNwOlRCexD+PTEAp5fUcKLq3Zz5bi2BmSJiHR9epK6Az5yUjYFWWnc98YWGjUNuIh0c0oQHRAXZ3z74hGsKD7IX97aGutwRESiSgmig64cN4hzR+Tw0+dW88ii7VTXNXKwuj7WYYmIHHdKEB1kZsycPoEpw/vxo2dXceXdbzL9vojP/4mIdGlKEMcgNSme31xzOglxxvo9lawoPsiu8upYhyUicly1K0GY2U1mlmEh95vZUjO7JNrBdWYD+qTwh8+M55sXngzA6+uj8xS3iEistPcO4kvBNBmXAH0JPd/wq6hF1UVcMCqXb110MoP6pPDssl1U1+n5CBHpPtqbII48zzAN+Iu7r6Idzzj0BGbGZycN4a3N+7ny7jepqFGHtYh0D+1NEEvM7CVCCeLFYBqMpuiF1bV8/fzh3P+FIjaVVjH9/kXMeXenFhgSkS6vvQniy8BtwJnufhhIBG6IWlRd0IWjc/nVJ09lf2Ut33p0OV/9vyVU1TbEOiwRkWPW3gRxNrDO3cvNbDrwA+Bg9MLqmj5VNJh/fOd8fnD5aOat3sNn71uoeZtEpMtqb4L4I3DYzE4HbgE2AQ9FLaouLC7O+MpHh3H3Z85g2Y5ybnlsOQeq6pQoRKTLaW+CaPBQo/qVwB/c/W4gPXphdX2XnTqQ2y4bxfMrShj/s3mc9YtXtCKdiHQp7U0QFWZ2O6Hhrc+bWRyhfghpw1fPPYnHv3o237poBKmJ8XzhgUWs260Fh0Ska2hvgrgOqCX0PMRuIB/4TdSi6kbOHJrFTRedzENfnogZfPKef/Lnf26htiHU5LRq10G+P2cFuw/WxDhSEZEPsvYOxzSzXODM4OWiYCnQTqWoqMgXL14c6zBatau8mu8++R5vbNhH37RExg3OZHXJIfYcqqVf72Tm3vRRctKTYx2miPQgZrbE3Ysi7WvvVBvXElrZ7VPAtcBCM7vmKMcMNrP5ZrbazFaZ2U0R6pxnZgfDVpz7Udi+qWa2zsw2mtlt7YmzsxuUmcpDX5rIQ1+ayAWjctm6/zBVtY389trTKT9cx/+8uiHWIYqINGvvinLfJ/QMxF4AM8sBXgaeaOOYBuAWd18aPFi3xMzmufvqFvXecPePhReYWTxwN3AxsBN4x8yejXBsl2NmnDMih3NG5ADQ0NhEQnwcS7cf4OGF2xk9MIPrzxxMaElvEZHYaW8fRFyLJqX9RzvW3UvcfWmwXQGsAdq7TudEYKO7b3b3OuARQiOoup2E+NC38TuXjGLSsGxuf2oF35j9Loc0ZYeIxFh7E8TfzexFM/uimX0ReB54ob0nMbOhwHgg0sIJZ5vZcjOba2anBGV5wI6wOjtpJbmY2QwzW2xmi0tLu+6Mqn3SEnnoSxP5z6kj+fvK3Uz7/Rv85e1tvLezXNN2iEhMtKuJyd2/Y2ZXA5ODolnuPqc9x5pZb+BJ4OZgRthwS4Eh7l5pZtOAp4GT2xd6c2yzgFkQ6qTuyLGdTVyc8e/nDeeswmx++PRKfvj0SgBOGZTBj684hYmFWTGOUER6knaPYjqmNzdLBJ4DXnT337aj/lagiFCS+Im7XxqU3w7g7r9s6/jOPoqpI9ydjXsrWbr9AHe9spHi8mo+OT6Pguw0pk8aQr/eGu0kIh9eW6OY2ryDMLMKIFIGMcDdPaONYw24H1jTWnIwswHAHnd3M5tIqMlrP1AOnGxmhUAxcD3wmbZi7W7MjJNz0zk5N50rTh/E717ewANvbqGhyfn7yt386urTGNQnhf4ZKbEOVUS6qajdQZjZFOANYAXvTw3+PaAAwN1nmtk3gK8RGvFUDXzb3RcEx08DfgfEAw+4+51HO2d3uoOIpL6xiUVbypjx0GKqgsWJrisazDkjcjhvZA69kts7KE1EJKStO4ioNjGdaN09QRxxsLqeV9fuYfmOg/x5wVYAPnpyPz5/9lDOGpZFRopmQRGR9lGC6MY2l1by+vpSfvq30CMig7NSue/zZzJygOZSFJGjO+Y+COn8huX0ZlhOb84cmkXJwRq+P2cF1816i6vG5TF17AAmDcuOdYgi0kW19zkI6eTG5vXh4jG5PP7VsynISuPRd3Zw/ay3+eL/LmL7/sOxDk9EuiA1MXVTNfWNPLhgK3+Yv5FeSQn85ONjOC0/k4F9UjSNh4g0Ux9ED7Z29yGm37eIfZW1AIwvyOSGyYVcMiaXlMT4GEcnIrGmBNHD1dQ3srrkEIu3lvHggm0Ul1czZmAGM6dPoCA7LdbhiUgMKUFIs8YmZ97q3dzy2HKq6ho5qzCLi8fkcvGYXIZk94p1eCJygilByL8oLq/mqSU7eXpZMZtKq4iPM248ZxjfuXSk+ihEehAlCGlTcXk1v31pPU8u3Unv5AROyunFz64ay2n5mbEOTUSiTM9BSJvyMlP5r0+dximDMli3u4LX15dyzcy3mDQsm4EZKXxv2mj6pOnpbJGeRglCgNDkgF+aUgjAgao6bnl8OZtKK1mwcR9vbtzHf04dycTCLAb2SY1xpCJyoqiJSdq0fEc533zkXbbtP0xSfBxfmlLIFz4yRIlCpJtQH4R8KLUNjawtqeDPC7by9LJi3OH0/D787vrxFPbTyCeRrkwJQo6brfuqeGn1bu55bRM19Y1cfUY+YwZl8Mnx+aQm6cE7ka5GCUKOu13l1fzihTW8unYvh+saGZCRwh1XnsIlpwyIdWgi0gFKEBJVCzfv58fPrmLt7gouHNWfq8bnce7IHK1LIdIFxCRBmNlg4CEgl9CypbPc/fct6nwW+C6hJUwrgK+5+/Jg39agrBFoaO0CwilBxE59YxOz/rGZ+9/cQllVHb2TE/jRFWM4qzBLT2iLdGKxShADgYHuvtTM0oElwFXuvjqszkcIrVl9wMwuA37i7mcF+7YCRe6+r73nVIKIvcYm593tB/jZ82tYvqMcgAlD+jKgTwrfumgEw/v3jnGEIhIuJg/KuXsJUBJsV5jZGiAPWB1WZ0HYIW8D+dGKR06M+DijaGgWj994Nu9uP8CiLWW8vHYvb6wv5aVVu7nuzMF87bzh5GVqmKxIZ3dC+iDMbCjwD2Csux9qpc6twCh3/0rwegtwgFDz1L3uPquV42YAMwAKCgombNu27bjHLx9eaUUtv523nieW7ADgU0WD+ffzTiK/r2aTFYmlmHZSm1lv4HXgTnd/qpU65wP3AFPcfX9QlufuxWbWH5gH/Ie7/6Otc6mJqfMrLq/mnvkbeWzxDpocLhjVn29fPILRAzNiHZpIjxSzBGFmicBzwIvu/ttW6pwGzAEuc/f1rdT5CVDp7v/V1vmUILqOXeXVPPjWVh59Zwflh+vJ75vKZWMHcOO5J9Gvd3KswxPpMWLVSW3Ag0CZu9/cSp0C4FXg8+H9EWbWC4gL+i56EbqDuMPd/97WOZUgup7yw3U8vngnC7eU8dq6vaQmxXNGQV9+cPloTs5Nj3V4It1erBLEFOANYAXQFBR/DygAcPeZZnYfcDVwpOOgwd2LzGwYobsKCHWkP+zudx7tnEoQXduGPRX88fVNvLaulKT4OK4tymf62UPon54S69BEui09KCddypqSQ/zH7HfZXFpJbkYKV5w+iMvGDmDc4EwtZiRynClBSJe0atdBvjdnJWtKDlHX0MSpeX24fdooBmSkUJCVRkJ8XKxDFOnylCCkS6usbWDO0p386Y0tbC87DMCkYVnM+nyRpvMQ+ZCUIKRbqKpt4OGF26mqa+Du+RspyErDHfL6pvLdqaMYm9cn1iGKdDlKENLtvLlhH1/7vyUU5vRiV3kNlbX1TBjSl0+Oz+fqCXogX6S9tCa1dDtTTu7H4h9eRFJ8HPsq6/jB0ytYv6eSWx5fzoa9lXzzwuGkJem/t8iHoZ8g6bKSE0ILFOWkJ3Pv54qoa2jiB0+vYObrm3hp9W6umZBP0ZAsJhZmxThSka5JTUzS7SzYtI9vP7qc3YdqAMjLTOWMIX25YfJQzijoG+PoRDoX9UFIj9PY5FTVNfDkkp0s3V7OmxtKKa+uZ8Y5w0hLTCAnPZnPnFUQ6zBFYk59ENLjxMcZGSmJ3DC5kBsmh4bK3vn8Gu59fXNznZKD1Xz89EGa0kOkFbqDkB7lrU37Abh7/kbe3LiPlMQ4vjJlGEOy07hqfB6JevhOehjdQYgEzj4pGwg9aFdcXs2Nf1nCH+ZvBGD2ou3M/NwEmppgQB/N/ySiOwjp0ZqanOr6Ruau3M2tjy8nzkKjo747dSTnj+pPQVaa5n+Sbk13ECKtiIszeiUncM2EfPZX1vJe8UH2HqrhJ39bzU/+tpph/Xpxx5VjyUxLZMm2A3x6YgFJCWqGkp5BdxAiLTQ1Oev3VrB46wHue2MzW/cfJjHeqG90Tsvvw1+/chbpmgNKugkNcxU5RjX1jdw9fyMb9lRy4ej+3P7UCs4Y0pfLTx3IgcN1XH1GPoOztK62dF1qYhI5RimJ8dxyycjm12bGj59ZyaItZUBoNNQ3zj+Zr513kpqepNuJ5opyg4GHgFzAgVnu/vsWdQz4PTANOAx80d2XBvu+APwgqPpzd3/waOfUHYScCNV1jeytqCExPo5fzV3Ls8t3kZeZyojc3lx6ygA+VTSY+Dh1bEvXEKslRwcCA919qZmlA0uAq9x9dVidacB/EEoQZwG/d/ezzCwLWAwUEUouS4AJ7n6grXMqQUgsvLJmD7MXbWdTaRVb9lVxVmEWn500hJr6Ri4anUtWr6RYhyjSqpg0Mbl7CVASbFeY2RogD1gdVu1K4CEPZam3zSwzSCznAfPcvSy4gHnAVGB2tOIVOVYXjs7lwtG5uDtPLNnJz59fwzdnvwtAckIcV43L4yPDs7n81IFaBU+6lBPSB2FmQ4HxwMIWu/KAHWGvdwZlrZVHeu8ZwAyAggLNrSOxY2Z8qmgwV5w+iLW7K4g34+FF25jzbjGPLt7BE0t2csXpg8hJTyY/M5Xh/XvrGQvp1KKeIMysN/AkcLO7Hzre7+/us4BZEGpiOt7vL9JRKYnxjBucCcAv80/jZ1eO5ZF3dnDH31bzxoZ9zfU+N2kI3798NCmJ8bEKVaRNUU0QZpZIKDn81d2filClGBgc9jo/KCsm1MwUXv5adKIUia6E+DimTxrCNRPyKa2oZW9FDc+9V8L//nMrT79bzLiCTL5z6Uj6piWR3TtJCx1JpxHNTmoDHgTK3P3mVupcDnyD9zup73L3iUEn9RLgjKDqUkKd1GVtnVOd1NKV/HPjPp57r4RX1+5hX2UdjU1OQlyomSqrVyJXn5HPsJzesQ5TurlYPQcxGfgcsMLMlgVl3wMKANx9JvACoeSwkdAw1xuCfWVm9jPgneC4O46WHES6msnD+zF5eD/2HDqZX7ywhjEDM9hWdphHFm2nyeFvy0v4/uWj2XOohqIhWYwZlBHrkKWH0ZPUIp1MWVUdG/ZU8PkHFlHb0ASAGdw2dRQ3nntSjGGzks8AAA+vSURBVKOT7kZPUot0IVm9kjhrWDYLbruA4vJq+qQm8uu/r+WXc9eybk8FYwZm0D8jhUnDsuifrmnJJXqUIEQ6qezeyWT3Tgbgt9eOIyn+Pf6xvpSnlhYDkJ6SwNnDshmUmcpZhVmcMyKHXsn6kZbjR01MIl3Mgao6tpcd5ncvr6e4vJodZdVU1zcyvH9vfvSxMfRNS2LEgN7sKDtMckK8JhOUNmk2V5FurK6hifnr9nLzI8uorm8EICHOaGhy+qQm8vC/ncUpg/rEOErprJQgRHqAHWWH2bb/MAer61m56yC9kxP469vbqGlo4nvTRpOcEMfIAekM69dLU35IMyUIkR5qy74qrrv3LfZW1DaX5WWm8t3LRrG25BAHDtdx51WnEqfZZ3ssjWIS6aEK+/XipW+dw/aywyTExbF29yHueW1T82SCAGlJCZw+OJOPnTpQiUI+QHcQIj1MfWMTy3aUk5wQx8+eW807W0Oz6BdkpVGQlcZXPlrIOSfnNCcLd9ekgt2YmphEJKKyqjo2l1ayeV8VL63aw+pdB9l1sIaMlARGDkhn1IAM5q3ew6zPT+C0/MxYhytRoAQhIu1S29DIi6v2sHDzfl5ctZt9lXX0Soqn0Z0pw/sxsE8q/zl1JE0O89fu5aIxufTWsxddmhKEiHTY3ooaVhYfZNSADO56ZQPvbC1j2/7DjBqYTkVNA9v2Hya7VxJ3fmIsl54yQM1QXZQShIgcF8+9t4tfvrCWjNREvjylkD8v2MLK4kP0T0/m/JH9ufHcYQzL6a1+iy5ECUJEoqKuoYlnl+9i/rq9zF+7l/rGJm6YXMhTS3fyi0+cyiWnDGBXeTUDMlI0QqqTUoIQkagrrajlxr8sZun2csygd1ICF4zuzzPLdnH64EwG903l6gn5nD+yf6xDlTBtJQg9Tikix0VOejL/+8WJ3HrJCJ75+mQKc3rx3HslXH7aQMoP1/HWpv3c8L/v8JNnV3Gopj7W4Uo7RHNFuQeAjwF73X1shP3fAT4bvEwARgM5wWJBW4EKoBFoaC27taQ7CJHOpaGxqXlaj9qGRn49dx0P/HMLAOMGZ3LNhHzizBjQJ5k/vLqRK04fxA2TC2MZco8TkyYmMzsHqAQeipQgWtS9AviWu18QvN4KFLn7vraOa0kJQqTzW7SljLc27WfuyhLW7q74wD4zuPWSkRyua6BoaBbnj+xPRU09yQnxJCWowSMaYjLVhrv/w8yGtrP6p4HZ0YpFRDqPiYVZTCzM4psXDmfVrkOkJMbzztYyTs/P5OfPr+Y3L64Lam7iotH9WbBpPx85KZs/fb5II6NOsKh2UgcJ4rm27iDMLA3YCQw/su60mW0BDgAO3Ovus9o4fgYwA6CgoGDCtm3bjlv8InLi7Sg7THJiHPfM38S81XvolRzP+j2VXHH6IMqqatm0t4pzR+Tw62tOi3Wo3ULMRjG1M0FcB0x39yvCyvLcvdjM+gPzgP9w938c7XxqYhLpfuobm7j6jwvYUlrFsP69SU2M4+3NZVw0uj+n5WcyIjedhqYmpp4ygIT4ONydv7y9jW37D/PDj42JdfidXmefzfV6WjQvuXtx8O9eM5sDTASOmiBEpPtJjI/jma9PBsDMaGhs4jP3LWTRljJeXrO3ud6wfr2IizNKK2o5WB0aJXXBqP5MHt4vJnF3BzFNEGbWBzgXmB5W1guIc/eKYPsS4I4YhSginUB430NCfByPzpgEwCtr9nK4vpHkhDjuemUD9Y1NnFGQSZwZa0oOcdMjy7h4TH/OKswmNSme80f2V2d3B0QtQZjZbOA8oJ+Z7QR+DCQCuPvMoNongJfcvSrs0FxgTvAfIgF42N3/Hq04RaTrOZIwLhqT21x26SkDPlDnna1lzHxtE88s28XsRTsAGNgnhVsvGUmTO3sO1fCR4f0oyEqjX+/kExd8F6InqUWkW6usbWBXeTXF5dX84vk1bNhb+YH9ifHGl6YUcvBwPV+aUsiI3PQYRRobmmpDRITQ3FHrdleQlBBH316JLNtezszXN7F0ezmJ8UZDk3PeiBy+OLmQ19eV8pWPFjIoMzXWYUeVEoSISCtq6htZU3KIgqw0HnxrG/e/sZmqukYAUhLjOHNoFt+dOoqxeX1iHGl0KEGIiLTT6l2HeHLpTi4/bSBPv1vM3JW7Ka2oJbtXEt+6eAQAuRkpuDs1DU3EGVw0OpeUxPgYR35slCBERI5R+eE6Hlu8gxdW7GbZjvKIdaadOoBxgzM5b2R/RuSmU1ZVR9+0xC7x5LcShIjIh1TX0MRbm/czJCuN8up6EuKMlMR4nl1WzF2vbgQgPs4Y2CeFnQeq+cLZQ/j6+cPp1zu5U6+FoQQhIhIlTU3Oi6t2h6Y3X17C5n2V1Dc681bvAUKz1uZlpnJafh+WbDvA+aP68+mJBTGO+n2d/UlqEZEuKy7OuOzUgQCMGpABhJLG40t2UFpRy0NvbaO4vJrnV5QQZ/DS6j2sLD7I9ElD+P6cFVw4Opevnz88lpfQKiUIEZHjLC7OuO7M0F3CNy44GXdn0ZYyhvbrxczXN/Hggq38deF2AFbtOkRSfBxVdQ1cNDoXM9hVXkNBVhr5fVPplRy7X9NqYhIROcG27KvimWXF5GWmcttTK2hsCv0ejo+z5u0jLhmTyx+nTyA+zqhraKK4vJqq2gbyMlPp2yvpQ8eiJiYRkU6ksF8vbr4oNGS2T2oiqUnxnJaXyS/nriEjNZHLxg5gx4Fqlm0v54F/bmH8HS+RmZZEfWMTJQdrAMhISeDhf5sU1eczdAchItKJ/XbeejbsqaD8cD1N7lwzIZ/UpHjufH4NJQdryM1IpiArjce/+pFjen/dQYiIdFHfDh7Oa6loSBbPLCtmw95KEqI0jFYJQkSkCxrQJ4Ubzz0pqufQxOgiIhKREoSIiESkBCEiIhFFLUGY2QNmttfMVray/zwzO2hmy4KvH4Xtm2pm68xso5ndFq0YRUSkddG8g/gzMPUodd5w93HB1x0AZhYP3A1cBowBPm1mY6IYp4iIRBC1BOHu/wDKjuHQicBGd9/s7nXAI8CVxzU4ERE5qlj3QZxtZsvNbK6ZnRKU5QE7wursDMoiMrMZZrbYzBaXlpZGM1YRkR4llgliKTDE3U8H/gd4+ljexN1nuXuRuxfl5OQc1wBFRHqymD0o5+6HwrZfMLN7zKwfUAwMDquaH5Qd1ZIlS/aZ2bZjDKkfsO8Yj+1sdC2dT3e5DtC1dFbHei1DWtsRswRhZgOAPe7uZjaR0N3MfqAcONnMCgklhuuBz7TnPd39mG8hzGxxa/ORdDW6ls6nu1wH6Fo6q2hcS9QShJnNBs4D+pnZTuDHQCKAu88ErgG+ZmYNQDVwvYdmDmwws28ALwLxwAPuvipacYqISGRRSxDu/umj7P8D8IdW9r0AvBCNuEREpH1iPYqpM5kV6wCOI11L59NdrgN0LZ3Vcb+WbrUehIiIHD+6gxARkYiUIEREJKIenyC6+sSAZrbVzFYEEx4uDsqyzGyemW0I/u0b6zgjiTShY2uxW8hdwef0npmdEbvI/1Ur1/ITMysOm5ByWti+24NrWWdml8Ym6sjMbLCZzTez1Wa2ysxuCsq73GfTxrV0uc/GzFLMbFEw+8QqM/tpUF5oZguDmB81s6SgPDl4vTHYP7TDJ3X3HvtFaBjtJmAYkAQsB8bEOq4OXsNWoF+Lsv8H3BZs3wb8OtZxthL7OcAZwMqjxQ5MA+YCBkwCFsY6/nZcy0+AWyPUHRP8X0sGCoP/g/Gxvoaw+AYCZwTb6cD6IOYu99m0cS1d7rMJvr+9g+1EYGHw/X6M0GMCADOBrwXb/w7MDLavBx7t6Dl7+h1Ed50Y8ErgwWD7QeCqGMbSKo88oWNrsV8JPOQhbwOZZjbwxER6dK1cS2uuBB5x91p33wJsJPR/sVNw9xJ3XxpsVwBrCM2H1uU+mzaupTWd9rMJvr+VwcvE4MuBC4AngvKWn8uRz+sJ4EIz69Di1T09QXRoYsBOyoGXzGyJmc0IynLdvSTY3g3kxia0Y9Ja7F31s/pG0OzyQFhTX5e5lqBZYjyhv1a79GfT4lqgC342ZhZvZsuAvcA8Qnc45e7eEFQJj7f5WoL9B4HsjpyvpyeI7mCKu59BaP2Mr5vZOeE7PXR/2SXHMnfl2AN/BE4CxgElwP8X23A6xsx6A08CN3vY3GnQ9T6bCNfSJT8bd29093GE5qibCIyK5vl6eoI45okBOwt3Lw7+3QvMIfSfZs+RW/zg372xi7DDWou9y31W7r4n+IFuAv7E+00Vnf5azCyR0C/Uv7r7U0Fxl/xsIl1LV/5sANy9HJgPnE2oSe/IrBjh8TZfS7C/D6H57tqtpyeIdwgmBgx6/q8Hno1xTO1mZr3MLP3INnAJsJLQNXwhqPYF4JnYRHhMWov9WeDzwYiZScDBsOaOTqlFO/wnCH02ELqW64NRJoXAycCiEx1fa4J26vuBNe7+27BdXe6zae1auuJnY2Y5ZpYZbKcCFxPqU5lPaG47+NfP5cjndQ3wanDn136x7pmP9RehERjrCbXlfT/W8XQw9mGERlwsB1YdiZ9QO+MrwAbgZSAr1rG2Ev9sQrf39YTaTr/cWuyERnDcHXxOK4CiWMffjmv5SxDre8EP68Cw+t8PrmUdcFms429xLVMINR+9BywLvqZ1xc+mjWvpcp8NcBrwbhDzSuBHQfkwQklsI/A4kByUpwSvNwb7h3X0nJpqQ0REIurpTUwiItIKJQgREYlICUJERCJSghARkYiUIEREJCIlCJFOwMzOM7PnYh2HSDglCBERiUgJQqQDzGx6MCf/MjO7N5g8rdLM/juYo/8VM8sJ6o4zs7eDCeHmhK2fMNzMXg7m9V9qZicFb9/bzJ4ws7Vm9teOzrwpcrwpQYi0k5mNBq4DJntowrRG4LNAL2Cxu58CvA78ODjkIeC77n4aoad2j5T/Fbjb3U8HPkLoCWwIzTR6M6E1CYYBk6N+USJtSDh6FREJXAhMAN4J/rhPJTRhXRPwaFDn/4CnzKwPkOnurwflDwKPB3Nn5bn7HAB3rwEI3m+Ru+8MXi8DhgJvRv+yRCJTghBpPwMedPfbP1Bo9sMW9Y51/prasO1G9PMpMaYmJpH2ewW4xsz6Q/MazUMI/RwdmU3zM8Cb7n4QOGBmHw3KPwe87qFVzXaa2VXBeySbWdoJvQqRdtJfKCLt5O6rzewHhFbwiyM0c+vXgSpgYrBvL6F+CghNtTwzSACbgRuC8s8B95rZHcF7fOoEXoZIu2k2V5EPycwq3b13rOMQOd7UxCQiIhHpDkJERCLSHYSIiESkBCEiIhEpQYiISERKECIiEpEShIiIRPT/A6xTKQeLjzR2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Apwt4NxZuMr"
      },
      "source": [
        "# Top 10 Types (x,y,z)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6S1iTWFZuMs",
        "outputId": "0e34fe22-a4cb-49cf-f932-38ae6ac14c80"
      },
      "source": [
        "#remove rows not in the top 16 types\n",
        "train_df = train_df[train_df['Type'].isin(list(Percentages[:10].index))]\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt        Lat       Long        PosTime  Type\n",
            "994       008DC6  0.088502 -25.992256  28.387245  1596723690985  P28A\n",
            "995       008DC6  0.089647 -25.994843  28.396912  1596723703073  P28A\n",
            "996       008DC6  0.090028 -25.995621  28.399864  1596723717541  P28A\n",
            "997       008DC6  0.090028 -25.995621  28.399864  1596723719963  P28A\n",
            "998       008DC6  0.136568 -25.843708  28.353390  1596724125875  P28A\n",
            "...          ...       ...        ...        ...            ...   ...\n",
            "29550390  E94C42  0.281147 -17.482864 -66.559227  1596733935427  B738\n",
            "29550391  E94C42  0.281147 -17.482864 -66.559227  1596733935427  B738\n",
            "29550392  E94C42  0.286107 -17.484467 -66.613289  1596733965728  B738\n",
            "29550393  E94C42  0.301747 -17.464863 -66.685097  1596734007974  B738\n",
            "29550394  E94C42  0.301747 -17.464863 -66.685097  1596734007974  B738\n",
            "\n",
            "[13141213 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIvWgxNvZuMt",
        "outputId": "3f530f18-3029-4a20-9b19-9d7831c097fd"
      },
      "source": [
        "type_dict = {k: v for v, k in enumerate(list(Percentages[:10].index))}\n",
        "print(type_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B738': 0, 'A320': 1, 'C172': 2, 'A321': 3, 'B737': 4, 'A319': 5, 'P28A': 6, 'A20N': 7, 'B763': 8, 'B739': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "5a2AQWSnZuMu",
        "outputId": "ed40d76c-4297-4782-b7d0-4396657f28ba"
      },
      "source": [
        "train_df['Type'].replace(type_dict, inplace = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-2cd5364b97b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6506\u001b[0m             return self.replace(\n\u001b[0;32m-> 6507\u001b[0;31m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6508\u001b[0m             )\n\u001b[1;32m   6509\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4580\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4582\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4583\u001b[0m         )\n\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6551\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6552\u001b[0m                         \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6553\u001b[0;31m                         \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6554\u001b[0m                     )\n\u001b[1;32m   6555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, mask, regex)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Calculate the mask once, prior to the call of comp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[0;34m(a, b, regex, mask)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_numeric_v_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m         \u001b[0;31m# GH#29553 avoid deprecation warnings from numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m         \u001b[0m_check_comparison_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_check_comparison_types\u001b[0;34m(result, a, b)\u001b[0m\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1981\u001b[0;31m                 \u001b[0;34mf\"Cannot compare types {repr(type_names[0])} and {repr(type_names[1])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1982\u001b[0m             )\n\u001b[1;32m   1983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpCYjQZTZuMu",
        "outputId": "39d9b969-d024-4184-f8b8-6e5a09a7704f"
      },
      "source": [
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt        Lat       Long        PosTime  Type\n",
            "0         008DC6  0.088502 -25.992256  28.387245  1596723690985     6\n",
            "1         008DC6  0.089647 -25.994843  28.396912  1596723703073     6\n",
            "2         008DC6  0.090028 -25.995621  28.399864  1596723717541     6\n",
            "3         008DC6  0.090028 -25.995621  28.399864  1596723719963     6\n",
            "4         008DC6  0.136568 -25.843708  28.353390  1596724125875     6\n",
            "...          ...       ...        ...        ...            ...   ...\n",
            "13141208  E94C42  0.281147 -17.482864 -66.559227  1596733935427     0\n",
            "13141209  E94C42  0.281147 -17.482864 -66.559227  1596733935427     0\n",
            "13141210  E94C42  0.286107 -17.484467 -66.613289  1596733965728     0\n",
            "13141211  E94C42  0.301747 -17.464863 -66.685097  1596734007974     0\n",
            "13141212  E94C42  0.301747 -17.464863 -66.685097  1596734007974     0\n",
            "\n",
            "[13141213 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIcN9fB5ZuMv",
        "outputId": "0f6ed28f-104e-440b-f180-072920f66ac6"
      },
      "source": [
        "#turn train dataframe into a multi-dimensional numpy array\n",
        "train_df = np.array(list(train_df.groupby('Icao').apply(pd.DataFrame.to_numpy)))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_count = train_df.shape[0]\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16046,)\n",
            "16046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoA3qVVGZuMw",
        "outputId": "c80e8ae8-7663-4240-a2f9-8a6dabefb61d"
      },
      "source": [
        "#load in first dataframe\n",
        "train_input = pd.DataFrame(data = train_df[1], columns = [\"Icao\", \"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "train_input = train_input.set_index('Time')\n",
        "train_input = train_input.drop('PosTime', axis = 1)\n",
        "train_input = train_input.drop('Icao', axis = 1)\n",
        "print(train_input)\n",
        "#Get Species Type\n",
        "unique_species = train_input.Type[0]\n",
        "print(unique_species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                Alt      Lat     Long Type\n",
            "Time                                                      \n",
            "2020-08-06 07:12:53.616    0.995056 -33.9873  18.6088    0\n",
            "2020-08-06 07:12:53.616    0.995056 -33.9873  18.6088    0\n",
            "2020-08-06 07:13:29.760    0.995056 -33.9772  18.6055    0\n",
            "2020-08-06 07:13:44.242    0.998108 -33.9675  18.6024    0\n",
            "2020-08-06 07:13:56.289  0.00572213 -33.9593  18.5995    0\n",
            "...                             ...      ...      ...  ...\n",
            "2020-08-06 16:02:45.713    0.999252 -33.9463  18.5956    0\n",
            "2020-08-06 16:02:57.784    0.996963 -33.9541  18.5981    0\n",
            "2020-08-06 16:03:55.777    0.994675 -33.9771  18.6055    0\n",
            "2020-08-06 16:04:10.278    0.994675 -33.9778  18.6055    0\n",
            "2020-08-06 16:04:27.227    0.994675 -33.9779  18.6052    0\n",
            "\n",
            "[373 rows x 4 columns]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ban50lhsZuMx",
        "outputId": "663e9c81-4693-4c55-d879-8c4d9e2966b2"
      },
      "source": [
        "#Resampling/Interpolating\n",
        "norm_train_df = pd.DataFrame()\n",
        "norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "norm_train_df['X'] = np.cos(norm_train_df['Lat'])*np.cos(norm_train_df['Long'])\n",
        "norm_train_df['Y'] = np.cos(norm_train_df['Lat'])*np.sin(norm_train_df['Long'])\n",
        "norm_train_df['Z'] = np.sin(norm_train_df['Lat'])\n",
        "norm_train_df = norm_train_df.drop(['Lat', 'Long'], axis = 1)\n",
        "norm_train_df.reset_index(inplace = True)\n",
        "norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "norm_train_df = norm_train_df.iloc[0:73]\n",
        "print(norm_train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Time       Alt         X         Y         Z\n",
            "0  2020-08-06 07:10:00  0.026703 -0.770283  0.210344 -0.602013\n",
            "1  2020-08-06 07:15:00  0.217823 -0.527870  0.024722 -0.848965\n",
            "2  2020-08-06 07:20:00  0.402075 -0.091336 -0.029668 -0.995378\n",
            "3  2020-08-06 07:25:00  0.501640  0.269307  0.300068 -0.915114\n",
            "4  2020-08-06 07:30:00  0.586328  0.062704  0.785371 -0.615841\n",
            "..                 ...       ...       ...       ...       ...\n",
            "68 2020-08-06 12:50:00  0.000000  0.616940 -0.609703  0.497641\n",
            "69 2020-08-06 12:55:00  0.000000  0.581517 -0.663431  0.470847\n",
            "70 2020-08-06 13:00:00  0.000000  0.532755 -0.724819  0.436817\n",
            "71 2020-08-06 13:05:00  0.000000  0.466976 -0.791179  0.394930\n",
            "72 2020-08-06 13:10:00  0.000000  0.380428 -0.858236  0.344536\n",
            "\n",
            "[73 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuGBDTzxZuMz",
        "outputId": "142f7053-aac5-419e-9f46-83213508e6aa"
      },
      "source": [
        "#add species to label list\n",
        "train_labels = []\n",
        "train_labels.append(unique_species)\n",
        "print(train_labels)\n",
        "#convert dataframe to numpy\n",
        "norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "norm_train_df = norm_train_df.to_numpy()\n",
        "print(norm_train_df)\n",
        "final_input_train = norm_train_df\n",
        "print(final_input_train.shape)\n",
        "final_input_train = np.reshape(final_input_train, (1,73,4))\n",
        "print(final_input_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[ 0.02670329 -0.77028258  0.2103442  -0.60201334]\n",
            " [ 0.21782254 -0.52787019  0.02472167 -0.8489652 ]\n",
            " [ 0.40207523 -0.09133599 -0.0296684  -0.99537808]\n",
            " [ 0.50164034  0.26930658  0.30006819 -0.91511368]\n",
            " [ 0.58632792  0.06270415  0.78537095 -0.61584143]\n",
            " [ 0.59510185 -0.51221838  0.84026871 -0.17770996]\n",
            " [ 0.59510185 -0.6184077   0.78146291 -0.0829918 ]\n",
            " [ 0.60817557 -0.75676625  0.6497598   0.07153351]\n",
            " [ 0.62872997 -0.87870612  0.27121743  0.39283159]\n",
            " [ 0.65039623 -0.61539892 -0.17781411  0.76789733]\n",
            " [ 0.66680553 -0.06695013 -0.10088145  0.99264325]\n",
            " [ 0.67158908 -0.09477814  0.48494388  0.86939435]\n",
            " [ 0.65837804 -0.77836276  0.50019933  0.37941014]\n",
            " [ 0.62080362 -0.9428782  -0.2063924  -0.2615012 ]\n",
            " [ 0.55249699 -0.38332727 -0.51896531 -0.76402566]\n",
            " [ 0.44708934 -0.00586531 -0.18168871 -0.9833386 ]\n",
            " [ 0.30861372 -0.09164781  0.19012696 -0.97747246]\n",
            " [ 0.17662318 -0.36459835  0.29505189 -0.88318312]\n",
            " [ 0.08812085 -0.5884268   0.26523043 -0.76381066]\n",
            " [ 0.08392462 -0.59861979  0.26113897 -0.75727194]\n",
            " [ 0.09457798 -0.56555829  0.26764698 -0.78006982]\n",
            " [ 0.09927008 -0.54056022  0.2682496  -0.79739375]\n",
            " [ 0.09827373 -0.52355258  0.26447023 -0.80990628]\n",
            " [ 0.09186173 -0.5142466   0.25728781 -0.81814022]\n",
            " [ 0.0803069  -0.51223068  0.2471947  -0.82250502]\n",
            " [ 0.06388204 -0.51701272  0.2342637  -0.82329725]\n",
            " [ 0.04285995 -0.52802446  0.21821845 -0.82071364]\n",
            " [ 0.01751345 -0.54459991  0.19850581 -0.81486587]\n",
            " [ 0.         -0.56593876  0.17437203 -0.80579632]\n",
            " [ 0.         -0.5910651   0.14494476 -0.79349421]\n",
            " [ 0.         -0.61879076  0.10932253 -0.77791168]\n",
            " [ 0.         -0.64769193  0.06667161 -0.75897961]\n",
            " [ 0.         -0.67610676  0.0163277  -0.73662274]\n",
            " [ 0.         -0.70215952 -0.04210252 -0.71077379]\n",
            " [ 0.         -0.72381501 -0.10864738 -0.68138651]\n",
            " [ 0.         -0.73896319 -0.1828928  -0.64844709]\n",
            " [ 0.         -0.74553072 -0.26393108 -0.61198393]\n",
            " [ 0.         -0.74161196 -0.35034475 -0.57207539]\n",
            " [ 0.         -0.72560855 -0.44023203 -0.52885535]\n",
            " [ 0.         -0.69636406 -0.53127673 -0.48251646]\n",
            " [ 0.         -0.6532791  -0.62086075 -0.43331092]\n",
            " [ 0.         -0.59639294 -0.70621234 -0.38154894]\n",
            " [ 0.         -0.52642042 -0.78457837 -0.32759475]\n",
            " [ 0.         -0.44473719 -0.85340532 -0.27186061]\n",
            " [ 0.         -0.35331186 -0.91051206 -0.2147988 ]\n",
            " [ 0.         -0.25459    -0.95423726 -0.15689226]\n",
            " [ 0.         -0.15134001 -0.98354744 -0.09864401]\n",
            " [ 0.         -0.04647552 -0.9980954  -0.04056609]\n",
            " [ 0.          0.05712857 -0.99822493  0.01683171]\n",
            " [ 0.          0.15680917 -0.98492345  0.07305258]\n",
            " [ 0.          0.25026204 -0.95972985  0.12762263]\n",
            " [ 0.          0.33565105 -0.92460942  0.1800994 ]\n",
            " [ 0.          0.41167296 -0.88181016  0.2300787 ]\n",
            " [ 0.          0.47757633 -0.8337154   0.27719936]\n",
            " [ 0.          0.53313762 -0.78270662  0.32114579]\n",
            " [ 0.          0.57860169 -0.73104767  0.36164815]\n",
            " [ 0.          0.61459595 -0.6807976   0.39848018]\n",
            " [ 0.          0.64202833 -0.63375588  0.43145465]\n",
            " [ 0.          0.66197868 -0.59143947  0.46041675]\n",
            " [ 0.          0.6755912  -0.55508836  0.48523544]\n",
            " [ 0.          0.68397335 -0.52569349  0.50579324]\n",
            " [ 0.          0.68810361 -0.50403957  0.52197465]\n",
            " [ 0.          0.68874823 -0.49075416  0.53365366]\n",
            " [ 0.          0.68638486 -0.48635376  0.5406809 ]\n",
            " [ 0.          0.68113016 -0.49127699  0.54287072]\n",
            " [ 0.          0.67266835 -0.50589435  0.53998907]\n",
            " [ 0.          0.66018021 -0.53048252  0.53174278]\n",
            " [ 0.          0.64227566 -0.56515042  0.51777117]\n",
            " [ 0.          0.61694039 -0.60970308  0.49764114]\n",
            " [ 0.          0.58151699 -0.66343122  0.47084712]\n",
            " [ 0.          0.53275453 -0.72481935  0.43681748]\n",
            " [ 0.          0.46697603 -0.79117884  0.39492965]\n",
            " [ 0.          0.38042772 -0.85823632  0.34453617]]\n",
            "(73, 4)\n",
            "(1, 73, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K41dCQD9ZuM0",
        "outputId": "27ef1f22-3eee-4de6-d342-2be753e21ca0"
      },
      "source": [
        "for j in range(2,16046):\n",
        "    try:\n",
        "        train_input = pd.DataFrame(data = train_df[j], columns = [\"Icao\",\"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "        train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "        train_input = train_input.set_index('Time')\n",
        "        train_input = train_input.drop('PosTime', axis = 1)\n",
        "        unique_species = train_input.Type[0]\n",
        "        norm_train_df = pd.DataFrame()\n",
        "        norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "        norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "        norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "        norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "        norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "        norm_train_df['X'] = np.cos(norm_train_df['Lat'])*np.cos(norm_train_df['Long'])\n",
        "        norm_train_df['Y'] = np.cos(norm_train_df['Lat'])*np.sin(norm_train_df['Long'])\n",
        "        norm_train_df['Z'] = np.sin(norm_train_df['Lat'])\n",
        "        norm_train_df = norm_train_df.drop(['Lat', 'Long'], axis = 1)\n",
        "        norm_train_df.reset_index(inplace = True)\n",
        "        norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "        norm_train_df = norm_train_df.iloc[0:73]\n",
        "        norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "        norm_train_df = norm_train_df.to_numpy()\n",
        "        norm_train_df = np.reshape(norm_train_df, (1,73,4))\n",
        "        final_input_train = np.append(final_input_train, norm_train_df, axis = 0)\n",
        "        train_labels.append(unique_species)\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "print(final_input_train.shape)\n",
        "print(len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10376, 73, 4)\n",
            "10376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8TD-YT-ZuM1",
        "outputId": "f0cf3030-143b-48c2-9616-f11fd8f6086b"
      },
      "source": [
        "final_input_test = final_input_train[7263:]\n",
        "arr = list(range(7263,final_input_train.shape[0] ))\n",
        "print(final_input_test.shape)\n",
        "\n",
        "final_input_train = np.delete(final_input_train, arr, 0)\n",
        "print(final_input_train.shape)\n",
        "\n",
        "test_labels = train_labels[7263:]\n",
        "print(len(test_labels))\n",
        "\n",
        "train_labels_final = train_labels[:7263]\n",
        "print(len(train_labels_final))\n",
        "\n",
        "unique = list(dict.fromkeys(test_labels))\n",
        "unique2 = list(dict.fromkeys(train_labels_final))\n",
        "print(unique)\n",
        "print(unique2)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "test_labels = to_categorical(test_labels,num_classes = 10)\n",
        "train_labels_final = to_categorical(train_labels_final,num_classes = 10)\n",
        "print(len(test_labels))\n",
        "print(len(train_labels_final))\n",
        "\n",
        "train_labels_final = np.array(train_labels_final)\n",
        "test_labels = np.array(test_labels)\n",
        "print(train_labels_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3113, 73, 4)\n",
            "(7263, 73, 4)\n",
            "3113\n",
            "7263\n",
            "[9, 8, 2, 1, 4, 6, 0, 5, 3, 7]\n",
            "[0, 1, 5, 7, 4, 3, 6, 2, 8, 9]\n",
            "3113\n",
            "7263\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCW7EkFoZuM2",
        "outputId": "c9f9c766-66a0-45b5-c626-4f4b74db39f1"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(final_input_train, train_labels_final, final_input_test, test_labels):\n",
        "    verbose, epochs, batch_size = 2, 100, 16\n",
        "    n_timesteps, n_features, n_outputs = final_input_train.shape[1], final_input_train.shape[2], 10\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # fit network\n",
        "    model.fit(final_input_train, train_labels_final, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle = True)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(final_input_test, test_labels, batch_size=batch_size, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "    print(scores)\n",
        "    m, s = np.mean(scores), np.std(scores)\n",
        "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats=2):\n",
        "    # load data\n",
        "    # repeat experiment\n",
        "    scores = list()\n",
        "    for r in range(repeats):\n",
        "        score = evaluate_model(final_input_train, train_labels_final, final_input_test, test_labels)\n",
        "        score = score * 100.0\n",
        "        print('>#%d: %.3f' % (r+1, score))\n",
        "        scores.append(score)\n",
        "    # summarize results\n",
        "    summarize_results(scores)\n",
        "\n",
        "run_experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "454/454 - 5s - loss: 1.8457 - accuracy: 0.3522\n",
            "Epoch 2/100\n",
            "454/454 - 4s - loss: 1.6236 - accuracy: 0.3901\n",
            "Epoch 3/100\n",
            "454/454 - 4s - loss: 1.5753 - accuracy: 0.4091\n",
            "Epoch 4/100\n",
            "454/454 - 4s - loss: 1.5755 - accuracy: 0.4292\n",
            "Epoch 5/100\n",
            "454/454 - 4s - loss: 1.5013 - accuracy: 0.4528\n",
            "Epoch 6/100\n",
            "454/454 - 4s - loss: 1.4374 - accuracy: 0.4761\n",
            "Epoch 7/100\n",
            "454/454 - 4s - loss: 1.3025 - accuracy: 0.5086\n",
            "Epoch 8/100\n",
            "454/454 - 4s - loss: 1.2183 - accuracy: 0.5430\n",
            "Epoch 9/100\n",
            "454/454 - 4s - loss: 1.1071 - accuracy: 0.5784\n",
            "Epoch 10/100\n",
            "454/454 - 4s - loss: 0.9877 - accuracy: 0.6329\n",
            "Epoch 11/100\n",
            "454/454 - 4s - loss: 0.8870 - accuracy: 0.6667\n",
            "Epoch 12/100\n",
            "454/454 - 4s - loss: 0.7865 - accuracy: 0.7118\n",
            "Epoch 13/100\n",
            "454/454 - 4s - loss: 0.6921 - accuracy: 0.7436\n",
            "Epoch 14/100\n",
            "454/454 - 4s - loss: 0.6113 - accuracy: 0.7731\n",
            "Epoch 15/100\n",
            "454/454 - 4s - loss: 0.5372 - accuracy: 0.8031\n",
            "Epoch 16/100\n",
            "454/454 - 4s - loss: 0.5016 - accuracy: 0.8147\n",
            "Epoch 17/100\n",
            "454/454 - 4s - loss: 0.4553 - accuracy: 0.8335\n",
            "Epoch 18/100\n",
            "454/454 - 4s - loss: 0.4027 - accuracy: 0.8543\n",
            "Epoch 19/100\n",
            "454/454 - 4s - loss: 0.3852 - accuracy: 0.8569\n",
            "Epoch 20/100\n",
            "454/454 - 4s - loss: 0.3573 - accuracy: 0.8742\n",
            "Epoch 21/100\n",
            "454/454 - 4s - loss: 0.3326 - accuracy: 0.8761\n",
            "Epoch 22/100\n",
            "454/454 - 4s - loss: 0.3121 - accuracy: 0.8845\n",
            "Epoch 23/100\n",
            "454/454 - 4s - loss: 0.2893 - accuracy: 0.8915\n",
            "Epoch 24/100\n",
            "454/454 - 4s - loss: 0.2835 - accuracy: 0.9002\n",
            "Epoch 25/100\n",
            "454/454 - 4s - loss: 0.2577 - accuracy: 0.9057\n",
            "Epoch 26/100\n",
            "454/454 - 4s - loss: 0.2847 - accuracy: 0.8981\n",
            "Epoch 27/100\n",
            "454/454 - 4s - loss: 0.2580 - accuracy: 0.9071\n",
            "Epoch 28/100\n",
            "454/454 - 4s - loss: 0.2365 - accuracy: 0.9139\n",
            "Epoch 29/100\n",
            "454/454 - 4s - loss: 0.2473 - accuracy: 0.9122\n",
            "Epoch 30/100\n",
            "454/454 - 4s - loss: 0.2140 - accuracy: 0.9233\n",
            "Epoch 31/100\n",
            "454/454 - 4s - loss: 0.2165 - accuracy: 0.9201\n",
            "Epoch 32/100\n",
            "454/454 - 4s - loss: 0.2016 - accuracy: 0.9284\n",
            "Epoch 33/100\n",
            "454/454 - 4s - loss: 0.2125 - accuracy: 0.9226\n",
            "Epoch 34/100\n",
            "454/454 - 4s - loss: 0.1974 - accuracy: 0.9283\n",
            "Epoch 35/100\n",
            "454/454 - 4s - loss: 0.2001 - accuracy: 0.9263\n",
            "Epoch 36/100\n",
            "454/454 - 4s - loss: 0.1988 - accuracy: 0.9313\n",
            "Epoch 37/100\n",
            "454/454 - 4s - loss: 0.1887 - accuracy: 0.9320\n",
            "Epoch 38/100\n",
            "454/454 - 4s - loss: 0.1866 - accuracy: 0.9306\n",
            "Epoch 39/100\n",
            "454/454 - 4s - loss: 0.1681 - accuracy: 0.9393\n",
            "Epoch 40/100\n",
            "454/454 - 4s - loss: 0.1840 - accuracy: 0.9371\n",
            "Epoch 41/100\n",
            "454/454 - 4s - loss: 0.1802 - accuracy: 0.9376\n",
            "Epoch 42/100\n",
            "454/454 - 4s - loss: 0.1614 - accuracy: 0.9420\n",
            "Epoch 43/100\n",
            "454/454 - 4s - loss: 0.1709 - accuracy: 0.9400\n",
            "Epoch 44/100\n",
            "454/454 - 4s - loss: 0.1784 - accuracy: 0.9342\n",
            "Epoch 45/100\n",
            "454/454 - 4s - loss: 0.1666 - accuracy: 0.9418\n",
            "Epoch 46/100\n",
            "454/454 - 4s - loss: 0.1614 - accuracy: 0.9423\n",
            "Epoch 47/100\n",
            "454/454 - 4s - loss: 0.1419 - accuracy: 0.9508\n",
            "Epoch 48/100\n",
            "454/454 - 4s - loss: 0.1586 - accuracy: 0.9452\n",
            "Epoch 49/100\n",
            "454/454 - 4s - loss: 0.1512 - accuracy: 0.9464\n",
            "Epoch 50/100\n",
            "454/454 - 4s - loss: 0.1471 - accuracy: 0.9484\n",
            "Epoch 51/100\n",
            "454/454 - 4s - loss: 0.1412 - accuracy: 0.9514\n",
            "Epoch 52/100\n",
            "454/454 - 4s - loss: 0.1321 - accuracy: 0.9536\n",
            "Epoch 53/100\n",
            "454/454 - 4s - loss: 0.2076 - accuracy: 0.9442\n",
            "Epoch 54/100\n",
            "454/454 - 4s - loss: 0.1350 - accuracy: 0.9543\n",
            "Epoch 55/100\n",
            "454/454 - 4s - loss: 0.1329 - accuracy: 0.9529\n",
            "Epoch 56/100\n",
            "454/454 - 4s - loss: 0.1530 - accuracy: 0.9481\n",
            "Epoch 57/100\n",
            "454/454 - 4s - loss: 0.1182 - accuracy: 0.9580\n",
            "Epoch 58/100\n",
            "454/454 - 4s - loss: 0.1319 - accuracy: 0.9535\n",
            "Epoch 59/100\n",
            "454/454 - 4s - loss: 0.1353 - accuracy: 0.9526\n",
            "Epoch 60/100\n",
            "454/454 - 4s - loss: 0.1370 - accuracy: 0.9515\n",
            "Epoch 61/100\n",
            "454/454 - 4s - loss: 0.1334 - accuracy: 0.9535\n",
            "Epoch 62/100\n",
            "454/454 - 4s - loss: 0.1376 - accuracy: 0.9489\n",
            "Epoch 63/100\n",
            "454/454 - 4s - loss: 0.1333 - accuracy: 0.9529\n",
            "Epoch 64/100\n",
            "454/454 - 4s - loss: 0.1218 - accuracy: 0.9602\n",
            "Epoch 65/100\n",
            "454/454 - 4s - loss: 0.1133 - accuracy: 0.9627\n",
            "Epoch 66/100\n",
            "454/454 - 4s - loss: 0.1229 - accuracy: 0.9564\n",
            "Epoch 67/100\n",
            "454/454 - 4s - loss: 0.1191 - accuracy: 0.9586\n",
            "Epoch 68/100\n",
            "454/454 - 4s - loss: 0.1261 - accuracy: 0.9557\n",
            "Epoch 69/100\n",
            "454/454 - 4s - loss: 0.0982 - accuracy: 0.9638\n",
            "Epoch 70/100\n",
            "454/454 - 4s - loss: 0.1189 - accuracy: 0.9605\n",
            "Epoch 71/100\n",
            "454/454 - 4s - loss: 0.1247 - accuracy: 0.9586\n",
            "Epoch 72/100\n",
            "454/454 - 4s - loss: 0.1316 - accuracy: 0.9568\n",
            "Epoch 73/100\n",
            "454/454 - 4s - loss: 0.1197 - accuracy: 0.9576\n",
            "Epoch 74/100\n",
            "454/454 - 4s - loss: 0.1229 - accuracy: 0.9569\n",
            "Epoch 75/100\n",
            "454/454 - 4s - loss: 0.1194 - accuracy: 0.9597\n",
            "Epoch 76/100\n",
            "454/454 - 4s - loss: 0.1122 - accuracy: 0.9595\n",
            "Epoch 77/100\n",
            "454/454 - 4s - loss: 0.0940 - accuracy: 0.9674\n",
            "Epoch 78/100\n",
            "454/454 - 4s - loss: 0.0976 - accuracy: 0.9656\n",
            "Epoch 79/100\n",
            "454/454 - 4s - loss: 0.1058 - accuracy: 0.9617\n",
            "Epoch 80/100\n",
            "454/454 - 4s - loss: 0.1046 - accuracy: 0.9650\n",
            "Epoch 81/100\n",
            "454/454 - 4s - loss: 0.1148 - accuracy: 0.9613\n",
            "Epoch 82/100\n",
            "454/454 - 4s - loss: 0.1033 - accuracy: 0.9645\n",
            "Epoch 83/100\n",
            "454/454 - 4s - loss: 0.1103 - accuracy: 0.9623\n",
            "Epoch 84/100\n",
            "454/454 - 4s - loss: 0.0951 - accuracy: 0.9674\n",
            "Epoch 85/100\n",
            "454/454 - 4s - loss: 0.1017 - accuracy: 0.9613\n",
            "Epoch 86/100\n",
            "454/454 - 4s - loss: 0.1196 - accuracy: 0.9592\n",
            "Epoch 87/100\n",
            "454/454 - 4s - loss: 0.1175 - accuracy: 0.9642\n",
            "Epoch 88/100\n",
            "454/454 - 4s - loss: 0.0960 - accuracy: 0.9667\n",
            "Epoch 89/100\n",
            "454/454 - 4s - loss: 0.0927 - accuracy: 0.9683\n",
            "Epoch 90/100\n",
            "454/454 - 4s - loss: 0.1124 - accuracy: 0.9603\n",
            "Epoch 91/100\n",
            "454/454 - 4s - loss: 0.0963 - accuracy: 0.9679\n",
            "Epoch 92/100\n",
            "454/454 - 4s - loss: 0.1056 - accuracy: 0.9668\n",
            "Epoch 93/100\n",
            "454/454 - 4s - loss: 0.0978 - accuracy: 0.9675\n",
            "Epoch 94/100\n",
            "454/454 - 4s - loss: 0.0881 - accuracy: 0.9697\n",
            "Epoch 95/100\n",
            "454/454 - 4s - loss: 0.0923 - accuracy: 0.9711\n",
            "Epoch 96/100\n",
            "454/454 - 4s - loss: 0.0974 - accuracy: 0.9693\n",
            "Epoch 97/100\n",
            "454/454 - 4s - loss: 0.1001 - accuracy: 0.9638\n",
            "Epoch 98/100\n",
            "454/454 - 4s - loss: 0.0989 - accuracy: 0.9697\n",
            "Epoch 99/100\n",
            "454/454 - 4s - loss: 0.0901 - accuracy: 0.9681\n",
            "Epoch 100/100\n",
            "454/454 - 4s - loss: 0.1052 - accuracy: 0.9663\n",
            ">#1: 36.524\n",
            "Epoch 1/100\n",
            "454/454 - 5s - loss: 1.9735 - accuracy: 0.3478\n",
            "Epoch 2/100\n",
            "454/454 - 4s - loss: 1.6833 - accuracy: 0.3945\n",
            "Epoch 3/100\n",
            "454/454 - 4s - loss: 1.5816 - accuracy: 0.4088\n",
            "Epoch 4/100\n",
            "454/454 - 4s - loss: 1.5273 - accuracy: 0.4254\n",
            "Epoch 5/100\n",
            "454/454 - 4s - loss: 1.4688 - accuracy: 0.4476\n",
            "Epoch 6/100\n",
            "454/454 - 4s - loss: 1.4172 - accuracy: 0.4757\n",
            "Epoch 7/100\n",
            "454/454 - 4s - loss: 1.3142 - accuracy: 0.5065\n",
            "Epoch 8/100\n",
            "454/454 - 4s - loss: 1.2158 - accuracy: 0.5439\n",
            "Epoch 9/100\n",
            "454/454 - 4s - loss: 1.1058 - accuracy: 0.5904\n",
            "Epoch 10/100\n",
            "454/454 - 4s - loss: 1.0031 - accuracy: 0.6309\n",
            "Epoch 11/100\n",
            "454/454 - 4s - loss: 0.8860 - accuracy: 0.6737\n",
            "Epoch 12/100\n",
            "454/454 - 4s - loss: 0.8107 - accuracy: 0.6992\n",
            "Epoch 13/100\n",
            "454/454 - 4s - loss: 0.7069 - accuracy: 0.7363\n",
            "Epoch 14/100\n",
            "454/454 - 4s - loss: 0.6301 - accuracy: 0.7703\n",
            "Epoch 15/100\n",
            "454/454 - 4s - loss: 0.5772 - accuracy: 0.7869\n",
            "Epoch 16/100\n",
            "454/454 - 4s - loss: 0.5185 - accuracy: 0.8119\n",
            "Epoch 17/100\n",
            "454/454 - 4s - loss: 0.4821 - accuracy: 0.8177\n",
            "Epoch 18/100\n",
            "454/454 - 4s - loss: 0.4327 - accuracy: 0.8367\n",
            "Epoch 19/100\n",
            "454/454 - 4s - loss: 0.4029 - accuracy: 0.8488\n",
            "Epoch 20/100\n",
            "454/454 - 4s - loss: 0.3641 - accuracy: 0.8688\n",
            "Epoch 21/100\n",
            "454/454 - 4s - loss: 0.3593 - accuracy: 0.8615\n",
            "Epoch 22/100\n",
            "454/454 - 4s - loss: 0.3283 - accuracy: 0.8777\n",
            "Epoch 23/100\n",
            "454/454 - 4s - loss: 0.3025 - accuracy: 0.8918\n",
            "Epoch 24/100\n",
            "454/454 - 4s - loss: 0.2948 - accuracy: 0.8976\n",
            "Epoch 25/100\n",
            "454/454 - 4s - loss: 0.2944 - accuracy: 0.8926\n",
            "Epoch 26/100\n",
            "454/454 - 4s - loss: 0.2794 - accuracy: 0.9007\n",
            "Epoch 27/100\n",
            "454/454 - 4s - loss: 0.2553 - accuracy: 0.9065\n",
            "Epoch 28/100\n",
            "454/454 - 4s - loss: 0.2468 - accuracy: 0.9115\n",
            "Epoch 29/100\n",
            "454/454 - 4s - loss: 0.2510 - accuracy: 0.9086\n",
            "Epoch 30/100\n",
            "454/454 - 4s - loss: 0.2411 - accuracy: 0.9145\n",
            "Epoch 31/100\n",
            "454/454 - 4s - loss: 0.2285 - accuracy: 0.9195\n",
            "Epoch 32/100\n",
            "454/454 - 4s - loss: 0.2199 - accuracy: 0.9196\n",
            "Epoch 33/100\n",
            "454/454 - 4s - loss: 0.2249 - accuracy: 0.9200\n",
            "Epoch 34/100\n",
            "454/454 - 4s - loss: 0.2173 - accuracy: 0.9222\n",
            "Epoch 35/100\n",
            "454/454 - 4s - loss: 0.1986 - accuracy: 0.9281\n",
            "Epoch 36/100\n",
            "454/454 - 4s - loss: 0.2085 - accuracy: 0.9240\n",
            "Epoch 37/100\n",
            "454/454 - 4s - loss: 0.1891 - accuracy: 0.9354\n",
            "Epoch 38/100\n",
            "454/454 - 4s - loss: 0.1878 - accuracy: 0.9332\n",
            "Epoch 39/100\n",
            "454/454 - 4s - loss: 0.2133 - accuracy: 0.9233\n",
            "Epoch 40/100\n",
            "454/454 - 4s - loss: 0.1847 - accuracy: 0.9375\n",
            "Epoch 41/100\n",
            "454/454 - 4s - loss: 0.1724 - accuracy: 0.9389\n",
            "Epoch 42/100\n",
            "454/454 - 4s - loss: 0.1814 - accuracy: 0.9342\n",
            "Epoch 43/100\n",
            "454/454 - 4s - loss: 0.1905 - accuracy: 0.9332\n",
            "Epoch 44/100\n",
            "454/454 - 4s - loss: 0.1619 - accuracy: 0.9423\n",
            "Epoch 45/100\n",
            "454/454 - 4s - loss: 0.1552 - accuracy: 0.9448\n",
            "Epoch 46/100\n",
            "454/454 - 4s - loss: 0.1692 - accuracy: 0.9429\n",
            "Epoch 47/100\n",
            "454/454 - 4s - loss: 0.1627 - accuracy: 0.9401\n",
            "Epoch 48/100\n",
            "454/454 - 4s - loss: 0.1563 - accuracy: 0.9466\n",
            "Epoch 49/100\n",
            "454/454 - 4s - loss: 0.1638 - accuracy: 0.9423\n",
            "Epoch 50/100\n",
            "454/454 - 4s - loss: 0.1555 - accuracy: 0.9424\n",
            "Epoch 51/100\n",
            "454/454 - 4s - loss: 0.1616 - accuracy: 0.9429\n",
            "Epoch 52/100\n",
            "454/454 - 4s - loss: 0.1415 - accuracy: 0.9502\n",
            "Epoch 53/100\n",
            "454/454 - 4s - loss: 0.1398 - accuracy: 0.9496\n",
            "Epoch 54/100\n",
            "454/454 - 4s - loss: 0.2154 - accuracy: 0.9471\n",
            "Epoch 55/100\n",
            "454/454 - 4s - loss: 0.1484 - accuracy: 0.9456\n",
            "Epoch 56/100\n",
            "454/454 - 4s - loss: 0.1287 - accuracy: 0.9539\n",
            "Epoch 57/100\n",
            "454/454 - 4s - loss: 0.1491 - accuracy: 0.9489\n",
            "Epoch 58/100\n",
            "454/454 - 4s - loss: 0.1372 - accuracy: 0.9522\n",
            "Epoch 59/100\n",
            "454/454 - 4s - loss: 0.1331 - accuracy: 0.9506\n",
            "Epoch 60/100\n",
            "454/454 - 4s - loss: 0.1458 - accuracy: 0.9499\n",
            "Epoch 61/100\n",
            "454/454 - 4s - loss: 0.1283 - accuracy: 0.9537\n",
            "Epoch 62/100\n",
            "454/454 - 4s - loss: 0.1387 - accuracy: 0.9485\n",
            "Epoch 63/100\n",
            "454/454 - 4s - loss: 0.1256 - accuracy: 0.9590\n",
            "Epoch 64/100\n",
            "454/454 - 4s - loss: 0.1193 - accuracy: 0.9568\n",
            "Epoch 65/100\n",
            "454/454 - 4s - loss: 0.1277 - accuracy: 0.9566\n",
            "Epoch 66/100\n",
            "454/454 - 4s - loss: 0.1285 - accuracy: 0.9584\n",
            "Epoch 67/100\n",
            "454/454 - 4s - loss: 0.1182 - accuracy: 0.9595\n",
            "Epoch 68/100\n",
            "454/454 - 4s - loss: 0.1279 - accuracy: 0.9564\n",
            "Epoch 69/100\n",
            "454/454 - 4s - loss: 0.1274 - accuracy: 0.9543\n",
            "Epoch 70/100\n",
            "454/454 - 4s - loss: 0.1326 - accuracy: 0.9542\n",
            "Epoch 71/100\n",
            "454/454 - 4s - loss: 0.1381 - accuracy: 0.9525\n",
            "Epoch 72/100\n",
            "454/454 - 4s - loss: 0.1229 - accuracy: 0.9581\n",
            "Epoch 73/100\n",
            "454/454 - 4s - loss: 0.1109 - accuracy: 0.9630\n",
            "Epoch 74/100\n",
            "454/454 - 4s - loss: 0.1067 - accuracy: 0.9594\n",
            "Epoch 75/100\n",
            "454/454 - 4s - loss: 0.1224 - accuracy: 0.9572\n",
            "Epoch 76/100\n",
            "454/454 - 4s - loss: 0.1148 - accuracy: 0.9610\n",
            "Epoch 77/100\n",
            "454/454 - 4s - loss: 0.1031 - accuracy: 0.9635\n",
            "Epoch 78/100\n",
            "454/454 - 4s - loss: 0.1181 - accuracy: 0.9584\n",
            "Epoch 79/100\n",
            "454/454 - 4s - loss: 0.1013 - accuracy: 0.9646\n",
            "Epoch 80/100\n",
            "454/454 - 4s - loss: 0.1267 - accuracy: 0.9551\n",
            "Epoch 81/100\n",
            "454/454 - 4s - loss: 0.1146 - accuracy: 0.9620\n",
            "Epoch 82/100\n",
            "454/454 - 4s - loss: 0.1199 - accuracy: 0.9608\n",
            "Epoch 83/100\n",
            "454/454 - 4s - loss: 0.1048 - accuracy: 0.9620\n",
            "Epoch 84/100\n",
            "454/454 - 4s - loss: 0.1186 - accuracy: 0.9599\n",
            "Epoch 85/100\n",
            "454/454 - 4s - loss: 0.1446 - accuracy: 0.9613\n",
            "Epoch 86/100\n",
            "454/454 - 4s - loss: 0.1003 - accuracy: 0.9667\n",
            "Epoch 87/100\n",
            "454/454 - 4s - loss: 0.1008 - accuracy: 0.9650\n",
            "Epoch 88/100\n",
            "454/454 - 4s - loss: 0.0901 - accuracy: 0.9700\n",
            "Epoch 89/100\n",
            "454/454 - 4s - loss: 0.1074 - accuracy: 0.9628\n",
            "Epoch 90/100\n",
            "454/454 - 4s - loss: 0.1020 - accuracy: 0.9631\n",
            "Epoch 91/100\n",
            "454/454 - 4s - loss: 0.0984 - accuracy: 0.9652\n",
            "Epoch 92/100\n",
            "454/454 - 4s - loss: 0.1067 - accuracy: 0.9637\n",
            "Epoch 93/100\n",
            "454/454 - 4s - loss: 0.1029 - accuracy: 0.9656\n",
            "Epoch 94/100\n",
            "454/454 - 4s - loss: 0.0995 - accuracy: 0.9649\n",
            "Epoch 95/100\n",
            "454/454 - 4s - loss: 0.1128 - accuracy: 0.9642\n",
            "Epoch 96/100\n",
            "454/454 - 4s - loss: 0.1134 - accuracy: 0.9631\n",
            "Epoch 97/100\n",
            "454/454 - 4s - loss: 0.1023 - accuracy: 0.9645\n",
            "Epoch 98/100\n",
            "454/454 - 4s - loss: 0.0981 - accuracy: 0.9664\n",
            "Epoch 99/100\n",
            "454/454 - 4s - loss: 0.0934 - accuracy: 0.9689\n",
            "Epoch 100/100\n",
            "454/454 - 4s - loss: 0.0834 - accuracy: 0.9714\n",
            ">#2: 35.496\n",
            "[36.52425408363342, 35.49630641937256]\n",
            "Accuracy: 36.010% (+/-0.514)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LTmRsnAsNbP"
      },
      "source": [
        "# Top 20 Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jko5Vz33-rA",
        "outputId": "eab47665-d8f3-4286-94e9-3800d0208e58"
      },
      "source": [
        "#remove rows not in the top 16 types\n",
        "train_df = train_df[train_df['Type'].isin(list(Percentages[:20].index))]\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "994       008DC6  0.088502  0.570442  0.578876  1596723690985  P28A\n",
            "995       008DC6  0.089647  0.570432  0.578902  1596723703073  P28A\n",
            "996       008DC6  0.090028  0.570430  0.578911  1596723717541  P28A\n",
            "997       008DC6  0.090028  0.570430  0.578911  1596723719963  P28A\n",
            "998       008DC6  0.136568  0.570992  0.578782  1596724125875  P28A\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "29550390  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550391  E94C42  0.281147  0.601961  0.315125  1596733935427  B738\n",
            "29550392  E94C42  0.286107  0.601955  0.314975  1596733965728  B738\n",
            "29550393  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "29550394  E94C42  0.301747  0.602027  0.314776  1596734007974  B738\n",
            "\n",
            "[16355352 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwq0kX_M8kxH",
        "outputId": "2bfdcd01-ddf1-4517-8c8c-0238360354b0"
      },
      "source": [
        "type_dict = {k: v for v, k in enumerate(list(Percentages[:20].index))}\n",
        "print(type_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B738': 0, 'A320': 1, 'C172': 2, 'A321': 3, 'B737': 4, 'A319': 5, 'P28A': 6, 'A20N': 7, 'B763': 8, 'B739': 9, 'E75L': 10, 'B752': 11, 'B789': 12, 'B773': 13, 'CRJ9': 14, 'B77L': 15, 'C182': 16, 'PC12': 17, 'E190': 18, 'C208': 19}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Etvofp4RhO3"
      },
      "source": [
        "train_df['Type'].replace(type_dict, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJC8wTMMUNRv",
        "outputId": "8cdac814-5414-4a85-b1ab-47fac072b73e"
      },
      "source": [
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "0         008DC6  0.088502  0.570442  0.578876  1596723690985     6\n",
            "1         008DC6  0.089647  0.570432  0.578902  1596723703073     6\n",
            "2         008DC6  0.090028  0.570430  0.578911  1596723717541     6\n",
            "3         008DC6  0.090028  0.570430  0.578911  1596723719963     6\n",
            "4         008DC6  0.136568  0.570992  0.578782  1596724125875     6\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "16355347  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "16355348  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "16355349  E94C42  0.286107  0.601955  0.314975  1596733965728     0\n",
            "16355350  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "16355351  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "\n",
            "[16355352 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn9J65MLtfnc",
        "outputId": "f02bb4a5-48ef-4aa3-f4f5-dbed293f8800"
      },
      "source": [
        "#turn train dataframe into a multi-dimensional numpy array\n",
        "train_df = np.array(list(train_df.groupby('Icao').apply(pd.DataFrame.to_numpy)))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_count = train_df.shape[0]\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(20391,)\n",
            "20391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMigxKIDtgQr",
        "outputId": "1ff7fc9e-6757-4632-f9af-99034e663244"
      },
      "source": [
        "#load in first dataframe\n",
        "train_input = pd.DataFrame(data = train_df[1], columns = [\"Icao\", \"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "train_input = train_input.set_index('Time')\n",
        "train_input = train_input.drop('PosTime', axis = 1)\n",
        "train_input = train_input.drop('Icao', axis = 1)\n",
        "print(train_input)\n",
        "#Get Species Type\n",
        "unique_species = train_input.Type[0]\n",
        "print(unique_species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                Alt       Lat      Long Type\n",
            "Time                                                        \n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:13:29.760    0.995056  0.540866  0.551703    0\n",
            "2020-08-06 07:13:44.242    0.998108  0.540902  0.551694    0\n",
            "2020-08-06 07:13:56.289  0.00572213  0.540932  0.551686    0\n",
            "...                             ...       ...       ...  ...\n",
            "2020-08-06 16:02:45.713    0.999252   0.54098  0.551676    0\n",
            "2020-08-06 16:02:57.784    0.996963  0.540951  0.551683    0\n",
            "2020-08-06 16:03:55.777    0.994675  0.540866  0.551703    0\n",
            "2020-08-06 16:04:10.278    0.994675  0.540864  0.551703    0\n",
            "2020-08-06 16:04:27.227    0.994675  0.540863  0.551702    0\n",
            "\n",
            "[373 rows x 4 columns]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJypcl3MtrNB",
        "outputId": "d7127886-4fb2-455b-d2b7-12b92afd9562"
      },
      "source": [
        "#Resampling/Interpolating\n",
        "norm_train_df = pd.DataFrame()\n",
        "norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "norm_train_df.reset_index(inplace = True)\n",
        "#norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "norm_train_df = norm_train_df.iloc[0:73]\n",
        "print(norm_train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Time       Lat      Long       Alt\n",
            "0  2020-08-06 07:10:00  0.541109  0.551641  0.026703\n",
            "1  2020-08-06 07:15:00  0.542472  0.552251  0.217823\n",
            "2  2020-08-06 07:20:00  0.544178  0.553254  0.402075\n",
            "3  2020-08-06 07:25:00  0.546072  0.554713  0.501640\n",
            "4  2020-08-06 07:30:00  0.547895  0.556523  0.586328\n",
            "..                 ...       ...       ...       ...\n",
            "68 2020-08-06 12:50:00  0.575555  0.585123 -1.378310\n",
            "69 2020-08-06 12:55:00  0.575441  0.584925 -1.338937\n",
            "70 2020-08-06 13:00:00  0.575300  0.584686 -1.292159\n",
            "71 2020-08-06 13:05:00  0.575129  0.584407 -1.237701\n",
            "72 2020-08-06 13:10:00  0.574928  0.584084 -1.175291\n",
            "\n",
            "[73 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK12mXzdttxC",
        "outputId": "6cf707be-c615-49b7-853f-225f04ad78a7"
      },
      "source": [
        "#add species to label list\n",
        "train_labels = []\n",
        "train_labels.append(unique_species)\n",
        "print(train_labels)\n",
        "#convert dataframe to numpy\n",
        "norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "norm_train_df = norm_train_df.to_numpy()\n",
        "print(norm_train_df)\n",
        "final_input_train = norm_train_df\n",
        "print(final_input_train.shape)\n",
        "final_input_train = np.reshape(final_input_train, (1,73,3))\n",
        "print(final_input_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[ 0.54110926  0.55164051  0.02670329]\n",
            " [ 0.54247236  0.55225104  0.21782254]\n",
            " [ 0.54417837  0.55325353  0.40207523]\n",
            " [ 0.54607177  0.55471271  0.50164034]\n",
            " [ 0.54789543  0.5565232   0.58632792]\n",
            " [ 0.54969102  0.55826527  0.59510185]\n",
            " [ 0.55004507  0.55860418  0.59510185]\n",
            " [ 0.55061809  0.55913722  0.60817557]\n",
            " [ 0.55184827  0.56027639  0.62872997]\n",
            " [ 0.55359598  0.56188938  0.65039623]\n",
            " [ 0.55572157  0.5638439   0.66680553]\n",
            " [ 0.55808541  0.56600764  0.67158908]\n",
            " [ 0.56054785  0.56824831  0.65837804]\n",
            " [ 0.56296924  0.5704336   0.62080362]\n",
            " [ 0.56520995  0.57243121  0.55249699]\n",
            " [ 0.56713033  0.57410884  0.44708934]\n",
            " [ 0.56859511  0.57544625  0.30861372]\n",
            " [ 0.56961566  0.57667202  0.17662318]\n",
            " [ 0.57040614  0.5773856   0.08812085]\n",
            " [ 0.57044345  0.57741934  0.08392462]\n",
            " [ 0.57031141  0.57733422  0.09457798]\n",
            " [ 0.57020701  0.57728254  0.09927008]\n",
            " [ 0.57012913  0.57726283  0.09827373]\n",
            " [ 0.57007663  0.57727358  0.09186173]\n",
            " [ 0.57004836  0.5773133   0.0803069 ]\n",
            " [ 0.5700432   0.57738052  0.06388204]\n",
            " [ 0.57006001  0.57747373  0.04285995]\n",
            " [ 0.57009765  0.57759144  0.01751345]\n",
            " [ 0.57015498  0.57773217 -0.01188467]\n",
            " [ 0.57023088  0.57789442 -0.04506159]\n",
            " [ 0.5703242   0.57807671 -0.08174451]\n",
            " [ 0.5704338   0.57827755 -0.12166062]\n",
            " [ 0.57055856  0.57849543 -0.16453711]\n",
            " [ 0.57069733  0.57872888 -0.21010118]\n",
            " [ 0.57084898  0.5789764  -0.25808002]\n",
            " [ 0.57101237  0.5792365  -0.30820083]\n",
            " [ 0.57118636  0.5795077  -0.36019079]\n",
            " [ 0.57136983  0.57978849 -0.41377711]\n",
            " [ 0.57156163  0.5800774  -0.46868697]\n",
            " [ 0.57176063  0.58037292 -0.52464756]\n",
            " [ 0.57196568  0.58067358 -0.58138609]\n",
            " [ 0.57217567  0.58097787 -0.63862974]\n",
            " [ 0.57238944  0.58128432 -0.69610571]\n",
            " [ 0.57260586  0.58159142 -0.75354119]\n",
            " [ 0.5728238   0.58189769 -0.81066338]\n",
            " [ 0.57304211  0.58220164 -0.86719946]\n",
            " [ 0.57325968  0.58250177 -0.92287663]\n",
            " [ 0.57347534  0.58279661 -0.97742209]\n",
            " [ 0.57368798  0.58308465 -1.03056303]\n",
            " [ 0.57389646  0.5833644  -1.08202663]\n",
            " [ 0.57409963  0.58363438 -1.1315401 ]\n",
            " [ 0.57429636  0.5838931  -1.17883063]\n",
            " [ 0.57448553  0.58413906 -1.22362541]\n",
            " [ 0.57466598  0.58437077 -1.26565163]\n",
            " [ 0.57483658  0.58458675 -1.30463649]\n",
            " [ 0.5749962   0.5847855  -1.34030718]\n",
            " [ 0.5751437   0.58496553 -1.3723909 ]\n",
            " [ 0.57527795  0.58512536 -1.40061483]\n",
            " [ 0.57539781  0.58526349 -1.42470618]\n",
            " [ 0.57550214  0.58537843 -1.44439212]\n",
            " [ 0.5755898   0.58546869 -1.45939987]\n",
            " [ 0.57565966  0.58553279 -1.46945661]\n",
            " [ 0.57571059  0.58556922 -1.47428953]\n",
            " [ 0.57574145  0.5855765  -1.47362583]\n",
            " [ 0.57575109  0.58555314 -1.4671927 ]\n",
            " [ 0.57573839  0.58549765 -1.45471733]\n",
            " [ 0.57570221  0.58540854 -1.43592692]\n",
            " [ 0.57564142  0.58528432 -1.41054866]\n",
            " [ 0.57555487  0.5851235  -1.37830975]\n",
            " [ 0.57544142  0.58492458 -1.33893737]\n",
            " [ 0.57529996  0.58468608 -1.29215873]\n",
            " [ 0.57512933  0.58440651 -1.23770101]\n",
            " [ 0.5749284   0.58408437 -1.1752914 ]]\n",
            "(73, 3)\n",
            "(1, 73, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZQI2wdRtu4X",
        "outputId": "57b1863b-9001-4b8d-e30e-e2efa240c592"
      },
      "source": [
        "for j in range(2,20391):\n",
        "    try:\n",
        "        train_input = pd.DataFrame(data = train_df[j], columns = [\"Icao\",\"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "        train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "        train_input = train_input.set_index('Time')\n",
        "        train_input = train_input.drop('PosTime', axis = 1)\n",
        "        unique_species = train_input.Type[0]\n",
        "        norm_train_df = pd.DataFrame()\n",
        "        norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "        norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "        norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "        norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "        norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "        norm_train_df.reset_index(inplace = True)\n",
        "        #norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "        norm_train_df = norm_train_df.iloc[0:73]\n",
        "        norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "        norm_train_df = norm_train_df.to_numpy()\n",
        "        norm_train_df = np.reshape(norm_train_df, (1,73,3))\n",
        "        final_input_train = np.append(final_input_train, norm_train_df, axis = 0)\n",
        "        train_labels.append(unique_species)\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "print(final_input_train.shape)\n",
        "print(len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12878, 73, 3)\n",
            "12878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaV47EbdtycZ",
        "outputId": "df48774a-6a73-4405-c12d-47c3d36efb8d"
      },
      "source": [
        "final_input_test = final_input_train[9014:]\n",
        "arr = list(range(9014,final_input_train.shape[0] ))\n",
        "print(final_input_test.shape)\n",
        "\n",
        "final_input_train = np.delete(final_input_train, arr, 0)\n",
        "print(final_input_train.shape)\n",
        "\n",
        "test_labels = train_labels[9014:]\n",
        "print(len(test_labels))\n",
        "\n",
        "train_labels_final = train_labels[:9014]\n",
        "print(len(train_labels_final))\n",
        "\n",
        "unique = list(dict.fromkeys(test_labels))\n",
        "unique2 = list(dict.fromkeys(train_labels_final))\n",
        "print(unique)\n",
        "print(unique2)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "test_labels = to_categorical(test_labels,num_classes = 20)\n",
        "train_labels_final = to_categorical(train_labels_final,num_classes = 20)\n",
        "print(len(test_labels))\n",
        "print(len(train_labels_final))\n",
        "\n",
        "train_labels_final = np.array(train_labels_final)\n",
        "test_labels = np.array(test_labels)\n",
        "print(train_labels_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3864, 73, 3)\n",
            "(9014, 73, 3)\n",
            "3864\n",
            "9014\n",
            "[4, 2, 17, 1, 11, 19, 6, 9, 14, 16, 0, 5, 3, 7, 8, 10, 15, 12, 13, 18]\n",
            "[0, 18, 1, 17, 13, 5, 12, 14, 7, 4, 15, 19, 3, 6, 11, 2, 16, 8, 9, 10]\n",
            "3864\n",
            "9014\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xmgX-xluD_N",
        "outputId": "fb907aca-6a46-4096-8486-8816b0c54018"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(final_input_train, train_labels_final, final_input_test, test_labels):\n",
        "    verbose, epochs, batch_size = 2, 100, 16\n",
        "    n_timesteps, n_features, n_outputs = final_input_train.shape[1], final_input_train.shape[2], 20\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # fit network\n",
        "    model.fit(final_input_train, train_labels_final, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle = True)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(final_input_test, test_labels, batch_size=batch_size, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "    print(scores)\n",
        "    m, s = np.mean(scores), np.std(scores)\n",
        "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats=2):\n",
        "    # load data\n",
        "    # repeat experiment\n",
        "    scores = list()\n",
        "    for r in range(repeats):\n",
        "        score = evaluate_model(final_input_train, train_labels_final, final_input_test, test_labels)\n",
        "        score = score * 100.0\n",
        "        print('>#%d: %.3f' % (r+1, score))\n",
        "        scores.append(score)\n",
        "    # summarize results\n",
        "    summarize_results(scores)\n",
        "\n",
        "run_experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "564/564 - 5s - loss: 2.4051 - accuracy: 0.3046\n",
            "Epoch 2/100\n",
            "564/564 - 4s - loss: 2.0522 - accuracy: 0.3315\n",
            "Epoch 3/100\n",
            "564/564 - 4s - loss: 1.9878 - accuracy: 0.3424\n",
            "Epoch 4/100\n",
            "564/564 - 4s - loss: 1.9456 - accuracy: 0.3590\n",
            "Epoch 5/100\n",
            "564/564 - 4s - loss: 1.9361 - accuracy: 0.3643\n",
            "Epoch 6/100\n",
            "564/564 - 4s - loss: 1.8960 - accuracy: 0.3720\n",
            "Epoch 7/100\n",
            "564/564 - 4s - loss: 1.8675 - accuracy: 0.3719\n",
            "Epoch 8/100\n",
            "564/564 - 4s - loss: 1.8491 - accuracy: 0.3759\n",
            "Epoch 9/100\n",
            "564/564 - 4s - loss: 1.8211 - accuracy: 0.3815\n",
            "Epoch 10/100\n",
            "564/564 - 4s - loss: 1.7999 - accuracy: 0.3833\n",
            "Epoch 11/100\n",
            "564/564 - 4s - loss: 1.7643 - accuracy: 0.3915\n",
            "Epoch 12/100\n",
            "564/564 - 4s - loss: 1.7371 - accuracy: 0.3993\n",
            "Epoch 13/100\n",
            "564/564 - 4s - loss: 1.7136 - accuracy: 0.4004\n",
            "Epoch 14/100\n",
            "564/564 - 4s - loss: 1.6762 - accuracy: 0.4175\n",
            "Epoch 15/100\n",
            "564/564 - 4s - loss: 1.6436 - accuracy: 0.4220\n",
            "Epoch 16/100\n",
            "564/564 - 4s - loss: 1.6074 - accuracy: 0.4373\n",
            "Epoch 17/100\n",
            "564/564 - 4s - loss: 1.5855 - accuracy: 0.4380\n",
            "Epoch 18/100\n",
            "564/564 - 4s - loss: 1.5483 - accuracy: 0.4509\n",
            "Epoch 19/100\n",
            "564/564 - 4s - loss: 1.5304 - accuracy: 0.4509\n",
            "Epoch 20/100\n",
            "564/564 - 4s - loss: 1.5018 - accuracy: 0.4707\n",
            "Epoch 21/100\n",
            "564/564 - 4s - loss: 1.4759 - accuracy: 0.4751\n",
            "Epoch 22/100\n",
            "564/564 - 4s - loss: 1.4426 - accuracy: 0.4836\n",
            "Epoch 23/100\n",
            "564/564 - 4s - loss: 1.4234 - accuracy: 0.4879\n",
            "Epoch 24/100\n",
            "564/564 - 4s - loss: 1.3994 - accuracy: 0.5009\n",
            "Epoch 25/100\n",
            "564/564 - 4s - loss: 1.3807 - accuracy: 0.5051\n",
            "Epoch 26/100\n",
            "564/564 - 4s - loss: 1.3522 - accuracy: 0.5146\n",
            "Epoch 27/100\n",
            "564/564 - 4s - loss: 1.3283 - accuracy: 0.5193\n",
            "Epoch 28/100\n",
            "564/564 - 4s - loss: 1.3205 - accuracy: 0.5236\n",
            "Epoch 29/100\n",
            "564/564 - 4s - loss: 1.2880 - accuracy: 0.5314\n",
            "Epoch 30/100\n",
            "564/564 - 4s - loss: 1.2681 - accuracy: 0.5458\n",
            "Epoch 31/100\n",
            "564/564 - 4s - loss: 1.2399 - accuracy: 0.5496\n",
            "Epoch 32/100\n",
            "564/564 - 4s - loss: 1.2298 - accuracy: 0.5552\n",
            "Epoch 33/100\n",
            "564/564 - 4s - loss: 1.2072 - accuracy: 0.5572\n",
            "Epoch 34/100\n",
            "564/564 - 4s - loss: 1.2190 - accuracy: 0.5586\n",
            "Epoch 35/100\n",
            "564/564 - 4s - loss: 1.1880 - accuracy: 0.5650\n",
            "Epoch 36/100\n",
            "564/564 - 4s - loss: 1.1876 - accuracy: 0.5728\n",
            "Epoch 37/100\n",
            "564/564 - 4s - loss: 1.1332 - accuracy: 0.5848\n",
            "Epoch 38/100\n",
            "564/564 - 4s - loss: 1.1339 - accuracy: 0.5810\n",
            "Epoch 39/100\n",
            "564/564 - 4s - loss: 1.1148 - accuracy: 0.5892\n",
            "Epoch 40/100\n",
            "564/564 - 4s - loss: 1.1081 - accuracy: 0.5896\n",
            "Epoch 41/100\n",
            "564/564 - 4s - loss: 1.0823 - accuracy: 0.6015\n",
            "Epoch 42/100\n",
            "564/564 - 4s - loss: 1.0683 - accuracy: 0.6113\n",
            "Epoch 43/100\n",
            "564/564 - 4s - loss: 1.0645 - accuracy: 0.6098\n",
            "Epoch 44/100\n",
            "564/564 - 4s - loss: 1.0606 - accuracy: 0.6045\n",
            "Epoch 45/100\n",
            "564/564 - 4s - loss: 1.0564 - accuracy: 0.6122\n",
            "Epoch 46/100\n",
            "564/564 - 4s - loss: 1.0255 - accuracy: 0.6188\n",
            "Epoch 47/100\n",
            "564/564 - 4s - loss: 1.0257 - accuracy: 0.6189\n",
            "Epoch 48/100\n",
            "564/564 - 4s - loss: 1.0146 - accuracy: 0.6214\n",
            "Epoch 49/100\n",
            "564/564 - 4s - loss: 0.9966 - accuracy: 0.6284\n",
            "Epoch 50/100\n",
            "564/564 - 4s - loss: 0.9863 - accuracy: 0.6291\n",
            "Epoch 51/100\n",
            "564/564 - 4s - loss: 0.9848 - accuracy: 0.6358\n",
            "Epoch 52/100\n",
            "564/564 - 4s - loss: 0.9728 - accuracy: 0.6333\n",
            "Epoch 53/100\n",
            "564/564 - 4s - loss: 0.9626 - accuracy: 0.6463\n",
            "Epoch 54/100\n",
            "564/564 - 4s - loss: 0.9405 - accuracy: 0.6518\n",
            "Epoch 55/100\n",
            "564/564 - 4s - loss: 0.9444 - accuracy: 0.6492\n",
            "Epoch 56/100\n",
            "564/564 - 4s - loss: 0.9377 - accuracy: 0.6533\n",
            "Epoch 57/100\n",
            "564/564 - 4s - loss: 0.9193 - accuracy: 0.6529\n",
            "Epoch 58/100\n",
            "564/564 - 4s - loss: 0.9091 - accuracy: 0.6616\n",
            "Epoch 59/100\n",
            "564/564 - 4s - loss: 0.8955 - accuracy: 0.6684\n",
            "Epoch 60/100\n",
            "564/564 - 4s - loss: 0.9032 - accuracy: 0.6626\n",
            "Epoch 61/100\n",
            "564/564 - 4s - loss: 0.8914 - accuracy: 0.6680\n",
            "Epoch 62/100\n",
            "564/564 - 4s - loss: 0.8882 - accuracy: 0.6691\n",
            "Epoch 63/100\n",
            "564/564 - 4s - loss: 0.8845 - accuracy: 0.6692\n",
            "Epoch 64/100\n",
            "564/564 - 4s - loss: 0.8715 - accuracy: 0.6725\n",
            "Epoch 65/100\n",
            "564/564 - 4s - loss: 0.8578 - accuracy: 0.6753\n",
            "Epoch 66/100\n",
            "564/564 - 4s - loss: 0.8628 - accuracy: 0.6697\n",
            "Epoch 67/100\n",
            "564/564 - 4s - loss: 0.8569 - accuracy: 0.6807\n",
            "Epoch 68/100\n",
            "564/564 - 4s - loss: 0.8587 - accuracy: 0.6757\n",
            "Epoch 69/100\n",
            "564/564 - 4s - loss: 0.8238 - accuracy: 0.6908\n",
            "Epoch 70/100\n",
            "564/564 - 4s - loss: 0.8343 - accuracy: 0.6865\n",
            "Epoch 71/100\n",
            "564/564 - 4s - loss: 0.8227 - accuracy: 0.6976\n",
            "Epoch 72/100\n",
            "564/564 - 4s - loss: 0.8168 - accuracy: 0.6925\n",
            "Epoch 73/100\n",
            "564/564 - 4s - loss: 0.8138 - accuracy: 0.6943\n",
            "Epoch 74/100\n",
            "564/564 - 4s - loss: 0.8205 - accuracy: 0.6906\n",
            "Epoch 75/100\n",
            "564/564 - 4s - loss: 0.7887 - accuracy: 0.7020\n",
            "Epoch 76/100\n",
            "564/564 - 4s - loss: 0.7885 - accuracy: 0.7020\n",
            "Epoch 77/100\n",
            "564/564 - 4s - loss: 0.7953 - accuracy: 0.7035\n",
            "Epoch 78/100\n",
            "564/564 - 4s - loss: 0.7776 - accuracy: 0.7103\n",
            "Epoch 79/100\n",
            "564/564 - 4s - loss: 0.7775 - accuracy: 0.7109\n",
            "Epoch 80/100\n",
            "564/564 - 4s - loss: 0.7671 - accuracy: 0.7148\n",
            "Epoch 81/100\n",
            "564/564 - 4s - loss: 0.7829 - accuracy: 0.7025\n",
            "Epoch 82/100\n",
            "564/564 - 4s - loss: 0.7660 - accuracy: 0.7120\n",
            "Epoch 83/100\n",
            "564/564 - 4s - loss: 0.7581 - accuracy: 0.7116\n",
            "Epoch 84/100\n",
            "564/564 - 4s - loss: 0.7646 - accuracy: 0.7143\n",
            "Epoch 85/100\n",
            "564/564 - 4s - loss: 0.7487 - accuracy: 0.7180\n",
            "Epoch 86/100\n",
            "564/564 - 4s - loss: 0.7336 - accuracy: 0.7192\n",
            "Epoch 87/100\n",
            "564/564 - 4s - loss: 0.7384 - accuracy: 0.7201\n",
            "Epoch 88/100\n",
            "564/564 - 4s - loss: 0.7372 - accuracy: 0.7237\n",
            "Epoch 89/100\n",
            "564/564 - 4s - loss: 0.7383 - accuracy: 0.7208\n",
            "Epoch 90/100\n",
            "564/564 - 4s - loss: 0.7211 - accuracy: 0.7285\n",
            "Epoch 91/100\n",
            "564/564 - 4s - loss: 0.7413 - accuracy: 0.7228\n",
            "Epoch 92/100\n",
            "564/564 - 4s - loss: 0.7091 - accuracy: 0.7352\n",
            "Epoch 93/100\n",
            "564/564 - 4s - loss: 0.7176 - accuracy: 0.7295\n",
            "Epoch 94/100\n",
            "564/564 - 4s - loss: 0.6961 - accuracy: 0.7423\n",
            "Epoch 95/100\n",
            "564/564 - 4s - loss: 0.7059 - accuracy: 0.7332\n",
            "Epoch 96/100\n",
            "564/564 - 4s - loss: 0.6941 - accuracy: 0.7347\n",
            "Epoch 97/100\n",
            "564/564 - 4s - loss: 0.7001 - accuracy: 0.7332\n",
            "Epoch 98/100\n",
            "564/564 - 4s - loss: 0.6796 - accuracy: 0.7397\n",
            "Epoch 99/100\n",
            "564/564 - 4s - loss: 0.7014 - accuracy: 0.7382\n",
            "Epoch 100/100\n",
            "564/564 - 4s - loss: 0.6833 - accuracy: 0.7454\n",
            ">#1: 33.773\n",
            "Epoch 1/100\n",
            "564/564 - 5s - loss: 2.3211 - accuracy: 0.2995\n",
            "Epoch 2/100\n",
            "564/564 - 4s - loss: 2.0310 - accuracy: 0.3422\n",
            "Epoch 3/100\n",
            "564/564 - 4s - loss: 1.9743 - accuracy: 0.3523\n",
            "Epoch 4/100\n",
            "564/564 - 4s - loss: 1.9317 - accuracy: 0.3559\n",
            "Epoch 5/100\n",
            "564/564 - 4s - loss: 1.8927 - accuracy: 0.3618\n",
            "Epoch 6/100\n",
            "564/564 - 5s - loss: 1.8734 - accuracy: 0.3683\n",
            "Epoch 7/100\n",
            "564/564 - 4s - loss: 1.8519 - accuracy: 0.3695\n",
            "Epoch 8/100\n",
            "564/564 - 4s - loss: 1.8270 - accuracy: 0.3729\n",
            "Epoch 9/100\n",
            "564/564 - 4s - loss: 1.8038 - accuracy: 0.3790\n",
            "Epoch 10/100\n",
            "564/564 - 4s - loss: 1.8097 - accuracy: 0.3873\n",
            "Epoch 11/100\n",
            "564/564 - 4s - loss: 1.7473 - accuracy: 0.3936\n",
            "Epoch 12/100\n",
            "564/564 - 4s - loss: 1.7263 - accuracy: 0.4004\n",
            "Epoch 13/100\n",
            "564/564 - 4s - loss: 1.7031 - accuracy: 0.4050\n",
            "Epoch 14/100\n",
            "564/564 - 4s - loss: 1.6760 - accuracy: 0.4141\n",
            "Epoch 15/100\n",
            "564/564 - 4s - loss: 1.6587 - accuracy: 0.4257\n",
            "Epoch 16/100\n",
            "564/564 - 4s - loss: 1.6118 - accuracy: 0.4277\n",
            "Epoch 17/100\n",
            "564/564 - 4s - loss: 1.5776 - accuracy: 0.4429\n",
            "Epoch 18/100\n",
            "564/564 - 4s - loss: 1.5561 - accuracy: 0.4499\n",
            "Epoch 19/100\n",
            "564/564 - 4s - loss: 1.5315 - accuracy: 0.4571\n",
            "Epoch 20/100\n",
            "564/564 - 4s - loss: 1.5005 - accuracy: 0.4614\n",
            "Epoch 21/100\n",
            "564/564 - 4s - loss: 1.4814 - accuracy: 0.4744\n",
            "Epoch 22/100\n",
            "564/564 - 4s - loss: 1.4531 - accuracy: 0.4759\n",
            "Epoch 23/100\n",
            "564/564 - 4s - loss: 1.4291 - accuracy: 0.4927\n",
            "Epoch 24/100\n",
            "564/564 - 4s - loss: 1.4012 - accuracy: 0.4970\n",
            "Epoch 25/100\n",
            "564/564 - 4s - loss: 1.3739 - accuracy: 0.5049\n",
            "Epoch 26/100\n",
            "564/564 - 4s - loss: 1.3713 - accuracy: 0.5040\n",
            "Epoch 27/100\n",
            "564/564 - 4s - loss: 1.3467 - accuracy: 0.5163\n",
            "Epoch 28/100\n",
            "564/564 - 4s - loss: 1.3149 - accuracy: 0.5258\n",
            "Epoch 29/100\n",
            "564/564 - 4s - loss: 1.3013 - accuracy: 0.5253\n",
            "Epoch 30/100\n",
            "564/564 - 4s - loss: 1.2796 - accuracy: 0.5398\n",
            "Epoch 31/100\n",
            "564/564 - 4s - loss: 1.2661 - accuracy: 0.5375\n",
            "Epoch 32/100\n",
            "564/564 - 4s - loss: 1.2360 - accuracy: 0.5462\n",
            "Epoch 33/100\n",
            "564/564 - 4s - loss: 1.2210 - accuracy: 0.5524\n",
            "Epoch 34/100\n",
            "564/564 - 4s - loss: 1.2051 - accuracy: 0.5565\n",
            "Epoch 35/100\n",
            "564/564 - 4s - loss: 1.1860 - accuracy: 0.5650\n",
            "Epoch 36/100\n",
            "564/564 - 4s - loss: 1.1817 - accuracy: 0.5707\n",
            "Epoch 37/100\n",
            "564/564 - 4s - loss: 1.1578 - accuracy: 0.5764\n",
            "Epoch 38/100\n",
            "564/564 - 4s - loss: 1.1434 - accuracy: 0.5724\n",
            "Epoch 39/100\n",
            "564/564 - 4s - loss: 1.1343 - accuracy: 0.5832\n",
            "Epoch 40/100\n",
            "564/564 - 4s - loss: 1.1325 - accuracy: 0.5883\n",
            "Epoch 41/100\n",
            "564/564 - 4s - loss: 1.1138 - accuracy: 0.5939\n",
            "Epoch 42/100\n",
            "564/564 - 4s - loss: 1.0992 - accuracy: 0.5926\n",
            "Epoch 43/100\n",
            "564/564 - 4s - loss: 1.0694 - accuracy: 0.5982\n",
            "Epoch 44/100\n",
            "564/564 - 4s - loss: 1.0727 - accuracy: 0.6014\n",
            "Epoch 45/100\n",
            "564/564 - 4s - loss: 1.0711 - accuracy: 0.6026\n",
            "Epoch 46/100\n",
            "564/564 - 4s - loss: 1.0294 - accuracy: 0.6154\n",
            "Epoch 47/100\n",
            "564/564 - 4s - loss: 1.0356 - accuracy: 0.6123\n",
            "Epoch 48/100\n",
            "564/564 - 4s - loss: 1.0141 - accuracy: 0.6209\n",
            "Epoch 49/100\n",
            "564/564 - 4s - loss: 1.0022 - accuracy: 0.6262\n",
            "Epoch 50/100\n",
            "564/564 - 4s - loss: 0.9976 - accuracy: 0.6229\n",
            "Epoch 51/100\n",
            "564/564 - 4s - loss: 0.9771 - accuracy: 0.6343\n",
            "Epoch 52/100\n",
            "564/564 - 4s - loss: 0.9822 - accuracy: 0.6305\n",
            "Epoch 53/100\n",
            "564/564 - 4s - loss: 0.9704 - accuracy: 0.6355\n",
            "Epoch 54/100\n",
            "564/564 - 4s - loss: 0.9560 - accuracy: 0.6411\n",
            "Epoch 55/100\n",
            "564/564 - 4s - loss: 0.9471 - accuracy: 0.6454\n",
            "Epoch 56/100\n",
            "564/564 - 4s - loss: 0.9346 - accuracy: 0.6517\n",
            "Epoch 57/100\n",
            "564/564 - 4s - loss: 0.9188 - accuracy: 0.6604\n",
            "Epoch 58/100\n",
            "564/564 - 4s - loss: 0.9202 - accuracy: 0.6552\n",
            "Epoch 59/100\n",
            "564/564 - 4s - loss: 0.8963 - accuracy: 0.6659\n",
            "Epoch 60/100\n",
            "564/564 - 4s - loss: 0.9038 - accuracy: 0.6636\n",
            "Epoch 61/100\n",
            "564/564 - 4s - loss: 0.8984 - accuracy: 0.6669\n",
            "Epoch 62/100\n",
            "564/564 - 4s - loss: 0.8930 - accuracy: 0.6615\n",
            "Epoch 63/100\n",
            "564/564 - 4s - loss: 0.8540 - accuracy: 0.6797\n",
            "Epoch 64/100\n",
            "564/564 - 4s - loss: 0.8683 - accuracy: 0.6765\n",
            "Epoch 65/100\n",
            "564/564 - 4s - loss: 0.8544 - accuracy: 0.6785\n",
            "Epoch 66/100\n",
            "564/564 - 4s - loss: 0.8594 - accuracy: 0.6757\n",
            "Epoch 67/100\n",
            "564/564 - 4s - loss: 0.8543 - accuracy: 0.6798\n",
            "Epoch 68/100\n",
            "564/564 - 4s - loss: 0.8459 - accuracy: 0.6843\n",
            "Epoch 69/100\n",
            "564/564 - 4s - loss: 0.8479 - accuracy: 0.6824\n",
            "Epoch 70/100\n",
            "564/564 - 4s - loss: 0.8314 - accuracy: 0.6905\n",
            "Epoch 71/100\n",
            "564/564 - 4s - loss: 0.8141 - accuracy: 0.6940\n",
            "Epoch 72/100\n",
            "564/564 - 4s - loss: 0.8270 - accuracy: 0.6877\n",
            "Epoch 73/100\n",
            "564/564 - 4s - loss: 0.7976 - accuracy: 0.6979\n",
            "Epoch 74/100\n",
            "564/564 - 4s - loss: 0.7901 - accuracy: 0.7051\n",
            "Epoch 75/100\n",
            "564/564 - 4s - loss: 0.7952 - accuracy: 0.6981\n",
            "Epoch 76/100\n",
            "564/564 - 4s - loss: 0.7839 - accuracy: 0.7020\n",
            "Epoch 77/100\n",
            "564/564 - 4s - loss: 0.7857 - accuracy: 0.7068\n",
            "Epoch 78/100\n",
            "564/564 - 4s - loss: 0.7797 - accuracy: 0.7069\n",
            "Epoch 79/100\n",
            "564/564 - 4s - loss: 0.7681 - accuracy: 0.7086\n",
            "Epoch 80/100\n",
            "564/564 - 4s - loss: 0.7636 - accuracy: 0.7049\n",
            "Epoch 81/100\n",
            "564/564 - 4s - loss: 0.7510 - accuracy: 0.7143\n",
            "Epoch 82/100\n",
            "564/564 - 4s - loss: 0.7471 - accuracy: 0.7168\n",
            "Epoch 83/100\n",
            "564/564 - 4s - loss: 0.7403 - accuracy: 0.7222\n",
            "Epoch 84/100\n",
            "564/564 - 4s - loss: 0.7425 - accuracy: 0.7230\n",
            "Epoch 85/100\n",
            "564/564 - 4s - loss: 0.7292 - accuracy: 0.7290\n",
            "Epoch 86/100\n",
            "564/564 - 4s - loss: 0.7387 - accuracy: 0.7220\n",
            "Epoch 87/100\n",
            "564/564 - 4s - loss: 0.7325 - accuracy: 0.7212\n",
            "Epoch 88/100\n",
            "564/564 - 4s - loss: 0.7220 - accuracy: 0.7269\n",
            "Epoch 89/100\n",
            "564/564 - 4s - loss: 0.7238 - accuracy: 0.7238\n",
            "Epoch 90/100\n",
            "564/564 - 4s - loss: 0.7001 - accuracy: 0.7349\n",
            "Epoch 91/100\n",
            "564/564 - 4s - loss: 0.7118 - accuracy: 0.7303\n",
            "Epoch 92/100\n",
            "564/564 - 4s - loss: 0.6951 - accuracy: 0.7366\n",
            "Epoch 93/100\n",
            "564/564 - 4s - loss: 0.7047 - accuracy: 0.7341\n",
            "Epoch 94/100\n",
            "564/564 - 4s - loss: 0.6831 - accuracy: 0.7432\n",
            "Epoch 95/100\n",
            "564/564 - 4s - loss: 0.6843 - accuracy: 0.7440\n",
            "Epoch 96/100\n",
            "564/564 - 4s - loss: 0.7067 - accuracy: 0.7373\n",
            "Epoch 97/100\n",
            "564/564 - 4s - loss: 0.6774 - accuracy: 0.7443\n",
            "Epoch 98/100\n",
            "564/564 - 4s - loss: 0.6775 - accuracy: 0.7440\n",
            "Epoch 99/100\n",
            "564/564 - 4s - loss: 0.6665 - accuracy: 0.7450\n",
            "Epoch 100/100\n",
            "564/564 - 4s - loss: 0.6748 - accuracy: 0.7482\n",
            ">#2: 34.731\n",
            "[33.77329111099243, 34.7308486700058]\n",
            "Accuracy: 34.252% (+/-0.479)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA484-i0GIhl"
      },
      "source": [
        "# Top 25 Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqbb8RvR3NjY"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZUiM7pj3PAl"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "rgAVnUAFGIhx",
        "outputId": "e335f8cf-2db3-4d26-afae-949e28625ade"
      },
      "source": [
        "#remove rows not in the top 16 types\n",
        "train_df = train_df[train_df['Type'].isin(list(Percentages[:25].index))]\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-57b5395d0e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#remove rows not in the top 16 types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPercentages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EPCnAbLGIh0",
        "outputId": "9514da73-9de1-4649-9332-6908efc1a2e5"
      },
      "source": [
        "type_dict = {k: v for v, k in enumerate(list(Percentages[:25].index))}\n",
        "print(type_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B738': 0, 'A320': 1, 'C172': 2, 'A321': 3, 'B737': 4, 'A319': 5, 'P28A': 6, 'A20N': 7, 'B763': 8, 'B739': 9, 'E75L': 10, 'B752': 11, 'B789': 12, 'B773': 13, 'CRJ9': 14, 'B77L': 15, 'C182': 16, 'PC12': 17, 'E190': 18, 'C208': 19, 'B744': 20, 'A333': 21, 'A21N': 22, 'BE20': 23, 'E170': 24}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ZWt251GIh5"
      },
      "source": [
        "train_df['Type'].replace(type_dict, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EjJaTdjGIh6",
        "outputId": "6c519ebe-a11e-49b1-d2d6-4b6ada4bf5b6"
      },
      "source": [
        "train_df = train_df.reset_index(drop = True)\n",
        "print(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Icao       Alt       Lat      Long        PosTime  Type\n",
            "0         008DC6  0.088502  0.570442  0.578876  1596723690985     6\n",
            "1         008DC6  0.089647  0.570432  0.578902  1596723703073     6\n",
            "2         008DC6  0.090028  0.570430  0.578911  1596723717541     6\n",
            "3         008DC6  0.090028  0.570430  0.578911  1596723719963     6\n",
            "4         008DC6  0.136568  0.570992  0.578782  1596724125875     6\n",
            "...          ...       ...       ...       ...            ...   ...\n",
            "17503879  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "17503880  E94C42  0.281147  0.601961  0.315125  1596733935427     0\n",
            "17503881  E94C42  0.286107  0.601955  0.314975  1596733965728     0\n",
            "17503882  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "17503883  E94C42  0.301747  0.602027  0.314776  1596734007974     0\n",
            "\n",
            "[17503884 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6Q_BQ2PGIh7",
        "outputId": "80e3dbfb-da90-4035-cc4b-07f7367fb5f0"
      },
      "source": [
        "#turn train dataframe into a multi-dimensional numpy array\n",
        "train_df = np.array(list(train_df.groupby('Icao').apply(pd.DataFrame.to_numpy)))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_count = train_df.shape[0]\n",
        "print(train_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(21745,)\n",
            "21745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O72wzu3lGIh8",
        "outputId": "7bfb4fe2-444e-4059-a0e2-1e09f4a6f139"
      },
      "source": [
        "#load in first dataframe\n",
        "train_input = pd.DataFrame(data = train_df[1], columns = [\"Icao\", \"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "train_input = train_input.set_index('Time')\n",
        "train_input = train_input.drop('PosTime', axis = 1)\n",
        "train_input = train_input.drop('Icao', axis = 1)\n",
        "print(train_input)\n",
        "#Get Species Type\n",
        "unique_species = train_input.Type[0]\n",
        "print(unique_species)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                Alt       Lat      Long Type\n",
            "Time                                                        \n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:12:53.616    0.995056  0.540828  0.551712    0\n",
            "2020-08-06 07:13:29.760    0.995056  0.540866  0.551703    0\n",
            "2020-08-06 07:13:44.242    0.998108  0.540902  0.551694    0\n",
            "2020-08-06 07:13:56.289  0.00572213  0.540932  0.551686    0\n",
            "...                             ...       ...       ...  ...\n",
            "2020-08-06 16:02:45.713    0.999252   0.54098  0.551676    0\n",
            "2020-08-06 16:02:57.784    0.996963  0.540951  0.551683    0\n",
            "2020-08-06 16:03:55.777    0.994675  0.540866  0.551703    0\n",
            "2020-08-06 16:04:10.278    0.994675  0.540864  0.551703    0\n",
            "2020-08-06 16:04:27.227    0.994675  0.540863  0.551702    0\n",
            "\n",
            "[373 rows x 4 columns]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqCkHpvdGIh-",
        "outputId": "4ecced0f-05a7-4f09-898d-bf8420c47d59"
      },
      "source": [
        "#Resampling/Interpolating\n",
        "norm_train_df = pd.DataFrame()\n",
        "norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "norm_train_df.reset_index(inplace = True)\n",
        "#norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "norm_train_df = norm_train_df.iloc[0:73]\n",
        "print(norm_train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  Time       Lat      Long       Alt\n",
            "0  2020-08-06 07:10:00  0.541109  0.551641  0.026703\n",
            "1  2020-08-06 07:15:00  0.542472  0.552251  0.217823\n",
            "2  2020-08-06 07:20:00  0.544178  0.553254  0.402075\n",
            "3  2020-08-06 07:25:00  0.546072  0.554713  0.501640\n",
            "4  2020-08-06 07:30:00  0.547895  0.556523  0.586328\n",
            "..                 ...       ...       ...       ...\n",
            "68 2020-08-06 12:50:00  0.575555  0.585123  0.000000\n",
            "69 2020-08-06 12:55:00  0.575441  0.584925  0.000000\n",
            "70 2020-08-06 13:00:00  0.575300  0.584686  0.000000\n",
            "71 2020-08-06 13:05:00  0.575129  0.584407  0.000000\n",
            "72 2020-08-06 13:10:00  0.574928  0.584084  0.000000\n",
            "\n",
            "[73 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSnoporMGIh_",
        "outputId": "f0b3080c-fcf7-4fcc-ab50-d5581eb48794"
      },
      "source": [
        "#add species to label list\n",
        "train_labels = []\n",
        "train_labels.append(unique_species)\n",
        "print(train_labels)\n",
        "#convert dataframe to numpy\n",
        "norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "norm_train_df = norm_train_df.to_numpy()\n",
        "print(norm_train_df)\n",
        "final_input_train = norm_train_df\n",
        "print(final_input_train.shape)\n",
        "final_input_train = np.reshape(final_input_train, (1,73,3))\n",
        "print(final_input_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[0.54110926 0.55164051 0.02670329]\n",
            " [0.54247236 0.55225104 0.21782254]\n",
            " [0.54417837 0.55325353 0.40207523]\n",
            " [0.54607177 0.55471271 0.50164034]\n",
            " [0.54789543 0.5565232  0.58632792]\n",
            " [0.54969102 0.55826527 0.59510185]\n",
            " [0.55004507 0.55860418 0.59510185]\n",
            " [0.55061809 0.55913722 0.60817557]\n",
            " [0.55184827 0.56027639 0.62872997]\n",
            " [0.55359598 0.56188938 0.65039623]\n",
            " [0.55572157 0.5638439  0.66680553]\n",
            " [0.55808541 0.56600764 0.67158908]\n",
            " [0.56054785 0.56824831 0.65837804]\n",
            " [0.56296924 0.5704336  0.62080362]\n",
            " [0.56520995 0.57243121 0.55249699]\n",
            " [0.56713033 0.57410884 0.44708934]\n",
            " [0.56859511 0.57544625 0.30861372]\n",
            " [0.56961566 0.57667202 0.17662318]\n",
            " [0.57040614 0.5773856  0.08812085]\n",
            " [0.57044345 0.57741934 0.08392462]\n",
            " [0.57031141 0.57733422 0.09457798]\n",
            " [0.57020701 0.57728254 0.09927008]\n",
            " [0.57012913 0.57726283 0.09827373]\n",
            " [0.57007663 0.57727358 0.09186173]\n",
            " [0.57004836 0.5773133  0.0803069 ]\n",
            " [0.5700432  0.57738052 0.06388204]\n",
            " [0.57006001 0.57747373 0.04285995]\n",
            " [0.57009765 0.57759144 0.01751345]\n",
            " [0.57015498 0.57773217 0.        ]\n",
            " [0.57023088 0.57789442 0.        ]\n",
            " [0.5703242  0.57807671 0.        ]\n",
            " [0.5704338  0.57827755 0.        ]\n",
            " [0.57055856 0.57849543 0.        ]\n",
            " [0.57069733 0.57872888 0.        ]\n",
            " [0.57084898 0.5789764  0.        ]\n",
            " [0.57101237 0.5792365  0.        ]\n",
            " [0.57118636 0.5795077  0.        ]\n",
            " [0.57136983 0.57978849 0.        ]\n",
            " [0.57156163 0.5800774  0.        ]\n",
            " [0.57176063 0.58037292 0.        ]\n",
            " [0.57196568 0.58067358 0.        ]\n",
            " [0.57217567 0.58097787 0.        ]\n",
            " [0.57238944 0.58128432 0.        ]\n",
            " [0.57260586 0.58159142 0.        ]\n",
            " [0.5728238  0.58189769 0.        ]\n",
            " [0.57304211 0.58220164 0.        ]\n",
            " [0.57325968 0.58250177 0.        ]\n",
            " [0.57347534 0.58279661 0.        ]\n",
            " [0.57368798 0.58308465 0.        ]\n",
            " [0.57389646 0.5833644  0.        ]\n",
            " [0.57409963 0.58363438 0.        ]\n",
            " [0.57429636 0.5838931  0.        ]\n",
            " [0.57448553 0.58413906 0.        ]\n",
            " [0.57466598 0.58437077 0.        ]\n",
            " [0.57483658 0.58458675 0.        ]\n",
            " [0.5749962  0.5847855  0.        ]\n",
            " [0.5751437  0.58496553 0.        ]\n",
            " [0.57527795 0.58512536 0.        ]\n",
            " [0.57539781 0.58526349 0.        ]\n",
            " [0.57550214 0.58537843 0.        ]\n",
            " [0.5755898  0.58546869 0.        ]\n",
            " [0.57565966 0.58553279 0.        ]\n",
            " [0.57571059 0.58556922 0.        ]\n",
            " [0.57574145 0.5855765  0.        ]\n",
            " [0.57575109 0.58555314 0.        ]\n",
            " [0.57573839 0.58549765 0.        ]\n",
            " [0.57570221 0.58540854 0.        ]\n",
            " [0.57564142 0.58528432 0.        ]\n",
            " [0.57555487 0.5851235  0.        ]\n",
            " [0.57544142 0.58492458 0.        ]\n",
            " [0.57529996 0.58468608 0.        ]\n",
            " [0.57512933 0.58440651 0.        ]\n",
            " [0.5749284  0.58408437 0.        ]]\n",
            "(73, 3)\n",
            "(1, 73, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tbiJ0uUGIiB",
        "outputId": "e911d183-d1d8-4047-f5c1-62f9097ecd1a"
      },
      "source": [
        "for j in range(2,21745):\n",
        "    try:\n",
        "        train_input = pd.DataFrame(data = train_df[j], columns = [\"Icao\",\"Alt\",\"Lat\", \"Long\",\"PosTime\", \"Type\"], index = None)\n",
        "        train_input['Time'] = pd.to_datetime(train_input['PosTime'],unit='ms')\n",
        "        train_input = train_input.set_index('Time')\n",
        "        train_input = train_input.drop('PosTime', axis = 1)\n",
        "        unique_species = train_input.Type[0]\n",
        "        norm_train_df = pd.DataFrame()\n",
        "        norm_train_df['Lat'] = train_input.Lat.resample('5T').last()\n",
        "        norm_train_df['Long'] = train_input.Long.resample('5T').last()\n",
        "        norm_train_df['Alt'] = train_input.Alt.resample('5T').last()\n",
        "        norm_train_df['Lat'] = pd.to_numeric(norm_train_df['Lat'], errors='coerce')\n",
        "        norm_train_df['Long'] = pd.to_numeric(norm_train_df['Long'], errors='coerce')\n",
        "        norm_train_df['Alt'] = pd.to_numeric(norm_train_df['Alt'], errors='coerce')\n",
        "        norm_train_df = norm_train_df.interpolate(method='spline', order=3, s=0.)\n",
        "        norm_train_df.reset_index(inplace = True)\n",
        "        #norm_train_df['Alt'] = norm_train_df['Alt'].clip(0)\n",
        "        norm_train_df = norm_train_df.iloc[0:73]\n",
        "        norm_train_df = norm_train_df.drop('Time', axis = 1)\n",
        "        norm_train_df = norm_train_df.to_numpy()\n",
        "        norm_train_df = np.reshape(norm_train_df, (1,73,3))\n",
        "        final_input_train = np.append(final_input_train, norm_train_df, axis = 0)\n",
        "        train_labels.append(unique_species)\n",
        "    except:\n",
        "        pass\n",
        "        \n",
        "print(final_input_train.shape)\n",
        "print(len(train_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13776, 73, 3)\n",
            "13776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLbF6Fc1GIiC",
        "outputId": "99c6b47f-850c-4de8-ba02-90bfbbd50137"
      },
      "source": [
        "final_input_test = final_input_train[9643:]\n",
        "arr = list(range(9643,final_input_train.shape[0] ))\n",
        "print(final_input_test.shape)\n",
        "\n",
        "final_input_train = np.delete(final_input_train, arr, 0)\n",
        "print(final_input_train.shape)\n",
        "\n",
        "test_labels = train_labels[9643:]\n",
        "print(len(test_labels))\n",
        "\n",
        "train_labels_final = train_labels[:9643]\n",
        "print(len(train_labels_final))\n",
        "\n",
        "unique = list(dict.fromkeys(test_labels))\n",
        "unique2 = list(dict.fromkeys(train_labels_final))\n",
        "print(unique)\n",
        "print(unique2)\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "test_labels = to_categorical(test_labels,num_classes = 25)\n",
        "train_labels_final = to_categorical(train_labels_final,num_classes = 25)\n",
        "print(len(test_labels))\n",
        "print(len(train_labels_final))\n",
        "\n",
        "train_labels_final = np.array(train_labels_final)\n",
        "test_labels = np.array(test_labels)\n",
        "print(train_labels_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4133, 73, 3)\n",
            "(9643, 73, 3)\n",
            "4133\n",
            "9643\n",
            "[2, 19, 11, 4, 9, 1, 12, 6, 23, 16, 20, 17, 14, 0, 5, 3, 7, 8, 22, 10, 24, 15, 21, 13, 18]\n",
            "[0, 18, 1, 17, 13, 5, 12, 14, 7, 4, 15, 19, 3, 6, 11, 2, 21, 23, 16, 24, 22, 8, 20, 9, 10]\n",
            "4133\n",
            "9643\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE1R8S3tGIiC",
        "outputId": "65d7e4d7-3af9-4cb6-d97a-064eccca88d7"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(final_input_train, train_labels_final, final_input_test, test_labels):\n",
        "    verbose, epochs, batch_size = 2, 100, 16\n",
        "    n_timesteps, n_features, n_outputs = final_input_train.shape[1], final_input_train.shape[2], 25\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    #model.add(Dropout(0.5))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(n_outputs, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # fit network\n",
        "    model.fit(final_input_train, train_labels_final, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle = True)\n",
        "    # evaluate model\n",
        "    _, accuracy = model.evaluate(final_input_test, test_labels, batch_size=batch_size, verbose=0)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "    print(scores)\n",
        "    m, s = np.mean(scores), np.std(scores)\n",
        "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats=2):\n",
        "    # load data\n",
        "    # repeat experiment\n",
        "    scores = list()\n",
        "    for r in range(repeats):\n",
        "        score = evaluate_model(final_input_train, train_labels_final, final_input_test, test_labels)\n",
        "        score = score * 100.0\n",
        "        print('>#%d: %.3f' % (r+1, score))\n",
        "        scores.append(score)\n",
        "    # summarize results\n",
        "    summarize_results(scores)\n",
        "\n",
        "run_experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "603/603 - 6s - loss: 2.4027 - accuracy: 0.2825\n",
            "Epoch 2/100\n",
            "603/603 - 5s - loss: 2.2370 - accuracy: 0.3052\n",
            "Epoch 3/100\n",
            "603/603 - 5s - loss: 2.1495 - accuracy: 0.3249\n",
            "Epoch 4/100\n",
            "603/603 - 5s - loss: 2.1028 - accuracy: 0.3359\n",
            "Epoch 5/100\n",
            "603/603 - 5s - loss: 2.0692 - accuracy: 0.3337\n",
            "Epoch 6/100\n",
            "603/603 - 5s - loss: 2.0270 - accuracy: 0.3457\n",
            "Epoch 7/100\n",
            "603/603 - 5s - loss: 1.9921 - accuracy: 0.3473\n",
            "Epoch 8/100\n",
            "603/603 - 5s - loss: 1.9442 - accuracy: 0.3583\n",
            "Epoch 9/100\n",
            "603/603 - 5s - loss: 1.9090 - accuracy: 0.3667\n",
            "Epoch 10/100\n",
            "603/603 - 5s - loss: 1.8789 - accuracy: 0.3760\n",
            "Epoch 11/100\n",
            "603/603 - 5s - loss: 1.8461 - accuracy: 0.3818\n",
            "Epoch 12/100\n",
            "603/603 - 5s - loss: 1.8013 - accuracy: 0.3969\n",
            "Epoch 13/100\n",
            "603/603 - 5s - loss: 1.7721 - accuracy: 0.3997\n",
            "Epoch 14/100\n",
            "603/603 - 5s - loss: 1.7425 - accuracy: 0.4080\n",
            "Epoch 15/100\n",
            "603/603 - 5s - loss: 1.7407 - accuracy: 0.4217\n",
            "Epoch 16/100\n",
            "603/603 - 5s - loss: 1.6779 - accuracy: 0.4247\n",
            "Epoch 17/100\n",
            "603/603 - 5s - loss: 1.6380 - accuracy: 0.4380\n",
            "Epoch 18/100\n",
            "603/603 - 5s - loss: 1.6052 - accuracy: 0.4477\n",
            "Epoch 19/100\n",
            "603/603 - 5s - loss: 1.5800 - accuracy: 0.4561\n",
            "Epoch 20/100\n",
            "603/603 - 5s - loss: 1.5495 - accuracy: 0.4682\n",
            "Epoch 21/100\n",
            "603/603 - 5s - loss: 2.0924 - accuracy: 0.4696\n",
            "Epoch 22/100\n",
            "603/603 - 5s - loss: 1.5089 - accuracy: 0.4724\n",
            "Epoch 23/100\n",
            "603/603 - 5s - loss: 1.4877 - accuracy: 0.4814\n",
            "Epoch 24/100\n",
            "603/603 - 5s - loss: 1.4572 - accuracy: 0.4938\n",
            "Epoch 25/100\n",
            "603/603 - 5s - loss: 1.4375 - accuracy: 0.4970\n",
            "Epoch 26/100\n",
            "603/603 - 5s - loss: 1.4156 - accuracy: 0.5052\n",
            "Epoch 27/100\n",
            "603/603 - 5s - loss: 1.3996 - accuracy: 0.5045\n",
            "Epoch 28/100\n",
            "603/603 - 5s - loss: 1.3612 - accuracy: 0.5216\n",
            "Epoch 29/100\n",
            "603/603 - 5s - loss: 1.3521 - accuracy: 0.5246\n",
            "Epoch 30/100\n",
            "603/603 - 5s - loss: 1.3376 - accuracy: 0.5260\n",
            "Epoch 31/100\n",
            "603/603 - 5s - loss: 1.3049 - accuracy: 0.5431\n",
            "Epoch 32/100\n",
            "603/603 - 5s - loss: 1.3082 - accuracy: 0.5361\n",
            "Epoch 33/100\n",
            "603/603 - 5s - loss: 1.2826 - accuracy: 0.5411\n",
            "Epoch 34/100\n",
            "603/603 - 5s - loss: 1.2692 - accuracy: 0.5518\n",
            "Epoch 35/100\n",
            "603/603 - 5s - loss: 1.2568 - accuracy: 0.5559\n",
            "Epoch 36/100\n",
            "603/603 - 5s - loss: 1.2328 - accuracy: 0.5635\n",
            "Epoch 37/100\n",
            "603/603 - 5s - loss: 1.2228 - accuracy: 0.5709\n",
            "Epoch 38/100\n",
            "603/603 - 5s - loss: 1.2008 - accuracy: 0.5707\n",
            "Epoch 39/100\n",
            "603/603 - 5s - loss: 1.1890 - accuracy: 0.5739\n",
            "Epoch 40/100\n",
            "603/603 - 5s - loss: 1.1735 - accuracy: 0.5832\n",
            "Epoch 41/100\n",
            "603/603 - 5s - loss: 1.1629 - accuracy: 0.5883\n",
            "Epoch 42/100\n",
            "603/603 - 5s - loss: 1.1543 - accuracy: 0.5853\n",
            "Epoch 43/100\n",
            "603/603 - 6s - loss: 1.1333 - accuracy: 0.5902\n",
            "Epoch 44/100\n",
            "603/603 - 5s - loss: 1.1087 - accuracy: 0.6037\n",
            "Epoch 45/100\n",
            "603/603 - 5s - loss: 1.1173 - accuracy: 0.5983\n",
            "Epoch 46/100\n",
            "603/603 - 5s - loss: 1.0957 - accuracy: 0.6052\n",
            "Epoch 47/100\n",
            "603/603 - 5s - loss: 1.0978 - accuracy: 0.6134\n",
            "Epoch 48/100\n",
            "603/603 - 5s - loss: 1.0770 - accuracy: 0.6152\n",
            "Epoch 49/100\n",
            "603/603 - 5s - loss: 1.0668 - accuracy: 0.6139\n",
            "Epoch 50/100\n",
            "603/603 - 5s - loss: 1.0524 - accuracy: 0.6260\n",
            "Epoch 51/100\n",
            "603/603 - 5s - loss: 1.0503 - accuracy: 0.6266\n",
            "Epoch 52/100\n",
            "603/603 - 5s - loss: 1.0434 - accuracy: 0.6283\n",
            "Epoch 53/100\n",
            "603/603 - 5s - loss: 1.0194 - accuracy: 0.6400\n",
            "Epoch 54/100\n",
            "603/603 - 5s - loss: 1.0200 - accuracy: 0.6331\n",
            "Epoch 55/100\n",
            "603/603 - 5s - loss: 1.0031 - accuracy: 0.6393\n",
            "Epoch 56/100\n",
            "603/603 - 5s - loss: 0.9906 - accuracy: 0.6450\n",
            "Epoch 57/100\n",
            "603/603 - 5s - loss: 0.9929 - accuracy: 0.6422\n",
            "Epoch 58/100\n",
            "603/603 - 5s - loss: 0.9831 - accuracy: 0.6404\n",
            "Epoch 59/100\n",
            "603/603 - 5s - loss: 0.9653 - accuracy: 0.6506\n",
            "Epoch 60/100\n",
            "603/603 - 5s - loss: 0.9671 - accuracy: 0.6438\n",
            "Epoch 61/100\n",
            "603/603 - 5s - loss: 0.9437 - accuracy: 0.6496\n",
            "Epoch 62/100\n",
            "603/603 - 5s - loss: 0.9568 - accuracy: 0.6475\n",
            "Epoch 63/100\n",
            "603/603 - 5s - loss: 0.9443 - accuracy: 0.6630\n",
            "Epoch 64/100\n",
            "603/603 - 5s - loss: 0.9303 - accuracy: 0.6607\n",
            "Epoch 65/100\n",
            "603/603 - 5s - loss: 0.9462 - accuracy: 0.6570\n",
            "Epoch 66/100\n",
            "603/603 - 5s - loss: 0.9165 - accuracy: 0.6651\n",
            "Epoch 67/100\n",
            "603/603 - 5s - loss: 0.9094 - accuracy: 0.6725\n",
            "Epoch 68/100\n",
            "603/603 - 5s - loss: 0.9088 - accuracy: 0.6692\n",
            "Epoch 69/100\n",
            "603/603 - 5s - loss: 0.8960 - accuracy: 0.6784\n",
            "Epoch 70/100\n",
            "603/603 - 5s - loss: 0.8929 - accuracy: 0.6774\n",
            "Epoch 71/100\n",
            "603/603 - 5s - loss: 0.8844 - accuracy: 0.6836\n",
            "Epoch 72/100\n",
            "603/603 - 5s - loss: 0.8743 - accuracy: 0.6869\n",
            "Epoch 73/100\n",
            "603/603 - 5s - loss: 0.8767 - accuracy: 0.6823\n",
            "Epoch 74/100\n",
            "603/603 - 5s - loss: 0.8634 - accuracy: 0.6890\n",
            "Epoch 75/100\n",
            "603/603 - 5s - loss: 0.8539 - accuracy: 0.6888\n",
            "Epoch 76/100\n",
            "603/603 - 5s - loss: 0.8534 - accuracy: 0.6862\n",
            "Epoch 77/100\n",
            "603/603 - 5s - loss: 0.8756 - accuracy: 0.6858\n",
            "Epoch 78/100\n",
            "603/603 - 5s - loss: 0.8210 - accuracy: 0.6987\n",
            "Epoch 79/100\n",
            "603/603 - 5s - loss: 0.8364 - accuracy: 0.7008\n",
            "Epoch 80/100\n",
            "603/603 - 5s - loss: 0.8270 - accuracy: 0.7083\n",
            "Epoch 81/100\n",
            "603/603 - 5s - loss: 0.8261 - accuracy: 0.6986\n",
            "Epoch 82/100\n",
            "603/603 - 5s - loss: 0.8211 - accuracy: 0.7015\n",
            "Epoch 83/100\n",
            "603/603 - 5s - loss: 0.8068 - accuracy: 0.7046\n",
            "Epoch 84/100\n",
            "603/603 - 5s - loss: 0.8103 - accuracy: 0.7046\n",
            "Epoch 85/100\n",
            "603/603 - 5s - loss: 0.8061 - accuracy: 0.7046\n",
            "Epoch 86/100\n",
            "603/603 - 5s - loss: 0.8070 - accuracy: 0.7095\n",
            "Epoch 87/100\n",
            "603/603 - 5s - loss: 0.7820 - accuracy: 0.7152\n",
            "Epoch 88/100\n",
            "603/603 - 5s - loss: 0.7844 - accuracy: 0.7144\n",
            "Epoch 89/100\n",
            "603/603 - 5s - loss: 0.7938 - accuracy: 0.7137\n",
            "Epoch 90/100\n",
            "603/603 - 5s - loss: 0.7736 - accuracy: 0.7196\n",
            "Epoch 91/100\n",
            "603/603 - 5s - loss: 0.7680 - accuracy: 0.7193\n",
            "Epoch 92/100\n",
            "603/603 - 5s - loss: 0.7848 - accuracy: 0.7176\n",
            "Epoch 93/100\n",
            "603/603 - 5s - loss: 0.7734 - accuracy: 0.7158\n",
            "Epoch 94/100\n",
            "603/603 - 5s - loss: 0.7533 - accuracy: 0.7272\n",
            "Epoch 95/100\n",
            "603/603 - 5s - loss: 0.7628 - accuracy: 0.7242\n",
            "Epoch 96/100\n",
            "603/603 - 5s - loss: 0.7473 - accuracy: 0.7286\n",
            "Epoch 97/100\n",
            "603/603 - 5s - loss: 0.7520 - accuracy: 0.7290\n",
            "Epoch 98/100\n",
            "603/603 - 5s - loss: 0.7472 - accuracy: 0.7335\n",
            "Epoch 99/100\n",
            "603/603 - 5s - loss: 0.7351 - accuracy: 0.7331\n",
            "Epoch 100/100\n",
            "603/603 - 5s - loss: 0.7229 - accuracy: 0.7347\n",
            ">#1: 28.938\n",
            "Epoch 1/100\n",
            "603/603 - 6s - loss: 2.4469 - accuracy: 0.2870\n",
            "Epoch 2/100\n",
            "603/603 - 5s - loss: 2.2023 - accuracy: 0.3164\n",
            "Epoch 3/100\n",
            "603/603 - 5s - loss: 2.1399 - accuracy: 0.3209\n",
            "Epoch 4/100\n",
            "603/603 - 5s - loss: 2.0925 - accuracy: 0.3309\n",
            "Epoch 5/100\n",
            "603/603 - 5s - loss: 2.0535 - accuracy: 0.3406\n",
            "Epoch 6/100\n",
            "603/603 - 5s - loss: 2.0148 - accuracy: 0.3514\n",
            "Epoch 7/100\n",
            "603/603 - 5s - loss: 1.9791 - accuracy: 0.3538\n",
            "Epoch 8/100\n",
            "603/603 - 5s - loss: 1.9365 - accuracy: 0.3630\n",
            "Epoch 9/100\n",
            "603/603 - 5s - loss: 1.8852 - accuracy: 0.3734\n",
            "Epoch 10/100\n",
            "603/603 - 5s - loss: 1.8517 - accuracy: 0.3795\n",
            "Epoch 11/100\n",
            "603/603 - 5s - loss: 1.8108 - accuracy: 0.3867\n",
            "Epoch 12/100\n",
            "603/603 - 5s - loss: 1.7639 - accuracy: 0.4032\n",
            "Epoch 13/100\n",
            "603/603 - 5s - loss: 1.7298 - accuracy: 0.4084\n",
            "Epoch 14/100\n",
            "603/603 - 5s - loss: 1.6909 - accuracy: 0.4238\n",
            "Epoch 15/100\n",
            "603/603 - 5s - loss: 1.6620 - accuracy: 0.4385\n",
            "Epoch 16/100\n",
            "603/603 - 5s - loss: 1.6251 - accuracy: 0.4362\n",
            "Epoch 17/100\n",
            "603/603 - 5s - loss: 1.5868 - accuracy: 0.4491\n",
            "Epoch 18/100\n",
            "603/603 - 5s - loss: 1.5567 - accuracy: 0.4618\n",
            "Epoch 19/100\n",
            "603/603 - 5s - loss: 1.5307 - accuracy: 0.4722\n",
            "Epoch 20/100\n",
            "603/603 - 5s - loss: 1.4918 - accuracy: 0.4825\n",
            "Epoch 21/100\n",
            "603/603 - 5s - loss: 1.4788 - accuracy: 0.4822\n",
            "Epoch 22/100\n",
            "603/603 - 5s - loss: 1.4549 - accuracy: 0.4942\n",
            "Epoch 23/100\n",
            "603/603 - 5s - loss: 1.4200 - accuracy: 0.5052\n",
            "Epoch 24/100\n",
            "603/603 - 5s - loss: 1.4101 - accuracy: 0.5001\n",
            "Epoch 25/100\n",
            "603/603 - 5s - loss: 1.3801 - accuracy: 0.5149\n",
            "Epoch 26/100\n",
            "603/603 - 5s - loss: 1.3666 - accuracy: 0.5264\n",
            "Epoch 27/100\n",
            "603/603 - 5s - loss: 1.3515 - accuracy: 0.5244\n",
            "Epoch 28/100\n",
            "603/603 - 5s - loss: 1.3315 - accuracy: 0.5381\n",
            "Epoch 29/100\n",
            "603/603 - 5s - loss: 1.2996 - accuracy: 0.5414\n",
            "Epoch 30/100\n",
            "603/603 - 5s - loss: 1.2774 - accuracy: 0.5495\n",
            "Epoch 31/100\n",
            "603/603 - 5s - loss: 1.2619 - accuracy: 0.5554\n",
            "Epoch 32/100\n",
            "603/603 - 5s - loss: 1.2515 - accuracy: 0.5522\n",
            "Epoch 33/100\n",
            "603/603 - 5s - loss: 1.2285 - accuracy: 0.5602\n",
            "Epoch 34/100\n",
            "603/603 - 5s - loss: 1.2181 - accuracy: 0.5698\n",
            "Epoch 35/100\n",
            "603/603 - 5s - loss: 1.2024 - accuracy: 0.5752\n",
            "Epoch 36/100\n",
            "603/603 - 5s - loss: 1.1917 - accuracy: 0.5796\n",
            "Epoch 37/100\n",
            "603/603 - 5s - loss: 1.1753 - accuracy: 0.5785\n",
            "Epoch 38/100\n",
            "603/603 - 5s - loss: 1.1517 - accuracy: 0.5903\n",
            "Epoch 39/100\n",
            "603/603 - 5s - loss: 1.1469 - accuracy: 0.5856\n",
            "Epoch 40/100\n",
            "603/603 - 5s - loss: 1.1333 - accuracy: 0.5975\n",
            "Epoch 41/100\n",
            "603/603 - 5s - loss: 1.1255 - accuracy: 0.6010\n",
            "Epoch 42/100\n",
            "603/603 - 5s - loss: 1.1187 - accuracy: 0.5981\n",
            "Epoch 43/100\n",
            "603/603 - 5s - loss: 1.1025 - accuracy: 0.6083\n",
            "Epoch 44/100\n",
            "603/603 - 5s - loss: 1.0822 - accuracy: 0.6127\n",
            "Epoch 45/100\n",
            "603/603 - 5s - loss: 1.0845 - accuracy: 0.6093\n",
            "Epoch 46/100\n",
            "603/603 - 5s - loss: 1.0576 - accuracy: 0.6183\n",
            "Epoch 47/100\n",
            "603/603 - 5s - loss: 1.0533 - accuracy: 0.6233\n",
            "Epoch 48/100\n",
            "603/603 - 5s - loss: 1.0360 - accuracy: 0.6258\n",
            "Epoch 49/100\n",
            "603/603 - 5s - loss: 1.0363 - accuracy: 0.6272\n",
            "Epoch 50/100\n",
            "603/603 - 5s - loss: 1.0310 - accuracy: 0.6281\n",
            "Epoch 51/100\n",
            "603/603 - 5s - loss: 1.0204 - accuracy: 0.6353\n",
            "Epoch 52/100\n",
            "603/603 - 5s - loss: 1.0040 - accuracy: 0.6390\n",
            "Epoch 53/100\n",
            "603/603 - 5s - loss: 0.9927 - accuracy: 0.6406\n",
            "Epoch 54/100\n",
            "603/603 - 5s - loss: 0.9898 - accuracy: 0.6388\n",
            "Epoch 55/100\n",
            "603/603 - 5s - loss: 0.9793 - accuracy: 0.6442\n",
            "Epoch 56/100\n",
            "603/603 - 5s - loss: 0.9703 - accuracy: 0.6502\n",
            "Epoch 57/100\n",
            "603/603 - 5s - loss: 0.9619 - accuracy: 0.6510\n",
            "Epoch 58/100\n",
            "603/603 - 5s - loss: 0.9592 - accuracy: 0.6511\n",
            "Epoch 59/100\n",
            "603/603 - 5s - loss: 0.9461 - accuracy: 0.6610\n",
            "Epoch 60/100\n",
            "603/603 - 5s - loss: 0.9438 - accuracy: 0.6568\n",
            "Epoch 61/100\n",
            "603/603 - 5s - loss: 0.9388 - accuracy: 0.6583\n",
            "Epoch 62/100\n",
            "603/603 - 5s - loss: 0.9230 - accuracy: 0.6641\n",
            "Epoch 63/100\n",
            "603/603 - 5s - loss: 0.9266 - accuracy: 0.6703\n",
            "Epoch 64/100\n",
            "603/603 - 5s - loss: 0.9172 - accuracy: 0.6716\n",
            "Epoch 65/100\n",
            "603/603 - 5s - loss: 0.8881 - accuracy: 0.6839\n",
            "Epoch 66/100\n",
            "603/603 - 5s - loss: 0.8897 - accuracy: 0.6767\n",
            "Epoch 67/100\n",
            "603/603 - 5s - loss: 0.8847 - accuracy: 0.6752\n",
            "Epoch 68/100\n",
            "603/603 - 5s - loss: 0.8943 - accuracy: 0.6764\n",
            "Epoch 69/100\n",
            "603/603 - 5s - loss: 0.8831 - accuracy: 0.6841\n",
            "Epoch 70/100\n",
            "603/603 - 5s - loss: 0.8601 - accuracy: 0.6805\n",
            "Epoch 71/100\n",
            "603/603 - 5s - loss: 0.8754 - accuracy: 0.6757\n",
            "Epoch 72/100\n",
            "603/603 - 5s - loss: 0.8816 - accuracy: 0.6799\n",
            "Epoch 73/100\n",
            "603/603 - 5s - loss: 0.8438 - accuracy: 0.6918\n",
            "Epoch 74/100\n",
            "603/603 - 5s - loss: 0.8392 - accuracy: 0.6974\n",
            "Epoch 75/100\n",
            "603/603 - 5s - loss: 0.8508 - accuracy: 0.6946\n",
            "Epoch 76/100\n",
            "603/603 - 5s - loss: 0.8436 - accuracy: 0.6911\n",
            "Epoch 77/100\n",
            "603/603 - 5s - loss: 0.8314 - accuracy: 0.7006\n",
            "Epoch 78/100\n",
            "603/603 - 5s - loss: 0.8242 - accuracy: 0.7024\n",
            "Epoch 79/100\n",
            "603/603 - 5s - loss: 0.8155 - accuracy: 0.7052\n",
            "Epoch 80/100\n",
            "603/603 - 5s - loss: 0.8125 - accuracy: 0.7072\n",
            "Epoch 81/100\n",
            "603/603 - 5s - loss: 0.8158 - accuracy: 0.6994\n",
            "Epoch 82/100\n",
            "603/603 - 5s - loss: 0.8134 - accuracy: 0.7104\n",
            "Epoch 83/100\n",
            "603/603 - 6s - loss: 0.8102 - accuracy: 0.7048\n",
            "Epoch 84/100\n",
            "603/603 - 5s - loss: 0.7920 - accuracy: 0.7171\n",
            "Epoch 85/100\n",
            "603/603 - 5s - loss: 0.7884 - accuracy: 0.7105\n",
            "Epoch 86/100\n",
            "603/603 - 5s - loss: 0.7720 - accuracy: 0.7150\n",
            "Epoch 87/100\n",
            "603/603 - 5s - loss: 0.7724 - accuracy: 0.7230\n",
            "Epoch 88/100\n",
            "603/603 - 5s - loss: 0.7900 - accuracy: 0.7119\n",
            "Epoch 89/100\n",
            "603/603 - 5s - loss: 0.7732 - accuracy: 0.7195\n",
            "Epoch 90/100\n",
            "603/603 - 5s - loss: 0.7642 - accuracy: 0.7249\n",
            "Epoch 91/100\n",
            "603/603 - 5s - loss: 0.7802 - accuracy: 0.7184\n",
            "Epoch 92/100\n",
            "603/603 - 5s - loss: 0.7428 - accuracy: 0.7282\n",
            "Epoch 93/100\n",
            "603/603 - 5s - loss: 0.7608 - accuracy: 0.7281\n",
            "Epoch 94/100\n",
            "603/603 - 5s - loss: 0.7511 - accuracy: 0.7268\n",
            "Epoch 95/100\n",
            "603/603 - 5s - loss: 0.7437 - accuracy: 0.7316\n",
            "Epoch 96/100\n",
            "603/603 - 5s - loss: 0.7436 - accuracy: 0.7306\n",
            "Epoch 97/100\n",
            "603/603 - 5s - loss: 0.7342 - accuracy: 0.7281\n",
            "Epoch 98/100\n",
            "603/603 - 5s - loss: 0.7515 - accuracy: 0.7253\n",
            "Epoch 99/100\n",
            "603/603 - 5s - loss: 0.7343 - accuracy: 0.7291\n",
            "Epoch 100/100\n",
            "603/603 - 5s - loss: 0.7330 - accuracy: 0.7351\n",
            ">#2: 30.220\n",
            "[28.937816619873047, 30.22017776966095]\n",
            "Accuracy: 29.579% (+/-0.641)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}